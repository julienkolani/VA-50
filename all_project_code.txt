################################################################################
PATH: ./control_turtlebot/config/controls.yaml
################################################################################
# Controller Configuration

keyboard:
  max_linear_mps: 3.5
  max_angular_dps: 120
  acceleration_linear: 0.2
  acceleration_angular: 2.5
  friction_linear: 0.92
  friction_angular: 0.82

ps3:
  max_linear_mps: 3.5
  max_angular_dps: 120
  deadzone: 0.15
  button_mapping:
    emergency_stop: 0 # X button
    circle: 1
    triangle: 2
    square: 3
  axis_mapping:
    left_x: 0
    left_y: 1
    right_x: 2

speed_control:
  initial_factor: 0.07
  min_factor: 0.2
  max_factor: 2.0
  increment: 0.1


################################################################################
PATH: ./control_turtlebot/config/__init__.py
################################################################################
"""Configuration package for TurtleBot controller."""


################################################################################
PATH: ./control_turtlebot/config/network.yaml
################################################################################
# Network Configuration for TurtleBot Controller

websocket:
  uri: "ws://localhost:8765"
  reconnect_delay_s: 2.0
  ping_interval_s: 3.0
  timeout_s: 10.0

command:
  frequency_hz: 30
  k_linear: 6.0      # Linear velocity amplification
  k_angular: 4.0     # Angular velocity amplification


################################################################################
PATH: ./control_turtlebot/config.py
################################################################################
#!/usr/bin/env python3
"""
Configuration globale du TurtleBot Controller
Tous les paramètres modifiables de l'application
"""

# ============================================================================
# CONNEXION WEBSOCKET
# ============================================================================
WEBSOCKET_URI = "ws://localhost:8765"
WEBSOCKET_RECONNECT_DELAY = 2.0  # secondes
WEBSOCKET_PING_INTERVAL = 3.0    # secondes

# ============================================================================
# AMPLIFICATION DES COMMANDES ROBOT
# ============================================================================
# Facteurs d'amplification envoyés au robot via WebSocket
# Augmentez ces valeurs pour un robot plus réactif
# Réduisez-les pour un comportement plus doux
K_LINEAR = 1.0   # Amplification vitesse linéaire (défaut: 6.0)
K_ANGULAR = 1.0  # Amplification vitesse angulaire (défaut: 6.0)

# ============================================================================
# CONTRÔLEURS
# ============================================================================
# Facteur de vitesse initial (peut être modifié avec +/-)
INITIAL_SPEED_FACTOR = 0.07

# Limites des facteurs de vitesse
MIN_SPEED_FACTOR = 0.2
MAX_SPEED_FACTOR = 2.0
SPEED_INCREMENT = 0.1  # Incrément pour +/-

# Deadzone pour la manette PS3 (évite le drift)
PS3_DEADZONE = 0.15

# Fréquence d'envoi des commandes (Hz)
COMMAND_FREQUENCY = 30

# ============================================================================
# CLAVIER - Paramètres de contrôle
# ============================================================================
KEYBOARD_ACCEL_LINEAR = 0.2      # Accélération linéaire
KEYBOARD_ACCEL_ANGULAR = 2.5     # Accélération angulaire
KEYBOARD_MAX_LINEAR = 3.5        # Vitesse linéaire maximale
KEYBOARD_MAX_ANGULAR = 120       # Vitesse angulaire maximale (degrés)
KEYBOARD_FRICTION = 0.92         # Friction linéaire (0-1)
KEYBOARD_FRICTION_ANGULAR = 0.82 # Friction angulaire (0-1)

# ============================================================================
# MANETTE PS3 - Paramètres de contrôle
# ============================================================================
PS3_MAX_LINEAR = 3.5    # Vitesse linéaire maximale
PS3_MAX_ANGULAR = 120   # Vitesse angulaire maximale (degrés)

# Mapping des boutons PS3 (peut varier selon le driver)
PS3_BTN_X = 0           # Croix (arrêt d'urgence)
PS3_BTN_CIRCLE = 1      # Rond
PS3_BTN_TRIANGLE = 2    # Triangle
PS3_BTN_SQUARE = 3      # Carré

# Axes analogiques PS3
PS3_AXIS_LEFT_X = 0     # Stick gauche horizontal
PS3_AXIS_LEFT_Y = 1     # Stick gauche vertical
PS3_AXIS_RIGHT_X = 2    # Stick droit horizontal

# ============================================================================
# SIMULATION VISUELLE
# ============================================================================
# Échelles de mouvement dans la simulation visuelle
VISUAL_SPEED_SCALE = 1000      # pixels par m/s
VISUAL_ANGULAR_SCALE = 5       # pixels par rad/s

# Paramètres du robot visuel
VISUAL_MAX_DISTANCE = 220      # Distance max du centre (pixels)
VISUAL_TRAIL_LENGTH = 80       # Longueur de la traînée
VISUAL_RETURN_SPEED = 0.15     # Vitesse de retour au centre

# ============================================================================
# INTERFACE GRAPHIQUE
# ============================================================================
# Dimensions par défaut
DEFAULT_WIDTH = 1200
DEFAULT_HEIGHT = 700
INFO_PANEL_WIDTH = 350

# FPS cible
TARGET_FPS = 60

# Fréquence de mise à jour du status (secondes)
STATUS_UPDATE_INTERVAL = 3.0

# ============================================================================
# COULEURS - Thème sombre moderne avec accents néon
# ============================================================================
# Fond et panneaux
COLOR_BG = (15, 15, 20)              # Fond très sombre
COLOR_PANEL = (25, 28, 35)           # Panneaux légèrement plus clairs
COLOR_PANEL_ACCENT = (35, 40, 50)    # Accent pour sous-panneaux

# Texte
COLOR_TEXT = (230, 230, 235)         # Texte principal clair
COLOR_TEXT_DIM = (150, 150, 160)     # Texte secondaire
COLOR_TEXT_BRIGHT = (255, 255, 255)  # Texte en surbrillance

# Accents principaux (néon cyan/bleu)
COLOR_ACCENT = (0, 230, 255)         # Cyan néon principal
COLOR_ACCENT_BRIGHT = (100, 240, 255) # Cyan clair
COLOR_ACCENT_DIM = (0, 180, 200)     # Cyan foncé

# États
COLOR_SUCCESS = (50, 255, 150)       # Vert néon (succès)
COLOR_WARNING = (255, 180, 0)        # Orange vif (attention)
COLOR_ERROR = (255, 80, 100)         # Rouge néon (erreur)
COLOR_INFO = (150, 150, 255)         # Bleu clair (info)

# Grille et éléments de fond
COLOR_GRID = (35, 38, 45)            # Grille subtile
COLOR_GRID_ACCENT = (45, 50, 60)     # Lignes de grille accentuées

# Robot visuel
COLOR_ROBOT_BODY = (40, 45, 55)      # Corps du robot
COLOR_ROBOT_OUTLINE = (0, 220, 255)  # Contour cyan néon
COLOR_ROBOT_WHEELS = (90, 95, 105)   # Roues
COLOR_ROBOT_DIRECTION = (255, 100, 120) # Flèche de direction (rose néon)
COLOR_ROBOT_CENTER = (255, 220, 0)   # Point central (jaune)

# Traînée du robot (gradient cyan)
COLOR_TRAIL_START = (0, 100, 120)    # Début de traînée
COLOR_TRAIL_END = (0, 200, 220)      # Fin de traînée

# Effets visuels
COLOR_GLOW = (0, 200, 255, 100)      # Effet de lueur (avec alpha)
COLOR_SHADOW = (0, 0, 0, 80)         # Ombre portée

# ============================================================================
# POLICES
# ============================================================================
FONT_SIZE_TITLE = 36        # Titres principaux
FONT_SIZE_SUBTITLE = 28     # Sous-titres
FONT_SIZE_NORMAL = 24       # Texte normal
FONT_SIZE_SMALL = 20        # Petit texte
FONT_SIZE_TINY = 16         # Texte minuscule

# ============================================================================
# ANIMATIONS
# ============================================================================
ANIMATION_PULSE_SPEED = 2.0       # Vitesse de pulsation (connexion)
ANIMATION_GLOW_INTENSITY = 0.3    # Intensité de la lueur
ANIMATION_SMOOTH_FACTOR = 0.15    # Facteur de lissage des animations

# ============================================================================
# MESSAGES DE DEBUG
# ============================================================================
DEBUG_MODE = False  # Active les messages de debug supplémentaires


def get_websocket_config():
    """Retourne la configuration WebSocket"""
    return {
        'uri': WEBSOCKET_URI,
        'reconnect_delay': WEBSOCKET_RECONNECT_DELAY,
        'ping_interval': WEBSOCKET_PING_INTERVAL,
        'k_linear': K_LINEAR,
        'k_angular': K_ANGULAR
    }


def get_controller_config():
    """Retourne la configuration des contrôleurs"""
    return {
        'initial_speed_factor': INITIAL_SPEED_FACTOR,
        'min_speed_factor': MIN_SPEED_FACTOR,
        'max_speed_factor': MAX_SPEED_FACTOR,
        'speed_increment': SPEED_INCREMENT,
        'command_frequency': COMMAND_FREQUENCY
    }


def get_keyboard_config():
    """Retourne la configuration du contrôleur clavier"""
    return {
        'accel_linear': KEYBOARD_ACCEL_LINEAR,
        'accel_angular': KEYBOARD_ACCEL_ANGULAR,
        'max_linear': KEYBOARD_MAX_LINEAR,
        'max_angular': KEYBOARD_MAX_ANGULAR,
        'friction': KEYBOARD_FRICTION,
        'friction_angular': KEYBOARD_FRICTION_ANGULAR
    }


def get_ps3_config():
    """Retourne la configuration du contrôleur PS3"""
    return {
        'deadzone': PS3_DEADZONE,
        'max_linear': PS3_MAX_LINEAR,
        'max_angular': PS3_MAX_ANGULAR,
        'btn_x': PS3_BTN_X,
        'btn_circle': PS3_BTN_CIRCLE,
        'btn_triangle': PS3_BTN_TRIANGLE,
        'btn_square': PS3_BTN_SQUARE,
        'axis_left_x': PS3_AXIS_LEFT_X,
        'axis_left_y': PS3_AXIS_LEFT_Y,
        'axis_right_x': PS3_AXIS_RIGHT_X
    }


def get_visual_config():
    """Retourne la configuration de la simulation visuelle"""
    return {
        'speed_scale': VISUAL_SPEED_SCALE,
        'angular_scale': VISUAL_ANGULAR_SCALE,
        'max_distance': VISUAL_MAX_DISTANCE,
        'trail_length': VISUAL_TRAIL_LENGTH,
        'return_speed': VISUAL_RETURN_SPEED
    }


def get_ui_config():
    """Retourne la configuration de l'interface"""
    return {
        'default_width': DEFAULT_WIDTH,
        'default_height': DEFAULT_HEIGHT,
        'info_panel_width': INFO_PANEL_WIDTH,
        'target_fps': TARGET_FPS,
        'status_update_interval': STATUS_UPDATE_INTERVAL
    }


def get_color_scheme():
    """Retourne le schéma de couleurs complet"""
    return {
        'bg': COLOR_BG,
        'panel': COLOR_PANEL,
        'panel_accent': COLOR_PANEL_ACCENT,
        'text': COLOR_TEXT,
        'text_dim': COLOR_TEXT_DIM,
        'text_bright': COLOR_TEXT_BRIGHT,
        'accent': COLOR_ACCENT,
        'accent_bright': COLOR_ACCENT_BRIGHT,
        'accent_dim': COLOR_ACCENT_DIM,
        'success': COLOR_SUCCESS,
        'warning': COLOR_WARNING,
        'error': COLOR_ERROR,
        'info': COLOR_INFO,
        'grid': COLOR_GRID,
        'grid_accent': COLOR_GRID_ACCENT,
        'robot_body': COLOR_ROBOT_BODY,
        'robot_outline': COLOR_ROBOT_OUTLINE,
        'robot_wheels': COLOR_ROBOT_WHEELS,
        'robot_direction': COLOR_ROBOT_DIRECTION,
        'robot_center': COLOR_ROBOT_CENTER,
        'trail_start': COLOR_TRAIL_START,
        'trail_end': COLOR_TRAIL_END
    }

################################################################################
PATH: ./control_turtlebot/config/robot.yaml
################################################################################
# Robot Physical Limits Configuration

robot:
  name: "TurtleBot3 Burger"
  type: "differential_drive"

velocity_limits:
  max_linear_mps: 0.22 # Maximum linear velocity (m/s)
  max_angular_radps: 2.84 # Maximum angular velocity (rad/s)
  min_linear_mps: -0.22
  min_angular_radps: -2.84

physical:
  wheel_base_m: 0.16 # Distance between wheels
  wheel_radius_m: 0.033 # Wheel radius
  robot_radius_m: 0.09 # Robot approximation as circle

safety:
  emergency_stop_decel: 5.0 # Deceleration rate for emergency stop (m/s²)
  min_obstacle_distance_m: 0.1


################################################################################
PATH: ./control_turtlebot/config/ui.yaml
################################################################################
# UI Configuration

window:
  default_width: 1200
  default_height: 700
  title: "TurtleBot Controller"
  target_fps: 60
  resizable: true

panels:
  info_width: 350
  status_update_interval_s: 3.0
  margin: 20
  padding: 15

theme:
  name: "dark_professional"
  colors:
    background: [15, 15, 20]
    panel: [25, 28, 35]
    panel_accent: [35, 40, 50]
    text: [230, 230, 235]
    text_dim: [150, 150, 160]
    text_bright: [255, 255, 255]
    accent: [0, 180, 220]
    accent_bright: [80, 200, 240]
    accent_dim: [0, 140, 180]
    success: [50, 200, 100]
    warning: [200, 150, 0]
    error: [200, 50, 50]
    info: [120, 150, 255]
    grid: [35, 38, 45]

fonts:
  title_size: 32
  subtitle_size: 24
  normal_size: 20
  small_size: 16
  tiny_size: 14

visual:
  speed_scale: 1000 # pixels per m/s
  angular_scale: 5 # pixels per rad/s
  max_distance: 220 # max distance from center (pixels)
  trail_length: 80 # length of robot trail
  return_speed: 0.15 # return to center speed


################################################################################
PATH: ./control_turtlebot/core/controllers/base_controller.py
################################################################################
"""Classe abstraite de contrôleur de base."""

from abc import ABC, abstractmethod
from typing import Tuple, Dict, Any
import logging

logger = logging.getLogger(__name__)


class BaseController(ABC):
    """
    Classe de base abstraite pour tous les contrôleurs de robot.
    
    Les contrôleurs traduisent les entrées (clavier, joystick, etc.) 
    en commandes de vitesse pour le robot (linéaire, angulaire).
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialise le contrôleur avec la configuration.
        
        Args:
            config: Dictionnaire de configuration spécifique au contrôleur
        """
        self.config = config
        self.linear_cmd = 0.0
        self.angular_cmd = 0.0
        self._enabled = True
        
        logger.info(f"{self.__class__.__name__} initialisé")
    
    @abstractmethod
    def update(self, events: list) -> None:
        """
        Met à jour l'état du contrôleur basé sur les événements d'entrée.
        
        Args:
            events: Liste des événements pygame à traiter
        """
        pass
    
    @abstractmethod
    def get_command(self) -> Tuple[float, float]:
        """
        Obtient la commande de vitesse actuelle.
        
        Returns:
            Tuple de (vitesse_lineaire, vitesse_angulaire)
        """
        pass
    
    @abstractmethod
    def emergency_stop(self) -> None:
        """Exécute l'arrêt d'urgence - met immédiatement toutes les vitesses à zéro."""
        pass
    
    def enable(self) -> None:
        """Active le contrôleur."""
        self._enabled = True
        logger.info(f"{self.__class__.__name__} activé")
    
    def disable(self) -> None:
        """Désactive le contrôleur et arrête le robot."""
        self._enabled = False
        self.emergency_stop()
        logger.info(f"{self.__class__.__name__} désactivé")
    
    def is_enabled(self) -> bool:
        """Vérifie si le contrôleur est activé."""
        return self._enabled
    
    def reset(self) -> None:
        """Réinitialise le contrôleur à l'état initial."""
        self.linear_cmd = 0.0
        self.angular_cmd = 0.0
        logger.debug(f"{self.__class__.__name__} réinitialisé")


################################################################################
PATH: ./control_turtlebot/core/controllers/__init__.py
################################################################################
"""Controllers module for robot input handling."""


################################################################################
PATH: ./control_turtlebot/core/controllers/keyboard_controller.py
################################################################################
"""Contrôleur clavier pour TurtleBot."""

import pygame
import math
from typing import Tuple
import logging
from .base_controller import BaseController

logger = logging.getLogger(__name__)


class KeyboardController(BaseController):
    """
    Contrôleur clavier avec mouvement basé sur la physique.
    
    Contrôles :
        Flèches / WASD - Mouvement
        Espace - Arrêt d'urgence
        + / - - Ajuster le facteur de vitesse
    """
    
    def __init__(self, config: dict):
        """
        Initialise le contrôleur clavier.
        
        Args:
            config: Configuration clavier depuis controls.yaml
        """
        super().__init__(config)
        
        # Extract config
        kbd_cfg = config.get('keyboard', {})
        speed_cfg = config.get('speed_control', {})
        
        # Speed factor management
        self.speed_factor = speed_cfg.get('initial_factor', 0.07)
        self.min_factor = speed_cfg.get('min_factor', 0.2)
        self.max_factor = speed_cfg.get('max_factor', 2.0)
        self.factor_increment = speed_cfg.get('increment', 0.1)
        
        # Physics parameters (scaled by speed factor)
        self.base_accel_linear = kbd_cfg.get('acceleration_linear', 0.2)
        self.base_accel_angular = kbd_cfg.get('acceleration_angular', 2.5)
        self.base_max_linear = kbd_cfg.get('max_linear_mps', 3.5)
        self.base_max_angular = kbd_cfg.get('max_angular_dps', 120)
        
        # Apply scaling
        self._update_scaled_params()
        
        # Friction
        self.friction_linear = kbd_cfg.get('friction_linear', 0.92)
        self.friction_angular = kbd_cfg.get('friction_angular', 0.82)
        
        # Current velocities (in display units)
        self.velocity_linear = 0.0
        self.velocity_angular = 0.0
    
    def _update_scaled_params(self):
        """Update parameters based on current speed factor."""
        self.accel_linear = self.base_accel_linear * self.speed_factor
        self.accel_angular = self.base_accel_angular * self.speed_factor
        self.max_linear = self.base_max_linear * self.speed_factor
        self.max_angular = self.base_max_angular * self.speed_factor
    
    def increase_speed(self):
        """Increase speed factor."""
        old_factor = self.speed_factor
        self.speed_factor = min(self.speed_factor + self.factor_increment, self.max_factor)
        
        if self.speed_factor != old_factor:
            ratio = self.speed_factor / old_factor
            self.velocity_linear *= ratio
            self.velocity_angular *= ratio
            self._update_scaled_params()
            logger.info(f"Facteur de vitesse augmenté à {self.speed_factor:.2f}")
    
    def decrease_speed(self):
        """Decrease speed factor."""
        old_factor = self.speed_factor
        self.speed_factor = max(self.speed_factor - self.factor_increment, self.min_factor)
        
        if self.speed_factor != old_factor:
            ratio = self.speed_factor / old_factor
            self.velocity_linear *= ratio
            self.velocity_angular *= ratio
            self._update_scaled_params()
            logger.info(f"Facteur de vitesse diminué à {self.speed_factor:.2f}")
    
    def update(self, events: list) -> None:
        """
        Met à jour le contrôleur basé sur l'entrée clavier.
        
        Args:
            events: Liste des événements pygame
        """
        if not self._enabled:
            return
        
        # Get current key states
        keys = pygame.key.get_pressed()
        
        # Linear velocity control
        if keys[pygame.K_UP] or keys[pygame.K_w]:
            self.velocity_linear = min(
                self.velocity_linear + self.accel_linear,
                self.max_linear
            )
        elif keys[pygame.K_DOWN] or keys[pygame.K_s]:
            self.velocity_linear = max(
                self.velocity_linear - self.accel_linear,
                -self.max_linear
            )
        else:
            # Apply friction
            self.velocity_linear *= self.friction_linear
            if abs(self.velocity_linear) < 0.05:
                self.velocity_linear = 0.0
        
        # Angular velocity control with direction correction for reverse
        left = keys[pygame.K_LEFT] or keys[pygame.K_a]
        right = keys[pygame.K_RIGHT] or keys[pygame.K_d]
        forward = keys[pygame.K_UP] or keys[pygame.K_w]
        backward = keys[pygame.K_DOWN] or keys[pygame.K_s]
        
        # Direction factor inverts turning when moving backward
        direction_factor = -1 if self.velocity_linear < 0 else 1
        
        if left and right:
            # Both directions pressed - special case for sharp turning
            if forward:
                self.velocity_angular = self.max_angular
            elif backward:
                self.velocity_angular = -self.max_angular
            else:
                self.velocity_angular *= self.friction_angular
        elif left:
            # Turn left (corrected for reverse)
            intensity = 1.0 + abs(self.velocity_linear) * 0.3
            self.velocity_angular = max(
                self.velocity_angular - self.accel_angular * intensity * direction_factor,
                -self.max_angular * 0.6
            )
        elif right:
            # Turn right (corrected for reverse)
            intensity = 1.0 + abs(self.velocity_linear) * 0.3
            self.velocity_angular = min(
                self.velocity_angular + self.accel_angular * intensity * direction_factor,
                self.max_angular * 0.6
            )
        else:
            # Apply friction
            self.velocity_angular *= self.friction_angular
            if abs(self.velocity_angular) < 0.2:
                self.velocity_angular = 0.0
        
        # Convert to ROS command (m/s and rad/s)
        self.linear_cmd = self.velocity_linear * 0.1
        self.angular_cmd = math.radians(self.velocity_angular)
        
        # Handle discrete events (speed adjustment, emergency stop)
        for event in events:
            if event.type == pygame.KEYDOWN:
                if event.key == pygame.K_PLUS or event.key == pygame.K_EQUALS:
                    self.increase_speed()
                elif event.key == pygame.K_MINUS:
                    self.decrease_speed()
                elif event.key == pygame.K_SPACE:
                    self.emergency_stop()
    
    def get_command(self) -> Tuple[float, float]:
        """
        Obtient la commande de vitesse actuelle.
        
        Returns:
            Tuple de (vitesse_lineaire_m/s, vitesse_angulaire_rad/s)
        """
        if not self._enabled:
            return (0.0, 0.0)
        return (self.linear_cmd, self.angular_cmd)
    
    def emergency_stop(self) -> None:
        """Exécute l'arrêt d'urgence."""
        self.velocity_linear = 0.0
        self.velocity_angular = 0.0
        self.linear_cmd = 0.0
        self.angular_cmd = 0.0
        logger.warning("Arrêt d'urgence déclenché")
    
    def get_speed_factor(self) -> float:
        """Obtient le facteur de vitesse actuel."""
        return self.speed_factor


################################################################################
PATH: ./control_turtlebot/core/controllers/ps3_controller.py
################################################################################
"""Contrôleur PS3 pour TurtleBot."""

import pygame
import math
from typing import Tuple
import logging
from .base_controller import BaseController

logger = logging.getLogger(__name__)


class PS3Controller(BaseController):
    """
    Contrôleur manette PS3 avec deadzone et mapping de boutons.
    
    Fonctionnalités :
    - Contrôle stick analogique
    - Surcharge D-pad
    - Compensation deadzone
    - Support Hot-plug
    """
    
    def __init__(self, config: dict):
        """
        Initialise le contrôleur PS3.
        
        Args:
            config: Configuration PS3 depuis controls.yaml
        """
        super().__init__(config)
        
        # Extract config
        ps3_cfg = config.get('ps3', {})
        speed_cfg = config.get('speed_control', {})
        
        # Speed factor management
        self.speed_factor = speed_cfg.get('initial_factor', 0.07)
        
        # Max velocities (scaled by speed factor)
        self.base_max_linear = ps3_cfg.get('max_linear_mps', 3.5)
        self.base_max_angular = ps3_cfg.get('max_angular_dps', 120)
        self._update_scaled_params()
        
        # Deadzone
        self.deadzone = ps3_cfg.get('deadzone', 0.15)
        
        # Button and axis mapping
        button_map = ps3_cfg.get('button_mapping', {})
        axis_map = ps3_cfg.get('axis_mapping', {})
        
        self.btn_emergency_stop = button_map.get('emergency_stop', 0)
        self.axis_left_x = axis_map.get('left_x', 0)
        self.axis_left_y = axis_map.get('left_y', 1)
        self.axis_right_x = axis_map.get('right_x', 2)
        
        # Joystick state
        self.joystick = None
        self.connected = False
        
        # Initialize pygame joystick system
        pygame.joystick.init()
        self._detect_controller()
    
    def _update_scaled_params(self):
        """Update parameters based on current speed factor."""
        self.max_linear = self.base_max_linear * self.speed_factor
        self.max_angular = self.base_max_angular * self.speed_factor
    
    def _detect_controller(self):
        """Detect and initialize first available joystick."""
        joystick_count = pygame.joystick.get_count()
        
        if joystick_count == 0:
            logger.warning("Aucun joystick détecté")
            self.connected = False
            return False
        
        self.joystick = pygame.joystick.Joystick(0)
        self.joystick.init()
        self.connected = True
        
        logger.info(f"Joystick connecté : {self.joystick.get_name()}")
        logger.info(f"  Axes : {self.joystick.get_numaxes()}, Boutons : {self.joystick.get_numbuttons()}")
        
        return True
    
    def _apply_deadzone(self, value: float) -> float:
        """
        Applique la deadzone à la valeur de l'axe pour éliminer le drift.
        
        Args:
            value: Valeur brute de l'axe [-1, 1]
            
        Returns:
            Valeur corrigée avec deadzone appliquée
        """
        if abs(value) < self.deadzone:
            return 0.0
        
        # Rescale to maintain full range after deadzone
        sign = 1 if value > 0 else -1
        return sign * (abs(value) - self.deadzone) / (1.0 - self.deadzone)
    
    def set_speed_factor(self, factor: float):
        """
        Définit le facteur de vitesse.
        
        Args:
            factor: Nouveau facteur de vitesse
        """
        self.speed_factor = factor
        self._update_scaled_params()
        logger.info(f"Facteur de vitesse défini à {factor:.2f}")
    
    def update(self, events: list) -> None:
        """
        Met à jour le contrôleur basé sur l'entrée joystick.
        
        Args:
            events: Liste des événements pygame
        """
        if not self._enabled or not self.connected or self.joystick is None:
            self.linear_cmd = 0.0
            self.angular_cmd = 0.0
            return
        
        # Read analog stick axes
        axis_x = self.joystick.get_axis(self.axis_left_x)  # left/right
        axis_y = self.joystick.get_axis(self.axis_left_y)  # forward/backward
        
        # Apply deadzone
        axis_x = self._apply_deadzone(axis_x)
        axis_y = self._apply_deadzone(axis_y)
        
        # PS3 stick: up = negative value
        velocity_linear = -axis_y * self.max_linear
        
        # Direction correction for reverse (same as keyboard)
        direction_factor = -1 if velocity_linear < 0 else 1
        velocity_angular = -axis_x * self.max_angular * direction_factor
        
        # D-pad override (higher priority)
        try:
            if self.joystick.get_numhats() > 0:
                hat_x, hat_y = self.joystick.get_hat(0)
                
                # Forward/backward override
                if hat_y != 0:
                    velocity_linear = hat_y * self.max_linear
                    direction_factor = -1 if velocity_linear < 0 else 1
                
                # Left/right override
                if hat_x != 0:
                    velocity_angular = -hat_x * self.max_angular * direction_factor
        except Exception as e:
            logger.debug(f"D-pad read error: {e}")
        
        # Convert to ROS commands (m/s and rad/s)
        self.linear_cmd = velocity_linear * 0.1
        self.angular_cmd = math.radians(velocity_angular)
        
        # Handle events (emergency stop, hotplug)
        for event in events:
            if event.type == pygame.JOYBUTTONDOWN:
                if event.button == self.btn_emergency_stop:
                    self.emergency_stop()
            elif event.type == pygame.JOYDEVICEREMOVED:
                logger.warning("Joystick déconnecté")
                self.connected = False
                self.joystick = None
            elif event.type == pygame.JOYDEVICEADDED:
                logger.info("Nouveau joystick détecté")
                self._detect_controller()
    
    def get_command(self) -> Tuple[float, float]:
        """
        Obtient la commande de vitesse actuelle.
        
        Returns:
            Tuple de (vitesse_lineaire_m/s, vitesse_angulaire_rad/s)
        """
        if not self._enabled or not self.connected:
            return (0.0, 0.0)
        return (self.linear_cmd, self.angular_cmd)
    
    def emergency_stop(self) -> None:
        """Exécute l'arrêt d'urgence."""
        self.linear_cmd = 0.0
        self.angular_cmd = 0.0
        logger.warning("Arrêt d'urgence déclenché (PS3)")
    
    def is_connected(self) -> bool:
        """Vérifie si le joystick est connecté."""
        return self.connected


################################################################################
PATH: ./control_turtlebot/core/__init__.py
################################################################################
"""Core package for TurtleBot controller."""


################################################################################
PATH: ./control_turtlebot/core/networking/__init__.py
################################################################################
"""Networking module for WebSocket communication."""


################################################################################
PATH: ./control_turtlebot/DOCUMENTATION.md
################################################################################
# Control TurtleBot - Documentation

Interface de contrôle manuel pour piloter un robot TurtleBot via WebSocket.

## Architecture

```mermaid
flowchart TB
    subgraph INPUT["Entrées"]
        KB[Clavier<br/>WASD/Flèches]
        PS3[Manette PS3]
    end

    subgraph UI["IntegratedUI"]
        direction TB
        LOOP[Boucle Pygame]
        VR[VisualRobot]
        STATS[Panneau Stats]
    end

    subgraph WS["WebSocketClient"]
        QUEUE[Queue Envoi]
        RECV[Réception Async]
    end

    subgraph OUTPUT["Sortie"]
        ROS[Safety Bridge<br/>Port 8765]
    end

    KB --> LOOP
    PS3 --> LOOP
    LOOP --> QUEUE
    LOOP --> VR
    LOOP --> STATS
    QUEUE --> ROS
    ROS --> RECV
    RECV --> STATS
```

## Flux de Données

```mermaid
sequenceDiagram
    participant USER as Utilisateur
    participant UI as IntegratedUI
    participant WS as WebSocketClient
    participant BRIDGE as Safety Bridge

    USER->>UI: Input (clavier/manette)
    UI->>UI: Calcul vitesses (v, ω)
    UI->>WS: send_cmd_vel(linear_x, angular_z)
    WS->>BRIDGE: {"type": "cmd_vel", "linear_x": v, "angular_z": ω}
    BRIDGE->>WS: {"type": "cmd_accepted", ...}
    WS->>UI: Mise à jour stats
    UI->>UI: Rendu frame
```

## Protocole WebSocket

Le client envoie des messages JSON au Safety Bridge :

| Type             | Description      | Payload                 |
| ---------------- | ---------------- | ----------------------- |
| `cmd_vel`        | Commande vitesse | `linear_x`, `angular_z` |
| `emergency_stop` | Arrêt d'urgence  | -                       |
| `get_status`     | Demande status   | -                       |
| `ping`           | Test connexion   | `timestamp`             |

Réponses du serveur :

| Type           | Description                   |
| -------------- | ----------------------------- |
| `connected`    | Message d'accueil avec config |
| `cmd_accepted` | Confirmation commande         |
| `cmd_rejected` | Commande refusée              |
| `pong`         | Réponse ping                  |

## Configuration

### network.yaml
```yaml
websocket:
  uri: "ws://localhost:8765"
  reconnect_delay_s: 2.0

command:
  frequency_hz: 30
  k_linear: 6.0   # Amplification linéaire
  k_angular: 4.0  # Amplification angulaire
```

### ui.yaml
Paramètres d'interface : dimensions, couleurs, polices.

### controls.yaml
Mapping des touches clavier et boutons manette.

## Structure des Fichiers

```
control_turtlebot/
├── main.py                 # Point d'entrée
├── integrated_ui.py        # Interface Pygame principale
├── websocket_client.py     # Client WebSocket async
├── keyboard_controller.py  # Contrôle clavier
├── ps3_controller.py       # Contrôle manette PS3
├── visual_robot.py         # Représentation visuelle robot
├── config.py              # Constantes et thème
└── config/
    ├── network.yaml       # Configuration réseau
    ├── ui.yaml            # Configuration interface
    ├── controls.yaml      # Mapping contrôles
    └── robot.yaml         # Paramètres robot
```

## Lancement

```bash
cd control_turtlebot
python3 main.py
```

Prérequis : Safety Bridge actif sur `ws://localhost:8765`.


################################################################################
PATH: ./control_turtlebot/integrated_ui.py
################################################################################
#!/usr/bin/env python3
"""
Interface graphique integree pour TurtleBot Controller.

Ce module fournit une interface utilisateur moderne basee sur Pygame
pour controler le TurtleBot. Il inclut un panneau de simulation visuelle,
un panneau de statistiques, et supporte les controleurs clavier et PS3.

Classes:
    IntegratedUI: Interface graphique principale avec simulation et stats.
"""

import pygame
import math
import time

import config  # Chargement du thème
from websocket_client import WebSocketClient
from keyboard_controller import KeyboardController
from ps3_controller import PS3Controller
from visual_robot import VisualRobot


# ============================================================
# Outils internes : interpolation / pulse
# ============================================================

def lerp(a, b, t):
    """Interpolation linéaire"""
    return a + (b - a) * t


# ============================================================
#                   CLASS INTEGRATED UI
# ============================================================

class IntegratedUI:
    """Interface graphique TurtleBot moderne (Pygame)"""

    # -----------------------------------------------------
    #  INITIALISATION
    # -----------------------------------------------------
    def __init__(self, width=None, height=None, ws_uri=None):
        pygame.init()

        ui_cfg = config.get_ui_config()

        # Dimensions : priorité aux paramètres envoyés à __init__
        self.width = width if width is not None else ui_cfg['default_width']
        self.height = height if height is not None else ui_cfg['default_height']
        self.info_width = ui_cfg['info_panel_width']

        # WebSocket URI : priorité au paramètre constructor
        self.ws_uri = ws_uri if ws_uri is not None else config.WEBSOCKET_URI

        self.screen = pygame.display.set_mode(
            (self.width, self.height), pygame.RESIZABLE
        )
        pygame.display.set_caption("TurtleBot Control - UI")

        self.clock = pygame.time.Clock()

        # Thème moderne (couleurs + polices)
        self.load_theme()

        # WebSocket client
        self.ws_client = WebSocketClient(self.ws_uri)

        # Layout
        self.update_layout(self.width, self.height)

        # Robot visuel
        cx = self.sim_rect.centerx
        cy = self.sim_rect.centery
        self.visual_robot = VisualRobot(cx, cy, 0)

        # Contrôleurs
        ctrl_cfg = config.get_controller_config()
        self.keyboard_controller = KeyboardController(
            vitesse_factor=ctrl_cfg["initial_speed_factor"]
        )
        self.ps3_controller = PS3Controller(
            vitesse_factor=ctrl_cfg["initial_speed_factor"]
        )

        # Auto-detection manette
        self.control_mode = "ps3" if self.ps3_controller.is_connected() else "keyboard"

        self.last_status_request = 0


    # -----------------------------------------------------
    #  CHARGEMENT DU THÈME (couleurs + polices)
    # -----------------------------------------------------
    def load_theme(self):
        colors = config.get_color_scheme()

        # Couleurs
        self.bg_color = colors["bg"]
        self.panel_color = colors["panel"]
        self.panel_accent = colors["panel_accent"]
        self.text_color = colors["text"]
        self.text_dim = colors["text_dim"]
        self.text_bright = colors["text_bright"]
        self.accent_color = colors["accent"]
        self.accent_bright = colors["accent_bright"]
        self.accent_dim = colors["accent_dim"]
        self.success_color = colors["success"]
        self.warning_color = colors["warning"]
        self.error_color = colors["error"]

        # Polices Roboto modernisées
        # -----------------------------------------------------
        #  Polices (avec fallback automatique)
        # -----------------------------------------------------
        def safe_font(path, size):
            """Charge une police, ou fallback sur la police par défaut."""
            try:
                return pygame.font.Font(path, size)
            except FileNotFoundError:
                print(f"[UI] Police introuvable : {path} - utilisation de la police par defaut.")
                return pygame.font.Font(None, size)

        # Polices Roboto (si absentes -> police par defaut)
        self.font_titre = safe_font("assets/Roboto-Bold.ttf", config.FONT_SIZE_TITLE)
        self.font_sub = safe_font("assets/Roboto-Medium.ttf", config.FONT_SIZE_SUBTITLE)
        self.font_normal = safe_font("assets/Roboto-Regular.ttf", config.FONT_SIZE_NORMAL)
        self.font_small = safe_font("assets/Roboto-Light.ttf", config.FONT_SIZE_SMALL)
        self.font_tiny = safe_font("assets/Roboto-Light.ttf", config.FONT_SIZE_TINY)

    # -----------------------------------------------------
    #  MISE EN PAGE
    # -----------------------------------------------------
    def update_layout(self, width, height):
        self.width = width
        self.height = height

        self.sim_rect = pygame.Rect(
            10, 10, width - self.info_width - 30, height - 20
        )
        self.info_rect = pygame.Rect(
            width - self.info_width, 10, self.info_width - 10, height - 20
        )

        # Recentre le robot si déjà présent
        if hasattr(self, "visual_robot"):
            self.visual_robot.rest_x = self.sim_rect.centerx
            self.visual_robot.rest_y = self.sim_rect.centery
            self.visual_robot.reset_position()

    # -----------------------------------------------------
    #  EFFETS MODERNES : ombres, sous-panneaux, titres, pulse
    # -----------------------------------------------------

    def draw_shadow(self, rect, size=12):
        """Ombre portée moderne"""
        shadow = pygame.Surface((rect.width, rect.height), pygame.SRCALPHA)
        pygame.draw.rect(shadow, config.COLOR_SHADOW, shadow.get_rect(), border_radius=12)
        self.screen.blit(shadow, (rect.x + size, rect.y + size))

    def draw_subpanel(self, x, y, w, h, radius=12):
        """Sous-panneau semi-transparent"""
        surf = pygame.Surface((w, h), pygame.SRCALPHA)
        pygame.draw.rect(surf, (self.panel_accent[0], self.panel_accent[1], self.panel_accent[2], 90),
                         (0, 0, w, h), border_radius=radius)
        self.screen.blit(surf, (x, y))
        return pygame.Rect(x, y, w, h)

    def draw_title(self, text, x, y, color=None):
        """Titre moderne + ligne accent"""
        if color is None:
            color = self.accent_color

        surf = self.font_sub.render(text, True, color)
        self.screen.blit(surf, (x, y))

        pygame.draw.line(self.screen, color, (x, y + 32), (x + 220, y + 32), 3)

        return y + 50

    def pulse_color(self, base_color):
        """Couleur pulsante douce pour l'État connexion, FPS…"""
        pulse = (math.sin(time.time() * config.ANIMATION_PULSE_SPEED) + 1) / 2
        factor = lerp(0.75, 1.25, pulse)
        return tuple(min(int(c * factor), 255) for c in base_color)

    # -----------------------------------------------------
    #  PANNEAU STATS (VERSION MODERNE)
    # -----------------------------------------------------
    def draw_stats_panel(self, stats):

        # Ombre + panneau principal
        self.draw_shadow(self.info_rect)
        pygame.draw.rect(self.screen, self.panel_color, self.info_rect, border_radius=14)

        x = self.info_rect.x + 20
        y = self.info_rect.y + 20

        # --- Section ROS BRIDGE ---
        y = self.draw_title("ROS BRIDGE", x, y)

        sub = self.draw_subpanel(x, y, self.info_rect.width - 40, 110)
        y += 20

        # Connexion animée
        ccol = self.pulse_color(self.success_color) if stats["connected"] else self.error_color
        pygame.draw.circle(self.screen, ccol, (x + 20, y + 12), 10)

        label = "CONNECTÉ" if stats["connected"] else "DÉCONNECTÉ"
        self.screen.blit(self.font_normal.render(label, True, ccol), (x + 45, y))

        y += 40

        # Mode de controle
        mode = "Manette PS3" if self.control_mode == "ps3" else "Clavier"
        mcol = self.accent_bright if self.control_mode == "ps3" else self.text_color

        self.screen.blit(
            self.font_small.render("Mode : " + mode, True, mcol),
            (x + 20, y)
        )

        y += 70

        # --- Section statistiques ---
        y = self.draw_title("STATISTIQUES", x, y)

        sub = self.draw_subpanel(x, y, self.info_rect.width - 40, 160)
        y += 20

        stats_items = [
            ("Envoyées", stats["sent"], self.text_color),
            ("Acceptées", stats["accepted"], self.success_color),
            ("Rejetées", stats["rejected"],
             self.error_color if stats["rejected"] else self.text_dim),
            ("Succès", f"{stats['success_rate']*100:.1f}%",
             self.success_color),
        ]

        for label, value, col in stats_items:
            self.screen.blit(self.font_small.render(f"{label} :", True, self.text_dim), (x + 20, y))
            self.screen.blit(self.font_small.render(str(value), True, col), (x + 160, y))
            y += 28

        y += 20

        # --- Section sécurité ---
        y = self.draw_title("SÉCURITÉ", x, y)

        sub = self.draw_subpanel(x, y, self.info_rect.width - 40, 100)
        y += 20

        safety = stats.get("safety_info", {})
        if safety.get("current_pose"):
            px, py, pa = safety["current_pose"]
            self.screen.blit(self.font_small.render(f"Pos: ({px:.2f}, {py:.2f})",
                                                    True, self.text_color),
                             (x + 20, y))
            y += 25
            self.screen.blit(
                self.font_small.render(f"Angle: {math.degrees(pa):.1f}°",
                                       True, self.text_color),
                (x + 20, y)
            )

        # --- FPS ---
        sub = self.draw_subpanel(x, self.info_rect.bottom - 140,
                                 self.info_rect.width - 40, 120)

        fps = self.clock.get_fps()
        fps_color = self.pulse_color(
            self.success_color if fps > 55 else
            self.warning_color if fps > 30 else
            self.error_color
        )

        self.screen.blit(self.font_sub.render(f"{fps:.1f} FPS", True, fps_color),
                         (x + 30, self.info_rect.bottom - 110))

    # -----------------------------------------------------
    #  PANNEAU SIMULATION (inchangé + couleurs modernisées)
    # -----------------------------------------------------
    def draw_simulation_panel(self, linear_x, angular_z):
        pygame.draw.rect(self.screen, self.panel_color, self.sim_rect, border_radius=14)
        pygame.draw.rect(self.screen, self.accent_dim, self.sim_rect, 2, border_radius=14)

        cx, cy = self.sim_rect.center

        # Titre
        mode_icon = "[PS3]" if self.control_mode == "ps3" else "[KB]"
        surf = self.font_titre.render(f"MICRO-SIMULATION {mode_icon}", True, self.accent_bright)
        rect = surf.get_rect(center=(cx, self.sim_rect.y + 40))
        self.screen.blit(surf, rect)

        # Grille
        spacing = 50
        gc = config.COLOR_GRID
        for i in range(self.sim_rect.left + 20, self.sim_rect.right - 20, spacing):
            pygame.draw.line(self.screen, gc,
                             (i, self.sim_rect.top + 80),
                             (i, self.sim_rect.bottom - 80), 1)

        for i in range(self.sim_rect.top + 80, self.sim_rect.bottom - 80, spacing):
            pygame.draw.line(self.screen, gc,
                             (self.sim_rect.left + 20, i),
                             (self.sim_rect.right - 20, i), 1)

        # Robot
        self.visual_robot.draw(self.screen, scale=1.0)

        # Messages de vitesse
        info_y = self.sim_rect.y + 80

        if abs(linear_x) > 0.01:
            col = self.success_color if linear_x > 0 else self.warning_color
            direction = "Avant" if linear_x > 0 else "Arrière"
            msg = f"{direction}: {abs(linear_x):.3f} m/s"
            surf = self.font_normal.render(msg, True, col)
            self.screen.blit(surf, surf.get_rect(center=(cx, info_y)))

        if abs(angular_z) > 0.01:
            col = self.accent_color
            direction = "Gauche" if angular_z > 0 else "Droite"
            msg = f"Rotation {direction}: {abs(angular_z):.3f} rad/s"
            surf = self.font_normal.render(msg, True, col)
            self.screen.blit(surf,
                             surf.get_rect(center=(cx, self.sim_rect.bottom - 60)))

        # Mode inactif
        if abs(linear_x) < 0.01 and abs(angular_z) < 0.01:
            dist = math.dist((self.visual_robot.x, self.visual_robot.y),
                             (self.visual_robot.rest_x, self.visual_robot.rest_y))

            if dist < 2:
                surf = self.font_titre.render("EN ATTENTE", True, self.text_dim)
                self.screen.blit(surf, surf.get_rect(center=(cx, cy - 60)))

                hint = "Flèches / WASD" if self.control_mode == "keyboard" else "Stick gauche"
                surf = self.font_small.render(hint, True, self.text_dim)
                self.screen.blit(surf, surf.get_rect(center=(cx, cy + 80)))
            else:
                surf = self.font_small.render("Retour au centre…", True, self.warning_color)
                self.screen.blit(surf, surf.get_rect(center=(cx, cy - 80)))

    # -----------------------------------------------------
    #  BOUCLE PRINCIPALE
    # -----------------------------------------------------
    def run(self):

        # Connexion WebSocket
        if not self.ws_client.start():
            print("[UI] Impossible de se connecter au ROS Bridge.")
            return

        running = True
        cmd_freq = config.COMMAND_FREQUENCY
        cmd_interval = 1.0 / cmd_freq
        last_cmd_time = time.time()

        while running:

            dt = self.clock.get_time() / 1000.0

            # ---------------- ÉVÉNEMENTS ----------------
            for event in pygame.event.get():

                if event.type == pygame.QUIT:
                    running = False

                elif event.type == pygame.VIDEORESIZE:
                    self.update_layout(event.w, event.h)

                elif event.type == pygame.KEYDOWN:
                    if event.key in (pygame.K_ESCAPE, pygame.K_q):
                        running = False

                    elif event.key == pygame.K_m:
                        if self.control_mode == "keyboard" and self.ps3_controller.is_connected():
                            self.control_mode = "ps3"
                        else:
                            self.control_mode = "keyboard"

                    elif event.key == pygame.K_c:
                        self.visual_robot.reset_trail()

                    # Vitesse
                    if event.key in (pygame.K_EQUALS, pygame.K_KP_PLUS):
                        new = min(config.MAX_SPEED_FACTOR,
                                  self.keyboard_controller.vitesse_factor + config.SPEED_INCREMENT)
                        self.keyboard_controller.set_vitesse_factor(new)
                        self.ps3_controller.set_vitesse_factor(new)

                    if event.key in (pygame.K_MINUS, pygame.K_KP_MINUS):
                        new = max(config.MIN_SPEED_FACTOR,
                                  self.keyboard_controller.vitesse_factor - config.SPEED_INCREMENT)
                        self.keyboard_controller.set_vitesse_factor(new)
                        self.ps3_controller.set_vitesse_factor(new)

            # ------------ MISE À JOUR CONTRÔLES ----------
            if self.control_mode == "keyboard":
                keys = pygame.key.get_pressed()
                linear_x, angular_z, _ = self.keyboard_controller.update(keys)
            else:
                linear_x, angular_z, _ = self.ps3_controller.update()

            # Simulation robot
            self.visual_robot.update(linear_x, angular_z, dt)

            # Envoi cmd_vel à 30 Hz
            now = time.time()
            if now - last_cmd_time >= cmd_interval:
                if self.ws_client.connected:
                    self.ws_client.send_cmd_vel(linear_x, angular_z)
                last_cmd_time = now

            # Status régulier
            if now - self.last_status_request >= config.STATUS_UPDATE_INTERVAL:
                self.ws_client.request_status()
                self.last_status_request = now

            # ------------------- RENDU -------------------
            self.screen.fill(self.bg_color)

            stats = self.ws_client.get_stats()
            self.draw_stats_panel(stats)
            self.draw_simulation_panel(linear_x, angular_z)

            pygame.display.flip()
            self.clock.tick(config.TARGET_FPS)

        pygame.quit()


################################################################################
PATH: ./control_turtlebot/keyboard_controller.py
################################################################################
#!/usr/bin/env python3
"""
Module Keyboard Controller
"""

import pygame
import math
import config


class KeyboardController:
    """Contrôleur clavier configurable pour TurtleBot"""

    def __init__(self, vitesse_factor=None):

        cfg = config.get_keyboard_config()

        # Facteur de vitesse initial
        self.vitesse_factor = (
            vitesse_factor if vitesse_factor is not None
            else config.INITIAL_SPEED_FACTOR
        )

        # États internes
        self.vitesse_lineaire = 0.0
        self.vitesse_angulaire = 0.0
        self.tir_demande = False

        # Paramètres dépendant du facteur
        self.accel_lineaire = cfg["accel_linear"] * self.vitesse_factor
        self.accel_angulaire = cfg["accel_angular"] * self.vitesse_factor

        self.vitesse_max_lineaire = cfg["max_linear"] * self.vitesse_factor
        self.vitesse_max_angulaire = cfg["max_angular"] * self.vitesse_factor

        self.friction = cfg["friction"]
        self.friction_angulaire = cfg["friction_angular"]

    # ============================================================
    #   MISE À JOUR DU FACTEUR DE VITESSE (+ et -)
    # ============================================================
    def set_vitesse_factor(self, factor):

        ratio = factor / self.vitesse_factor
        self.vitesse_factor = factor

        cfg = config.get_keyboard_config()

        # Recalcul des paramètres
        self.accel_lineaire = cfg["accel_linear"] * factor
        self.accel_angulaire = cfg["accel_angular"] * factor
        self.vitesse_max_lineaire = cfg["max_linear"] * factor
        self.vitesse_max_angulaire = cfg["max_angular"] * factor

        # Ajustement des vitesses actuelles
        self.vitesse_lineaire *= ratio
        self.vitesse_angulaire *= ratio

    # ============================================================
    #   MISE À JOUR DES MOUVEMENTS
    # ============================================================
    def update(self, touches):

        self.tir_demande = False

        # ----------------- CONTRÔLE LINÉAIRE -----------------
        if touches[pygame.K_UP] or touches[pygame.K_w]:
            self.vitesse_lineaire = min(
                self.vitesse_lineaire + self.accel_lineaire,
                self.vitesse_max_lineaire
            )

        elif touches[pygame.K_DOWN] or touches[pygame.K_s]:
            self.vitesse_lineaire = max(
                self.vitesse_lineaire - self.accel_lineaire,
                -self.vitesse_max_lineaire
            )

        else:
            # friction linéaire
            self.vitesse_lineaire *= self.friction
            if abs(self.vitesse_lineaire) < 0.05:
                self.vitesse_lineaire = 0

        # ----------------- CONTRÔLE ANGULAIRE -----------------
        gauche  = touches[pygame.K_LEFT] or touches[pygame.K_a]
        droite  = touches[pygame.K_RIGHT] or touches[pygame.K_d]
        avant   = touches[pygame.K_UP] or touches[pygame.K_w]
        arriere = touches[pygame.K_DOWN] or touches[pygame.K_s]

        # Correction du bug : inversion du sens en marche arrière
        direction_factor = -1 if self.vitesse_lineaire < 0 else 1

        if gauche and droite:
            if avant:
                self.vitesse_angulaire = self.vitesse_max_angulaire
            elif arriere:
                self.vitesse_angulaire = -self.vitesse_max_angulaire
            else:
                self.vitesse_angulaire *= self.friction_angulaire

        elif gauche:
            intensite = 1.0 + abs(self.vitesse_lineaire) * 0.3
            self.vitesse_angulaire = max(
                self.vitesse_angulaire - self.accel_angulaire * intensite * direction_factor,
                -self.vitesse_max_angulaire * 0.6
            )

        elif droite:
            intensite = 1.0 + abs(self.vitesse_lineaire) * 0.3
            self.vitesse_angulaire = min(
                self.vitesse_angulaire + self.accel_angulaire * intensite * direction_factor,
                self.vitesse_max_angulaire * 0.6
            )

        else:
            # friction angulaire
            self.vitesse_angulaire *= self.friction_angulaire
            if abs(self.vitesse_angulaire) < 0.2:
                self.vitesse_angulaire = 0

        # ----------------- CONVERSION POUR ROS -----------------
        linear_x = self.vitesse_lineaire * 0.1
        angular_z = math.radians(self.vitesse_angulaire)

        return linear_x, angular_z, self.tir_demande

    # ============================================================
    #   ÉVÉNEMENTS (ARRÊT D'URGENCE)
    # ============================================================
    def handle_event(self, event):
        if event.type == pygame.KEYDOWN:
            if event.key == pygame.K_SPACE:
                self.tir_demande = True
                return True
        return False


################################################################################
PATH: ./control_turtlebot/main.py
################################################################################
#!/usr/bin/env python3
"""
TurtleBot Controller - Point d'Entrée Principal

Interface professionnelle basée sur Pygame pour le contrôle manuel du robot via WebSocket.
"""

import sys
import logging
from pathlib import Path

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(levelname)s] %(name)s: %(message)s'
)

logger = logging.getLogger(__name__)


def main():
    """Point d'entrée principal."""
    try:
        # Add current directory to path for imports
        sys.path.insert(0, str(Path(__file__).parent))
        
        # Import after path setup
        from utils.config_loader import ConfigLoader
        
        logger.info("=" * 60)
        logger.info(" TurtleBot Controller")
        logger.info("=" * 60)
        
        # Charge toutes les configurations
        logger.info("Chargement de la configuration...")
        config_loader = ConfigLoader()
        
        try:
            all_config = config_loader.load_all()
            logger.info(f"Chargé {len(all_config)} fichiers de configuration")
        except Exception as e:
            logger.error(f"Échec du chargement de la configuration : {e}")
            logger.error("Veuillez vérifier que le répertoire config/ contient des fichiers YAML valides")
            return 1
        
        # Import and launch UI
        from integrated_ui import IntegratedUI
        
        logger.info("Configuration chargée avec succès !")
        logger.info("")
        logger.info("Résumé de la configuration :")
        for name, cfg in all_config.items():
            logger.info("  - %s.yaml: %d clés de premier niveau", name, len(cfg))
        
        logger.info("")
        logger.info("Lancement de l'interface intégrée...")
        
        # Obtient la configuration UI
        ui_cfg = all_config.get('ui', {})
        network_cfg = all_config.get('network', {})
        
        # Construit l'URI WebSocket depuis la config (network.yaml a 'uri' directement)
        ws_cfg = network_cfg.get('websocket', {})
        ws_uri = ws_cfg.get('uri', 'ws://localhost:8765')
        
        # Crée et lance l'interface
        ui = IntegratedUI(
            width=ui_cfg.get('default_width', 1400),
            height=ui_cfg.get('default_height', 900),
            ws_uri=ws_uri
        )
        ui.run()
        
        logger.info("Interface fermée normalement")
        return 0
        
    except KeyboardInterrupt:
        logger.info("Interrompu par l'utilisateur (Ctrl+C)")
        return 0
        
    except Exception as e:
        logger.error(f"Erreur fatale : {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())

################################################################################
PATH: ./control_turtlebot/ps3_controller.py
################################################################################
#!/usr/bin/env python3
"""
Controleur manette PS3 pour TurtleBot.

Ce module gere les entrees d'une manette de jeu PS3 (ou compatible)
et les convertit en commandes de vitesse pour le robot. Il supporte
la detection automatique, la gestion des zones mortes (deadzone),
et les boutons speciaux (arret d'urgence).

Classes:
    PS3Controller: Controleur manette PS3 configurable.
"""

import pygame
import math
import config


class PS3Controller:
    """Contrôleur manette PS3 configurable pour TurtleBot"""

    def __init__(self, vitesse_factor=None):

        # Charger config PS3
        cfg = config.get_ps3_config()

        self.vitesse_factor = (
            vitesse_factor if vitesse_factor is not None
            else config.INITIAL_SPEED_FACTOR
        )

        self.joystick = None
        self.connected = False
        self.tir_demande = False

        # Deadzone depuis config
        self.deadzone = cfg["deadzone"]

        # Vitesse max depuis config (scalée par vitesse_factor)
        self.vitesse_max_lineaire = cfg["max_linear"] * self.vitesse_factor
        self.vitesse_max_angulaire = cfg["max_angular"] * self.vitesse_factor

        # Mapping boutons (configurable)
        self.BTN_X = cfg["btn_x"]
        self.BTN_CIRCLE = cfg["btn_circle"]
        self.BTN_TRIANGLE = cfg["btn_triangle"]
        self.BTN_SQUARE = cfg["btn_square"]

        # Mapping axes
        self.AXIS_LEFT_X = cfg["axis_left_x"]
        self.AXIS_LEFT_Y = cfg["axis_left_y"]
        self.AXIS_RIGHT_X = cfg["axis_right_x"]

        # Init manette pygame
        pygame.joystick.init()
        self._detect_controller()


    # ================================================================
    #   Détection et gestion du joystick
    # ================================================================
    def _detect_controller(self):
        """Détecte et initialise la première manette disponible."""
        joystick_count = pygame.joystick.get_count()

        if joystick_count == 0:
            print("[PS3] Aucune manette detectee")
            self.connected = False
            return False

        self.joystick = pygame.joystick.Joystick(0)
        self.joystick.init()

        self.connected = True
        print(f"[PS3] Manette connectee : {self.joystick.get_name()}")
        print(f"   Axes: {self.joystick.get_numaxes()}")
        print(f"   Boutons: {self.joystick.get_numbuttons()}")

        return True


    # ================================================================
    #   Ajustement dynamique du facteur de vitesse (+ / -)
    # ================================================================
    def set_vitesse_factor(self, factor):

        ratio = factor / self.vitesse_factor
        self.vitesse_factor = factor

        cfg = config.get_ps3_config()

        self.vitesse_max_lineaire = cfg["max_linear"] * factor
        self.vitesse_max_angulaire = cfg["max_angular"] * factor


    # ================================================================
    #   Deadzone
    # ================================================================
    def _apply_deadzone(self, value):
        """Supprime le drift du joystick."""
        if abs(value) < self.deadzone:
            return 0.0

        sign = 1 if value > 0 else -1
        return sign * (abs(value) - self.deadzone) / (1.0 - self.deadzone)


    # ================================================================
    #   Mise à jour des commandes
    # ================================================================
    def update(self):
        """Retourne (linear_x, angular_z, tir)"""

        if not self.connected or self.joystick is None:
            return 0, 0, False

        self.tir_demande = False

        # ----------------------------------------------------------
        #  Lecture des axes (stick gauche)
        # ----------------------------------------------------------
        axis_x = self.joystick.get_axis(self.AXIS_LEFT_X)  # gauche/droite
        axis_y = self.joystick.get_axis(self.AXIS_LEFT_Y)  # avant/arrière

        # Deadzone
        axis_x = self._apply_deadzone(axis_x)
        axis_y = self._apply_deadzone(axis_y)

        # Stick PS3 : vers le haut = valeur négative
        vitesse_lineaire = -axis_y * self.vitesse_max_lineaire

        # Correction du bug de rotation inversee (meme logique que clavier)
        direction_factor = -1 if vitesse_lineaire < 0 else 1

        vitesse_angulaire = -axis_x * self.vitesse_max_angulaire * direction_factor

        # ----------------------------------------------------------
        #  D-pad override (haut / bas / gauche / droite)
        # ----------------------------------------------------------
        try:
            if self.joystick.get_numhats() > 0:
                hat_x, hat_y = self.joystick.get_hat(0)

                # Avant / arrière
                if hat_y != 0:
                    vitesse_lineaire = hat_y * self.vitesse_max_lineaire

                # Gauche / droite
                if hat_x != 0:
                    vitesse_angulaire = -hat_x * self.vitesse_max_angulaire * direction_factor

        except Exception:
            pass

        # ----------------------------------------------------------
        # Conversion ROS
        # ----------------------------------------------------------
        linear_x = vitesse_lineaire * 0.1
        angular_z = math.radians(vitesse_angulaire)

        return linear_x, angular_z, self.tir_demande


    # ================================================================
    #   Gestion des événements
    # ================================================================
    def handle_event(self, event):

        if not self.connected:
            return False

        # Bouton X  arrêt d’urgence
        if event.type == pygame.JOYBUTTONDOWN:
            if event.button == self.BTN_X:
                self.tir_demande = True
                print(" PS3: Bouton X  ARRÊT D’URGENCE")
                return True

        # Deconnexion
        if event.type == pygame.JOYDEVICEREMOVED:
            print("[PS3] Manette deconnectee")
            self.connected = False
            self.joystick = None

        # Connexion d’une nouvelle manette
        if event.type == pygame.JOYDEVICEADDED:
            print("[PS3] Nouvelle manette detectee")
            self._detect_controller()

        return False


    # ================================================================
    #   Statut de connexion
    # ================================================================
    def is_connected(self):
        """Retourne True si une manette est connectée."""
        return self.connected


################################################################################
PATH: ./control_turtlebot/README.md
################################################################################
# Control TurtleBot

Interface Pygame professionnelle pour contrôle manuel du robot TurtleBot via WebSocket.

## Lancement

```bash
cd control_turtlebot
python3 main.py
```

Ou via le script unifié :
```bash
./launch_game.sh --control
```

## Structure

```
control_turtlebot/
├── main.py               # Point d'entrée
├── integrated_ui.py      # Interface Pygame
├── websocket_client.py   # Client WebSocket async
├── keyboard_controller.py
├── ps3_controller.py
├── visual_robot.py
└── config/
    ├── network.yaml      # URI WebSocket (port 8765)
    ├── ui.yaml           # Interface
    └── controls.yaml     # Mapping touches
```

## Configuration Réseau

```yaml
# config/network.yaml
websocket:
  uri: "ws://localhost:8765"
```

## Contrôles

### Clavier
| Touche | Action                         |
| ------ | ------------------------------ |
| `W/↑`  | Avancer                        |
| `S/↓`  | Reculer                        |
| `A/←`  | Tourner gauche                 |
| `D/→`  | Tourner droite                 |
| `+/-`  | Ajuster vitesse                |
| `M`    | Changer mode (clavier/manette) |
| `ESC`  | Quitter                        |

### Manette PS3
- Stick gauche : Déplacement
- L2/R2 : Vitesse

## Protocole

Envoie au Safety Bridge :
```json
{"type": "cmd_vel", "linear_x": 0.2, "angular_z": 0.5}
```

Voir [DOCUMENTATION.md](DOCUMENTATION.md) pour les détails.


################################################################################
PATH: ./control_turtlebot/requirements.txt
################################################################################
# TurtleBot Controller - Python Dependencies

# Core dependencies
pygame>=2.0.0
pyyaml>=5.4.0

# Networking
websockets>=10.0

# Scientific
numpy>=1.20.0


################################################################################
PATH: ./control_turtlebot/ui/__init__.py
################################################################################
"""UI module for Pygame rendering."""


################################################################################
PATH: ./control_turtlebot/ui/theme.py
################################################################################
"""Gestion du thème UI pour un style professionnel."""

import pygame
from dataclasses import dataclass
from typing import Tuple, Dict
from pathlib  import Path
import logging

logger = logging.getLogger(__name__)


@dataclass
class ColorScheme:
    """Schéma de couleurs professionnel."""
    background: Tuple[int, int, int]
    panel: Tuple[int, int, int]
    panel_accent: Tuple[int, int, int]
    text: Tuple[int, int, int]
    text_dim: Tuple[int, int, int]
    text_bright: Tuple[int, int, int]
    accent: Tuple[int, int, int]
    accent_bright: Tuple[int, int, int]
    accent_dim: Tuple[int, int, int]
    success: Tuple[int, int, int]
    warning: Tuple[int, int, int]
    error: Tuple[int, int, int]
    info: Tuple[int, int, int]
    grid: Tuple[int, int, int]


class Theme:
    """
    Thème UI avec couleurs et polices.
    
    Fournit un style cohérent à travers l'application.
    """
    
    def __init__(self, config: Dict):
        """
        Initialise le thème depuis la configuration.
        
        Args:
            config: Dictionnaire de configuration UI
        """
        theme_cfg = config.get('theme', {})
        font_cfg = config.get('fonts', {})
        
        # Create color scheme from config
        colors_dict = theme_cfg.get('colors', {})
        self.colors = ColorScheme(
            background=tuple(colors_dict.get('background', [15, 15, 20])),
            panel=tuple(colors_dict.get('panel', [25, 28, 35])),
            panel_accent=tuple(colors_dict.get('panel_accent', [35, 40, 50])),
            text=tuple(colors_dict.get('text', [230, 230, 235])),
            text_dim=tuple(colors_dict.get('text_dim', [150, 150, 160])),
            text_bright=tuple(colors_dict.get('text_bright', [255, 255, 255])),
            accent=tuple(colors_dict.get('accent', [0, 180, 220])),
            accent_bright=tuple(colors_dict.get('accent_bright', [80, 200, 240])),
            accent_dim=tuple(colors_dict.get('accent_dim', [0, 140, 180])),
            success=tuple(colors_dict.get('success', [50, 200, 100])),
            warning=tuple(colors_dict.get('warning', [200, 150, 0])),
            error=tuple(colors_dict.get('error', [200, 50, 50])),
            info=tuple(colors_dict.get('info', [120, 150, 255])),
            grid=tuple(colors_dict.get('grid', [35, 38, 45]))
        )
        
        theme_cfg = config.get('theme', {})
        font_cfg = config.get('fonts', {})
        
        # Crée le schéma de couleurs depuis la config
        self.fonts = self._load_fonts(font_cfg)
        
        logger.info(f"Theme loaded: {theme_cfg.get('name', 'unnamed')}")
    
    def _load_fonts(self, font_cfg: Dict) -> Dict[str, pygame.font.Font]:
        """
        Load fonts with fallback to default.
        
        Args:
            font_cfg: Font configuration dictionary
            
        Returns:
            Dictionary of font name to pygame.font.Font
        """
        fonts = {}
        
        # Font sizes from config (already english code keywords)
        sizes = {
            'title': font_cfg.get('title_size', 32),
            'subtitle': font_cfg.get('subtitle_size', 24),
            'normal': font_cfg.get('normal_size', 20),
            'small': font_cfg.get('small_size', 16),
            'tiny': font_cfg.get('tiny_size', 14)
        }
        
        # Essaie de charger police perso, repli sur defaut
        font_path = font_cfg.get('font_file', None)
        
        for name, size in sizes.items():
            try:
                if font_path and Path(font_path).exists():
                    fonts[name] = pygame.font.Font(font_path, size)
                else:
                    fonts[name] = pygame.font.SysFont('Arial', size, bold=(name == 'title'))
            except Exception as e:
                logger.warning(f"Échec chargement police '{name}' : {e}")
                fonts[name] = pygame.font.SysFont(None, size)
        
        return fonts
    
    def get_font(self, size: str = 'normal') -> pygame.font.Font:
        """
        Obtient la police par nom de taille.
        
        Args:
            size: Nom taille police ('title', 'subtitle', 'normal', 'small', 'tiny')
            
        Returns:
            Objet police Pygame
        """
        return self.fonts.get(size, self.fonts['normal'])
    
    def draw_rounded_rect(self, surface: pygame.Surface, rect: pygame.Rect, 
                         color: Tuple[int, int, int], radius: int = 12):
        """
        Draw a rounded rectangle.
        
        Args:
            surface: Surface to draw on
            rect: Rectangle to draw
            color: Fill color
            radius: Corner radius in pixels
        """
        pygame.draw.rect(surface, color, rect, border_radius=radius)
    
    def draw_panel(self, surface: pygame.Surface, rect: pygame.Rect, 
                  accent: bool = False, radius: int = 12):
        """
        Dessine un panneau stylisé.
        
        Args:
            surface: Surface sur laquelle dessiner
            rect: Rectangle panneau
            accent: Si True, utilise couleur accent
            radius: Rayon coins
        """
        color = self.colors.panel_accent if accent else self.colors.panel
        self.draw_rounded_rect(surface, rect, color, radius)
    
    def render_text(self, text: str, font_size: str = 'normal', 
                    color: Tuple[int, int, int] = None) -> pygame.Surface:
        """
        Rend le texte avec la police du thème.
        
        Args:
            text: Texte à rendre
            font_size: Nom taille police
            color: Couleur texte (défaut: couleur texte thème)
            
        Returns:
            Surface texte rendu
        """
        if color is None:
            color = self.colors.text
        
        font = self.get_font(font_size)
        return font.render(text, True, color)


################################################################################
PATH: ./control_turtlebot/utils/config_loader.py
################################################################################
"""Utilitaire de chargement de configuration pour les fichiers YAML."""

import yaml
from pathlib import Path
from typing import Dict, Any
import logging

logger = logging.getLogger(__name__)


class ConfigLoader:
    """Charge et gère les fichiers de configuration YAML."""
    
    def __init__(self, config_dir: Path = None):
        """
        Initialise le chargeur de configuration.
        
        Args:
            config_dir: Répertoire contenant les fichiers config. Si None, utilise ./config
        """
        if config_dir is None:
            # Obtient le répertoire config relatif à l'emplacement de ce fichier
            self.config_dir = Path(__file__).parent.parent / 'config'
        else:
            self.config_dir = Path(config_dir)
        
        if not self.config_dir.exists():
            raise FileNotFoundError(f"Répertoire config introuvable : {self.config_dir}")
        
        logger.info(f"Répertoire config : {self.config_dir}")
    
    def load(self, config_name: str) -> Dict[str, Any]:
        """
        Charge un fichier de configuration YAML.
        
        Args:
            config_name: Nom du fichier config (sans extension .yaml)
            
        Returns:
            Dictionnaire contenant la configuration
            
        Raises:
            FileNotFoundError: Si le fichier config n'existe pas
            yaml.YAMLError: Si le fichier config est malformé
        """
        config_path = self.config_dir / f"{config_name}.yaml"
        
        if not config_path.exists():
            raise FileNotFoundError(f"Fichier config introuvable : {config_path}")
        
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            logger.info(f"Config chargée : {config_name}")
            return config
        except yaml.YAMLError as e:
            logger.error(f"Erreur parsing {config_name}.yaml : {e}")
            raise
    
    def load_all(self) -> Dict[str, Dict[str, Any]]:
        """
        Charge tous les fichiers de configuration YAML du répertoire config.
        
        Returns:
            Dictionnaire mappant les noms de config à leur contenu
        """
        all_configs = {}
        
        for config_file in self.config_dir.glob("*.yaml"):
            config_name = config_file.stem
            try:
                all_configs[config_name] = self.load(config_name)
            except Exception as e:
                logger.warning(f"Échec du chargement de {config_name} : {e}")
        
        return all_configs
    
    def get_value(self, config_name: str, key_path: str, default: Any = None) -> Any:
        """
        Obtient une valeur spécifique d'une config en utilisant la notation par points.
        
        Args:
            config_name: Nom du fichier config
            key_path: Chemin vers la valeur (ex: 'websocket.uri')
            default: Valeur par défaut si la clé n'est pas trouvée
            
        Returns:
            Valeur à key_path ou default
            
        Example:
            loader.get_value('network', 'websocket.uri')  # Retourne 'ws://localhost:8765'
        """
        config = self.load(config_name)
        
        keys = key_path.split('.')
        value = config
        
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default
        
        return value


################################################################################
PATH: ./control_turtlebot/utils/__init__.py
################################################################################
"""Utilities package for TurtleBot controller."""


################################################################################
PATH: ./control_turtlebot/visual_robot.py
################################################################################
#!/usr/bin/env python3
"""
Module Visual Robot
Gère la représentation visuelle du robot dans l'interface
"""

import pygame
import math


class VisualRobot:
    """Robot visuel pour la simulation dans l'interface"""
    
    def __init__(self, x, y, angle=0):
        self.x = x
        self.y = y
        self.angle = angle  # en degrés
        
        self.trail = []  # Traînée
        self.max_trail_length = 80
        
        # Position de repos (centre)
        self.rest_x = x
        self.rest_y = y
        self.rest_angle = angle
        
        # Pour le retour au centre
        self.return_speed = 0.15
    
    def update(self, linear_x, angular_z, dt=0.016):
        """Met à jour la position du robot selon les commandes"""
        # Si aucune commande, retour progressif au centre
        if abs(linear_x) < 0.01 and abs(angular_z) < 0.01:
            # Retour en position
            dx = self.rest_x - self.x
            dy = self.rest_y - self.y
            da = self.rest_angle - self.angle
            
            # Normaliser l'angle
            while da > 180:
                da -= 360
            while da < -180:
                da += 360
            
            self.x += dx * self.return_speed
            self.y += dy * self.return_speed
            self.angle += da * self.return_speed
            
            # Snap au centre si très proche
            if abs(dx) < 1 and abs(dy) < 1 and abs(da) < 1:
                self.x = self.rest_x
                self.y = self.rest_y
                self.angle = self.rest_angle
                self.trail.clear()
        else:
            # Simulation du mouvement
            # CORRECTION: Échelles équilibrées pour rotation et translation
            speed_scale = 1000  # pixels par m/s
            angular_scale = 5  # pixels par rad/s
            
            # Rotation
            angular_deg = math.degrees(angular_z)
            self.angle += angular_deg * angular_scale * dt
            
            # Translation
            angle_rad = math.radians(self.angle)
            dx = math.sin(angle_rad) * linear_x * speed_scale * dt
            dy = -math.cos(angle_rad) * linear_x * speed_scale * dt
            
            self.x += dx
            self.y += dy
            
            # Limiter la zone de déplacement (pas trop loin du centre)
            max_dist = 220
            dist = math.sqrt((self.x - self.rest_x)**2 + (self.y - self.rest_y)**2)
            if dist > max_dist:
                ratio = max_dist / dist
                self.x = self.rest_x + (self.x - self.rest_x) * ratio
                self.y = self.rest_y + (self.y - self.rest_y) * ratio
            
            # Ajouter à la traînée
            if len(self.trail) == 0 or \
               (abs(self.trail[-1][0] - self.x) > 3 or abs(self.trail[-1][1] - self.y) > 3):
                self.trail.append((int(self.x), int(self.y)))
                
                if len(self.trail) > self.max_trail_length:
                    self.trail.pop(0)
    
    def draw(self, surface, scale=1.0):
        """Dessine le robot avec mise à l'échelle"""
        # Traînée avec gradient
        if len(self.trail) > 1:
            for i in range(len(self.trail) - 1):
                alpha = i / len(self.trail)
                color = (
                    int(0 * alpha),
                    int(150 * alpha),
                    int(150 * alpha)
                )
                radius = int((2 + alpha * 2) * scale)
                pygame.draw.circle(surface, color, self.trail[i], max(1, radius))
        
        # Tailles avec échelle
        rayon_ext = int(32 * scale)
        rayon_int = int(28 * scale)
        rayon_roue = int(8 * scale)
        rayon_roue_int = int(6 * scale)
        longueur_fleche = int(40 * scale)
        
        # Corps du robot
        pos = (int(self.x), int(self.y))
        pygame.draw.circle(surface, (40, 40, 50), pos, rayon_ext)
        pygame.draw.circle(surface, (0, 200, 255), pos, rayon_int, max(1, int(3 * scale)))
        
        # Roues
        angle_rad = math.radians(self.angle)
        for offset in [-15 * scale, 15 * scale]:
            angle_roue = angle_rad + math.radians(90)
            rx = self.x + math.cos(angle_roue) * offset
            ry = self.y + math.sin(angle_roue) * offset
            pygame.draw.circle(surface, (100, 100, 100), (int(rx), int(ry)), rayon_roue)
            pygame.draw.circle(surface, (60, 60, 60), (int(rx), int(ry)), rayon_roue_int)
        
        # Flèche directionnelle
        x1 = self.x + math.sin(angle_rad) * longueur_fleche
        y1 = self.y - math.cos(angle_rad) * longueur_fleche
        
        # Corps de la flèche
        pygame.draw.line(surface, (255, 100, 100), pos, (x1, y1), max(1, int(4 * scale)))
        
        # Pointe
        for angle_offset in [-25, 25]:
            angle_pointe = angle_rad + math.radians(180 + angle_offset)
            x2 = x1 + math.sin(angle_pointe) * 15 * scale
            y2 = y1 - math.cos(angle_pointe) * 15 * scale
            pygame.draw.line(surface, (255, 100, 100), (x1, y1), (x2, y2), max(1, int(4 * scale)))
        
        # Point central
        pygame.draw.circle(surface, (255, 255, 0), pos, max(1, int(3 * scale)))
    
    def reset_trail(self):
        """Efface la traînée"""
        self.trail.clear()
    
    def reset_position(self):
        """Remet le robot au centre instantanément"""
        self.x = self.rest_x
        self.y = self.rest_y
        self.angle = self.rest_angle
        self.trail.clear()

################################################################################
PATH: ./control_turtlebot/websocket_client.py
################################################################################
#!/usr/bin/env python3
"""
Client WebSocket pour TurtleBot Controller.

Ce module gere la communication bidirectionnelle avec le serveur ROS Bridge
via WebSocket. Il fournit une interface thread-safe avec reconnexion
automatique, gestion de file d'attente pour les commandes, et suivi
des statistiques de connexion (latence, taux de succes).

Classes:
    WebSocketClient: Client WebSocket thread-safe avec reconnexion automatique.
"""

import asyncio
import websockets
import json
import threading
import time
from queue import Queue, Empty
import config


class WebSocketClient:
    """Client WebSocket thread-safe avec reconnexion automatique"""
    
    def __init__(self, uri="ws://localhost:8765"):
        self.uri = uri
        self.websocket = None
        self.connected = False
        self.running = False
        self.send_queue = Queue()
        
        self.last_status = "Déconnecté"
        self.commands_sent = 0
        self.commands_rejected = 0
        self.commands_accepted = 0
        self.safety_info = {}
        
        self.connection_attempts = 0
        self.last_connection_attempt = 0
        self.reconnect_delay = 2.0
        
        self.loop = None
        self.thread = None
        
        self.last_latency = 0
        self.avg_latency = 0
        self.ping_count = 0
    
    def start(self):
        """Demarre le client dans un thread"""
        print(f"[WS] Connexion a {self.uri}...")
        self.running = True
        self.thread = threading.Thread(target=self._run_async, daemon=True)
        self.thread.start()
        
        for i in range(100):
            if self.connected:
                print(f"[WS] Connecte au ROS Bridge!")
                return True
            time.sleep(0.1)
            
            if i % 10 == 9:
                print(f"[WS] Tentative de connexion... ({i//10 + 1}s)")
        
        print("[WS] Delai de connexion depasse")
        return False
    
    def _run_async(self):
        """Thread asyncio"""
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        
        try:
            self.loop.run_until_complete(self._main_loop())
        except Exception as e:
            print(f"[WS] Erreur boucle asyncio: {e}")
        finally:
            self.loop.close()
    
    async def _main_loop(self):
        """Boucle principale avec reconnexion automatique"""
        while self.running:
            try:
                self.connection_attempts += 1
                self.last_connection_attempt = time.time()
                
                if self.connection_attempts > 1:
                    print(f"[WS] Tentative de reconnexion #{self.connection_attempts}...")
                
                async with websockets.connect(
                    self.uri,
                    ping_interval=10,
                    ping_timeout=5,
                    close_timeout=2
                ) as ws:
                    self.websocket = ws
                    self.connected = True
                    self.last_status = "Connecte"
                    
                    if self.connection_attempts > 1:
                        print(f"[WS] Reconnecte!")
                    
                    try:
                        welcome = await asyncio.wait_for(ws.recv(), timeout=5.0)
                        data = json.loads(welcome)
                        robot_name = data.get('robot', 'Inconnu')
                        print(f"[WS] Robot: {robot_name}")
                        
                        config = data.get('config', {})
                        print(f"[WS] Limites: linear=[{config.get('min_linear_vel')}, {config.get('max_linear_vel')}], "
                              f"angular=+/-{config.get('max_angular_vel')}")
                    
                    except asyncio.TimeoutError:
                        print("[WS] Timeout en attente du message d'accueil")
                    
                    await asyncio.gather(
                        self._send_loop(),
                        self._receive_loop(),
                        return_exceptions=True
                    )
            
            except websockets.exceptions.WebSocketException as e:
                self.connected = False
                self.last_status = f"Deconnecte"
                print(f"[WS] Connexion perdue: {e}")
                
                if self.running:
                    await asyncio.sleep(self.reconnect_delay)
            
            except Exception as e:
                self.connected = False
                self.last_status = f"Erreur"
                print(f"[WS] Erreur connexion: {type(e).__name__}: {e}")
                
                if self.running:
                    await asyncio.sleep(self.reconnect_delay)
    
    async def _send_loop(self):
        """Boucle d'envoi des commandes"""
        last_ping = time.time()
        ping_interval = 3.0
        
        while self.connected and self.running:
            try:
                try:
                    msg_type, data = self.send_queue.get_nowait()
                    
                    if msg_type == 'cmd_vel':
                        message = {
                            'type': 'cmd_vel',
                            'linear_x': config.K_LINEAR * data['linear_x'],
                            'angular_z': config.K_ANGULAR * data['angular_z'],
                            'timestamp': time.time()
                        }
                        await self.websocket.send(json.dumps(message))
                        self.commands_sent += 1
                    
                    elif msg_type == 'emergency_stop':
                        message = {
                            'type': 'emergency_stop',
                            'timestamp': time.time()
                        }
                        await self.websocket.send(json.dumps(message))
                        print("[WS] ARRET D'URGENCE envoye!")
                    
                    elif msg_type == 'get_status':
                        message = {
                            'type': 'get_status',
                            'timestamp': time.time()
                        }
                        await self.websocket.send(json.dumps(message))
                
                except Empty:
                    pass
                
                now = time.time()
                if now - last_ping >= ping_interval:
                    try:
                        ping_time = time.time()
                        message = {
                            'type': 'ping',
                            'timestamp': ping_time
                        }
                        await self.websocket.send(json.dumps(message))
                        last_ping = now
                    except:
                        pass
                
                await asyncio.sleep(0.01)
            
            except websockets.exceptions.ConnectionClosed:
                break
            except Exception as e:
                print(f"[WS] Erreur envoi: {e}")
                break
    
    async def _receive_loop(self):
        """Boucle de réception"""
        try:
            async for message in self.websocket:
                try:
                    data = json.loads(message)
                    msg_type = data.get('type')
                    
                    if msg_type == 'cmd_accepted':
                        self.commands_accepted += 1
                        reason = data.get('reason', 'OK')
                        self.last_status = f"Accepte: {reason}"
                    
                    elif msg_type == 'cmd_rejected':
                        self.commands_rejected += 1
                        reason = data.get('reason', 'Bloque')
                        self.last_status = f"Rejete: {reason}"
                        print(f"[WS] Commande rejetee: {reason}")
                    
                    elif msg_type == 'status_broadcast':
                        self.last_status = data.get('last_status', 'Inconnu')
                        self.safety_info = data.get('debug', {})
                    
                    elif msg_type == 'status':
                        self.safety_info = data.get('debug', {})
                    
                    elif msg_type == 'pong':
                        sent_time = data.get('timestamp')
                        if sent_time:
                            try:
                                recv_time = time.time()
                                latency = (recv_time - float(sent_time)) * 1000
                                self.last_latency = latency
                                
                                self.ping_count += 1
                                alpha = 0.3
                                self.avg_latency = alpha * latency + (1 - alpha) * self.avg_latency
                            except:
                                pass
                    
                    elif msg_type == 'emergency_stop_ack':
                        print("[WS] Arret d'urgence confirme par le serveur")
                    
                    elif msg_type == 'error':
                        reason = data.get('reason', 'Inconnu')
                        print(f"[WS] Erreur serveur: {reason}")
                
                except json.JSONDecodeError as e:
                    print(f"[WS] Erreur decodage JSON: {e}")
                except Exception as e:
                    print(f"[WS] Erreur traitement message: {e}")
        
        except websockets.exceptions.ConnectionClosed:
            pass
        except Exception as e:
            print(f"[WS] Erreur reception: {e}")
    
    def send_cmd_vel(self, linear_x, angular_z):
        """Envoie une commande (thread-safe)"""
        if self.connected:
            try:
                self.send_queue.put_nowait(('cmd_vel', {
                    'linear_x': linear_x,
                    'angular_z': angular_z
                }))
            except:
                pass
    
    def send_emergency_stop(self):
        """Arrêt d'urgence (thread-safe)"""
        try:
            self.send_queue.put_nowait(('emergency_stop', {}))
        except:
            pass
    
    def request_status(self):
        """Demande le status au serveur"""
        if self.connected:
            try:
                self.send_queue.put_nowait(('get_status', {}))
            except:
                pass
    
    def get_stats(self):
        """Retourne les statistiques"""
        success_rate = 0
        if self.commands_sent > 0:
            success_rate = (self.commands_accepted) / self.commands_sent
        
        return {
            'connected': self.connected,
            'status': self.last_status,
            'sent': self.commands_sent,
            'accepted': self.commands_accepted,
            'rejected': self.commands_rejected,
            'success_rate': success_rate,
            'safety_info': self.safety_info,
            'latency': self.last_latency,
            'avg_latency': self.avg_latency,
            'connection_attempts': self.connection_attempts
        }
    
    def stop(self):
        """Arrete le client"""
        print("[WS] Arret du client WebSocket...")
        self.running = False
        
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=2.0)

################################################################################
PATH: ./DOCUMENTATION.md
################################################################################
# VA-51 Tank Arena - Documentation Technique

## Introduction

Le projet VA-51 Tank Arena est un système de jeu en réalité augmentée innovant qui oppose deux robots TurtleBot dans un combat stratégique. L'un des robots est contrôlé par une intelligence artificielle sophistiquée basée sur un arbre de comportement, tandis que l'autre est piloté par un joueur humain via une manette PS3 ou un clavier.

Le système repose sur une architecture modulaire qui intègre vision par ordinateur, planification de trajectoire, et projection interactive. Une caméra Intel RealSense capture en temps réel la position des robots grâce à des marqueurs ArUco, tandis qu'un projecteur affiche les éléments de jeu directement sur l'arène physique, créant ainsi une expérience de réalité augmentée immersive.

---

## Architecture Globale

L'architecture du système suit le principe de séparation des responsabilités. Chaque module a un rôle bien défini et communique avec les autres via des interfaces claires.

```mermaid
flowchart TB
    subgraph PERCEPTION["Perception"]
        RS[RealSenseStream] --> AD[ArucoDetector]
        AD --> KF[KalmanFilter]
        AD --> HG[Homography]
    end

    subgraph WORLD["Modèle du Monde"]
        WM[WorldModel]
        OG[OccupancyGrid]
        TM[TransformManager]
    end

    subgraph GAME["Moteur de Jeu"]
        GE[GameEngine]
        RC[Raycast]
        HM[HitManager]
    end

    subgraph AI["IA"]
        ST[AIStrategy]
        BT[BehaviorTree]
        AStar[A* Planner]
    end

    subgraph CONTROL["Contrôle"]
        TF[TrajectoryFollower]
        ROS[ROSBridgeClient]
    end

    KF --> WM
    HG --> TM
    TM --> WM
    OG --> WM
    WM --> GE
    WM --> ST
    ST --> BT
    ST --> AStar
    GE --> RC
    RC --> HM
    ST --> TF
    TF --> ROS
```

Le flux de données principal commence par la capture d'images par la caméra RealSense. Ces images sont analysées par le détecteur ArUco qui identifie les marqueurs placés sur chaque robot. Les positions brutes sont ensuite lissées par des filtres de Kalman pour éliminer le bruit de mesure et estimer les vitesses.

Ces données alimentent le WorldModel, qui sert de référentiel central pour l'état du monde. Le moteur de jeu et l'IA consultent ce modèle pour prendre leurs décisions. L'IA génère des commandes de mouvement qui sont transmises aux robots via une connexion WebSocket avec ROS.

---

## Pipeline de Perception

Le pipeline de perception est le premier maillon de la chaîne. Il transforme les images brutes de la caméra en données de position exploitables par le reste du système.

### Acquisition d'Images

La caméra Intel RealSense D435 capture des images en haute définition (1920x1080) à 30 images par seconde. Cette résolution élevée permet une détection précise des marqueurs ArUco même lorsque les robots sont éloignés de la caméra.

### Détection des Marqueurs ArUco

Les marqueurs ArUco sont des codes-barres 2D facilement détectables par vision par ordinateur. Chaque robot porte un marqueur unique : l'ID 4 pour le robot IA et l'ID 5 pour le robot humain. Le détecteur extrait non seulement la position du centre du marqueur, mais aussi les quatre coins, ce qui permet de calculer l'orientation du robot.

### Filtrage de Kalman

Les mesures brutes de position sont bruitées en raison des vibrations, des variations d'éclairage, et des imprécisions de détection. Le filtre de Kalman étendu (EKF) résout ce problème en fusionnant les mesures avec un modèle de mouvement du robot. Le vecteur d'état comprend six variables : position (x, y), vitesse (vx, vy), orientation (θ), et vitesse angulaire (ω).

```mermaid
flowchart LR
    CAM[Caméra 1920x1080] --> AR[Détection ArUco]
    AR -->|ID 4| KF1[Kalman Robot IA]
    AR -->|ID 5| KF2[Kalman Robot Humain]
    KF1 --> POSE[Poses Filtrées]
    KF2 --> POSE
```

---

## Modèle du Monde

Le WorldModel est le cœur de la représentation spatiale du système. Il centralise toutes les informations sur l'état de l'arène : positions des robots, obstacles, limites du terrain.

### Grille d'Occupation

L'arène est discrétisée en une grille de cellules de 2cm de côté. Chaque cellule peut être libre (valeur 0) ou occupée par un obstacle (valeur 1). Cette représentation permet une planification de trajectoire efficace via l'algorithme A*.

Pour garantir la sécurité des robots, une zone d'inflation est ajoutée autour de chaque obstacle. Cette marge de sécurité empêche l'IA de planifier des trajectoires trop proches des obstacles, réduisant ainsi le risque de collision.

### Transformations de Coordonnées

Le système manipule plusieurs référentiels de coordonnées : pixels caméra, coordonnées virtuelles de l'arène, et mètres réels. Le TransformManager gère les homographies nécessaires pour convertir les positions entre ces référentiels. Ces transformations sont calibrées lors de la phase d'initialisation du système.

---

## Moteur de Jeu

Le GameEngine est l'arbitre central du match. Il gère les règles du jeu, valide les tirs, et détermine le vainqueur.

### Machine à États

Le match progresse à travers plusieurs états bien définis. Au démarrage, le système est en attente (WAITING). Lorsque le joueur appuie sur Espace, un compte à rebours de 3 secondes commence (COUNTDOWN). Le match démarre ensuite (PLAYING) et se poursuit jusqu'à ce qu'un robot atteigne 10 points ou que le temps imparti (3 minutes) soit écoulé (FINISHED).

```mermaid
stateDiagram-v2
    [*] --> WAITING
    WAITING --> COUNTDOWN: Espace
    COUNTDOWN --> PLAYING: 3..2..1..GO!
    PLAYING --> FINISHED: Victoire ou Temps écoulé
    FINISHED --> WAITING: Espace
```

### Système de Tir

Chaque robot dispose d'un laser virtuel pour tirer sur son adversaire. L'algorithme Raycast utilise la méthode DDA (Digital Differential Analyzer) pour tracer le rayon du tir à travers la grille d'occupation. Si le rayon atteint l'adversaire sans rencontrer d'obstacle, le tir est validé et un point est attribué.

Les tirs sont soumis à un temps de recharge (cooldown) : 5 secondes pour le joueur humain et 3 secondes pour l'IA, afin d'équilibrer le gameplay.

---

## Intelligence Artificielle

L'IA du robot adversaire repose sur un arbre de comportement (Behavior Tree) qui structure sa prise de décision de manière hiérarchique et modulaire.

### Arbre de Comportement

L'arbre est composé de trois branches principales, évaluées par ordre de priorité :

1. **Survie** : Si l'ennemi est trop proche (< 0.8m), le robot bat en retraite vers une position de couverture.

2. **Attaque** : Si le robot a une ligne de vue dégagée sur l'ennemi et se trouve à portée optimale (1.2m - 3.5m), il vise et tire.

3. **Chasse** : En l'absence des conditions précédentes, le robot cherche une position de flanc pour contourner les obstacles et surprendre l'adversaire.

```mermaid
flowchart TB
    ROOT[Sélecteur Principal]
    ROOT --> SURV[Survie]
    ROOT --> ATK[Attaque]
    ROOT --> HUNT[Chasse]
    
    SURV --> S1{Ennemi proche?}
    S1 -->|Oui| S2[Retraite]
    
    ATK --> A1{Ligne de vue?}
    A1 -->|Oui| A2{Portée OK?}
    A2 -->|Oui| A3[Tirer]
    
    HUNT --> H1[Flanquer]
```

### Planification de Trajectoire

Pour se déplacer, l'IA utilise l'algorithme A* qui trouve le chemin le plus court en évitant les obstacles. Le chemin brut est ensuite lissé par descente de gradient pour obtenir une trajectoire fluide, puis simplifié par l'algorithme de Douglas-Peucker pour réduire le nombre de waypoints.

---

## Contrôle des Robots

Le module de contrôle traduit les décisions de haut niveau (aller au point X) en commandes de vitesse envoyées aux moteurs des robots.

### Algorithme Pure Pursuit

Le TrajectoryFollower implémente l'algorithme Pure Pursuit pour suivre une liste de waypoints. À chaque instant, il identifie un point cible situé à une distance de "lookahead" devant le robot, puis calcule les vitesses linéaire et angulaire nécessaires pour atteindre ce point.

### Cinématique Différentielle

Les robots TurtleBot utilisent un système de propulsion différentielle avec deux roues indépendantes. La cinématique convertit les commandes (v, ω) en vitesses individuelles pour chaque roue, tout en respectant les limites physiques du robot : 0.22 m/s en vitesse linéaire maximale et 2.84 rad/s en vitesse angulaire.

### Communication ROS

Les commandes sont transmises aux robots via WebSocket, en utilisant le protocole rosbridge. Chaque message contient les vitesses linéaire et angulaire au format JSON, publié sur le topic `/cmd_vel`.

---

## Visualisation

Le rendu graphique utilise Pygame pour afficher l'état du jeu en temps réel, soit sur un écran de contrôle, soit directement sur l'arène via le projecteur.

L'interface comprend un HUD (Heads-Up Display) avec le chronomètre, les scores des deux joueurs, et les barres de cooldown des tirs. Des effets visuels accompagnent les actions : lignes laser pour les tirs, flash jaune pour les hits, et animation de lock-on lorsque l'IA vise sa cible.

En mode debug (touche D), le chemin planifié par l'IA est affiché en vert, permettant de comprendre sa stratégie en temps réel.

---

## Configuration

Le système est entièrement configurable via des fichiers YAML :

| Fichier       | Contenu                                                      |
| ------------- | ------------------------------------------------------------ |
| `arena.yaml`  | Dimensions arène, résolution projecteur, paramètres grille   |
| `camera.yaml` | Configuration RealSense, IDs ArUco, bruit Kalman             |
| `game.yaml`   | Durée match, cooldowns, conditions de victoire               |
| `ia.yaml`     | Seuils IA (distance danger, portée optimale), heuristique A* |
| `robot.yaml`  | Cinématique TurtleBot, limites vitesse, connexion ROS        |

---

## Boucle Principale

Le script `run_game.py` orchestre l'ensemble du système dans une boucle à 30 FPS :

```mermaid
flowchart TB
    A[Capturer Frame] --> B[Détecter ArUco]
    B --> C[Filtrer Kalman]
    C --> D[Mettre à jour WorldModel]
    D --> E[Traiter Input Humain]
    D --> F[Exécuter IA]
    E --> G[Tick GameEngine]
    F --> G
    G --> H[Envoyer Commandes]
    G --> I[Rendre Frame]
    I --> A
```

Cette boucle assure la synchronisation de tous les composants et maintient une latence minimale entre la détection des robots et leur contrôle.

---

## Conclusion

Le projet VA-51 Tank Arena démontre l'intégration réussie de technologies avancées : vision par ordinateur, intelligence artificielle comportementale, et robotique mobile. L'architecture modulaire facilite la maintenance et l'extension du système, tandis que la configuration externe permet d'ajuster le gameplay sans modification du code.


################################################################################
PATH: ./help
################################################################################
find . -type f \
  -not -path '*/.*' \                                                
  -not -path '*/__pycache__/*' \
  -not -path '*/assets/*' \
  -not -path '*/logs/*' \
  -not -name '*.pyc' \
  -not -name '*.png' \
  -not -name '*.jpg' \
  -not -name 'all_project_code.txt' \
  | sort | while read -r file; do
    echo "################################################################################"
    echo "PATH: $file"
    echo "################################################################################"
    cat "$file"
    echo -e "\n\n"
  done > all_project_code.txt


find . -type f \
-not -path '*/.*' \
-not -path '*/__pycache__/*' \
-not -path '*/assets/*' \
-not -path '*/logs/*' \
-not -name '*.pyc' \
-not -name '*.png' \
-not -name '*.jpg' \
-not -name 'all_project_code.txt' |
sort |
while IFS= read -r file; do
  echo "################################################################################"
  echo "PATH: $file"
  echo "################################################################################"
  cat "$file"
  echo
  echo
done > all_project_code.txt


################################################################################
PATH: ./launch_game.sh
################################################################################
#!/bin/bash
# =============================================================================
# VA-51 Tank Arena - Unified Launch Script
# =============================================================================
# Lance le Safety Bridge ROS2 et le jeu Tank Arena en une seule commande.
#
# Usage:
#   ./launch_game.sh           # Lance bridge + jeu
#   ./launch_game.sh --bridge  # Lance seulement le bridge
#   ./launch_game.sh --game    # Lance seulement le jeu
#   ./launch_game.sh --help    # Affiche l'aide
# =============================================================================

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROS2_WS="$SCRIPT_DIR/.."

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

print_banner() {
    echo -e "${BLUE}"
    echo "╔══════════════════════════════════════════════════════════════╗"
    echo "║              VA-51 TANK ARENA - LAUNCHER                     ║"
    echo "╚══════════════════════════════════════════════════════════════╝"
    echo -e "${NC}"
}

print_help() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --bridge    Lance seulement le Safety Bridge ROS2"
    echo "  --game      Lance seulement le jeu Tank Arena"
    echo "  --control   Lance seulement l'interface de contrôle manuel"
    echo "  --help      Affiche cette aide"
    echo ""
    echo "Sans option: lance le bridge puis le jeu automatiquement."
}

check_ros2() {
    if ! command -v ros2 &> /dev/null; then
        echo -e "${RED}[ERREUR] ROS2 n'est pas installé ou sourcé.${NC}"
        echo "Exécutez: source /opt/ros/humble/setup.bash"
        exit 1
    fi
}

source_workspace() {
    if [ -f "$ROS2_WS/install/setup.bash" ]; then
        echo -e "${YELLOW}[INFO] Source du workspace ROS2...${NC}"
        source "$ROS2_WS/install/setup.bash"
    else
        echo -e "${YELLOW}[WARN] Workspace non buildé. Build en cours...${NC}"
        cd "$ROS2_WS"
        colcon build --packages-select turtlebot_game
        source "$ROS2_WS/install/setup.bash"
    fi
}

launch_bridge() {
    echo -e "${GREEN}[BRIDGE] Lancement du Safety Bridge...${NC}"
    echo -e "${BLUE}         Port WebSocket: 8765${NC}"
    ros2 run turtlebot_game safety_bridge &
    BRIDGE_PID=$!
    echo -e "${GREEN}[BRIDGE] PID: $BRIDGE_PID${NC}"
    
    # Attendre que le bridge soit prêt
    sleep 3
    echo -e "${GREEN}[BRIDGE] Ready!${NC}"
}

launch_game() {
    echo -e "${GREEN}[GAME] Lancement de Tank Arena...${NC}"
    cd "$SCRIPT_DIR/tank_project"
    python3 scripts/run_game.py
}

launch_control() {
    echo -e "${GREEN}[CONTROL] Lancement de l'interface de contrôle...${NC}"
    cd "$SCRIPT_DIR/control_turtlebot"
    python3 main.py
}

cleanup() {
    echo ""
    echo -e "${YELLOW}[CLEANUP] Arrêt des processus...${NC}"
    if [ ! -z "$BRIDGE_PID" ]; then
        kill $BRIDGE_PID 2>/dev/null || true
        echo -e "${GREEN}[CLEANUP] Bridge arrêté${NC}"
    fi
    exit 0
}

# Trap Ctrl+C
trap cleanup SIGINT SIGTERM

# Main
print_banner

case "${1:-}" in
    --help|-h)
        print_help
        exit 0
        ;;
    --bridge)
        check_ros2
        source_workspace
        launch_bridge
        echo -e "${GREEN}[BRIDGE] En attente de connexions... (Ctrl+C pour arrêter)${NC}"
        wait $BRIDGE_PID
        ;;
    --game)
        launch_game
        ;;
    --control)
        launch_control
        ;;
    "")
        # Full launch: bridge + game
        check_ros2
        source_workspace
        launch_bridge
        launch_game
        cleanup
        ;;
    *)
        echo -e "${RED}[ERREUR] Option inconnue: $1${NC}"
        print_help
        exit 1
        ;;
esac


################################################################################
PATH: ./README.md
################################################################################
# VA-51 Tank Arena

Système de jeu en réalité augmentée opposant deux robots TurtleBot dans une arène physique.

## Architecture

```
VA-51/
├── tank_project/        # Jeu principal (IA, Vision, Game Engine)
├── control_turtlebot/   # Interface de contrôle manuel
├── turtlebot_game/      # ROS2 Safety Bridge
└── launch_game.sh       # Script de lancement unifié
```

## Lancement Rapide

```bash
# Lancer tout (Bridge + Jeu)
./launch_game.sh

# Options
./launch_game.sh --bridge   # Bridge ROS2 seul
./launch_game.sh --game     # Jeu seul
./launch_game.sh --control  # Interface contrôle manuel
```

## Prérequis

- ROS2 Humble
- Python 3.10+
- Intel RealSense SDK
- Pygame

## Communication

Tous les composants communiquent sur **port 8765** :

```
┌─────────────────┐     ┌─────────────────┐
│  Tank Project   │     │ Control Turtle  │
│   (IA Robot)    │     │   (Manuel)      │
└────────┬────────┘     └────────┬────────┘
         │                       │
         │    WebSocket:8765     │
         └───────────┬───────────┘
                     │
            ┌────────▼────────┐
            │  Safety Bridge  │
            │   (ROS2 Node)   │
            └────────┬────────┘
                     │
            ┌────────▼────────┐
            │    TurtleBot    │
            │    /cmd_vel     │
            └─────────────────┘
```

## Protocole WebSocket

```json
{
  "type": "cmd_vel",
  "linear_x": 0.2,
  "angular_z": 0.5,
  "timestamp": 1234567890.123
}
```

## Documentation

- [Documentation Principale](DOCUMENTATION.md)
- [Tank Project](tank_project/README.md)
- [Control TurtleBot](control_turtlebot/README.md)
- [TurtleBot Game](turtlebot_game/DOCUMENTATION.md)


################################################################################
PATH: ./scripts/connect_turtlebot.sh
################################################################################
#!/bin/bash
# TurtleBot SSH Connection and Launch Helper
# 
# Usage:
#   ./connect_turtlebot.sh [IP_ADDRESS]
#   
# Default IP: 192.168.50.1

set -e

# Configuration
TURTLEBOT_IP="${1:-192.168.50.1}"
TURTLEBOT_USER="turtlebot"
ROS_DOMAIN_ID="30"

echo "================================================"
echo " TurtleBot Connection Helper"
echo "================================================"
echo "Connecting to: ${TURTLEBOT_USER}@${TURTLEBOT_IP}"
echo "ROS_DOMAIN_ID: ${ROS_DOMAIN_ID}"
echo "================================================"
echo ""

# Test connectivity
echo "[1/3] Testing connectivity..."
if ! ping -c 1 -W 2 "${TURTLEBOT_IP}" > /dev/null 2>&1; then
    echo "ERROR: Cannot reach TurtleBot at ${TURTLEBOT_IP}"
    echo "Please check:"
    echo "  - TurtleBot is powered on"
    echo "  - WiFi connection is active"
    echo "  - IP address is correct"
    exit 1
fi
echo "  OK - TurtleBot is reachable"
echo ""

# Connect and launch
echo "[2/3] Connecting via SSH..."
echo "  (Password required for user '${TURTLEBOT_USER}')"
echo ""

# SSH with bringup launch
ssh -t ${TURTLEBOT_USER}@${TURTLEBOT_IP} << ENDSSH
    echo "================================================"
    echo " Connected to TurtleBot"
    echo "================================================"
    
    # Source ROS2 environment
    echo "[3/3] Setting up ROS2 environment..."
    source /opt/ros/humble/setup.bash
    
    # Set ROS_DOMAIN_ID
    export ROS_DOMAIN_ID=${ROS_DOMAIN_ID}
    
    echo "  ROS2 sourced: /opt/ros/humble/setup.bash"
    echo "  ROS_DOMAIN_ID set to: \${ROS_DOMAIN_ID}"
    echo ""
    
    # Launch TurtleBot bringup
    echo "Launching TurtleBot3 bringup..."
    echo "  (Press Ctrl+C to stop)"
    echo "================================================"
    echo ""
    
    ros2 launch turtlebot3_bringup robot.launch.py
ENDSSH

echo ""
echo "================================================"
echo " Disconnected from TurtleBot"
echo "================================================"


################################################################################
PATH: ./tank_project/config/arena.yaml
################################################################################
arena:
  height_m: 0.80
  width_m: 0.80
display:
  display_index: 0
  fullscreen: false
grid:
  resolution_m: 0.02 # 2 cm par cellule
robot:
  # Rayon physique du robot (Turtlebot Burger ~9cm)
  radius_m: 0.09
  # Marge de sécurité supplémentaire pour ne pas frotter les murs
  inflation_margin_m: 0.05
obstacles: []
projector:
  height: 960
  margin: 50
  margin_px: 50
  width: 1280
transform:
  H_C2W:
    - - -0.0010267945196526461
      - -3.730098981565071e-05
      - 1.5189658207743262
    - - -3.418757045764291e-05
      - 0.0015329706593207066
      - -0.5017419121719356
    - - -9.992942953194014e-07
      - 2.247742515662756e-05
      - 1.0
  scale: 0.5720342439860417
  scale_m_per_av: 0.5720342439860417


################################################################################
PATH: ./tank_project/config/camera.yaml
################################################################################
# Camera Configuration

realsense:
  # Résolution réduite pour détection ArUco rapide (~15ms au lieu de 50-80ms)
  # L'homographie gère le changement d'échelle automatiquement
  width: 848
  height: 480
  fps: 60 # Plus fluide pour le contrôle robot
  enable_depth: false

aruco:
  dictionary: DICT_4X4_50 # ArUco dictionary type

  # Marker IDs and their meanings
  markers:
    projected_corners: [0, 1, 2, 3] # Virtual corners for calibration
    robot_ai: 4 # AI robot marker
    robot_human: 5 # Human robot marker

  # Physical marker size for scale estimation
  marker_size_m: 0.10 # 10cm markers

kalman:
  # Process noise covariance
  process_noise:
    position: 0.01
    velocity: 0.1
    orientation: 0.01
    angular_velocity: 0.1

  # Measurement noise covariance
  measurement_noise:
    position: 0.05
    orientation: 0.1

  # Time step (matches game tick rate)
  dt: 0.0333 # 30 FPS


################################################################################
PATH: ./tank_project/config/game.yaml
################################################################################
# Game Rules Configuration

match:
  duration_seconds: 180 # 3 minutes
  tick_rate_fps: 30 # Game loop frequency

cooldowns:
  human_shot_seconds: 5.0 # Human can shoot every 5 seconds
  ai_shot_seconds: 3.0 # AI can shoot every 3 seconds

win_conditions:
  max_hits: 10 # First to 10 hits wins
  time_limit: true # Game ends when time expires
  sudden_death: false # Continue after time expires if tied?

shot_mechanics:
  range_m: 5.0 # Maximum shot range
  speed_mps: 10.0 # Shot travel speed (for animation)
  instant_hit: true # Hitscan vs projectile


################################################################################
PATH: ./tank_project/config/ia.yaml
################################################################################
# AI Configuration

behavior:
  # Threat assessment thresholds
  danger_distance_m: 0.8 # Enemy too close threshold
  optimal_range_min_m: 1.2 # Min optimal firing range
  optimal_range_max_m: 3.5 # Max optimal firing range

  # Behavior priorities
  survival_priority: true # Retreat overrides attack

strategy:
  # Path planning
  heuristic: "euclidean" # 'euclidean', 'manhattan', 'diagonal'
  path_simplify: true # Apply Douglas-Peucker simplification
  simplify_epsilon_m: 0.05 # Simplification tolerance

  # Path smoothing
  smooth_path: true
  smooth_weight_data: 0.5
  smooth_weight_smooth: 0.3

  # Flanking behavior
  flank_angle_deg: 90 # Preferred flanking angle
  cover_preference: 0.8 # Preference for cover (0-1)

decision_rate:
  # How often to replan (in ticks)
  replan_interval: 10 # Replan every 10 ticks (~0.33s at 30fps)


################################################################################
PATH: ./tank_project/config/projector.yaml
################################################################################
# =============================================================================
# Configuration Projecteur - Tank Arena
# =============================================================================
# Modifier ces valeurs selon votre setup matériel

projector:
  # Résolution du projecteur VGA
  width: 1024
  height: 768

  # Marge de sécurité (pixels depuis le bord)
  margin_px: 50

# Configuration multi-écran
display:
  # Offset X = largeur de l'écran principal (ex: 1920 pour Full HD)
  monitor_offset_x: 1920
  monitor_offset_y: 0

  # Mode sans bordure: supprime la barre de titre et les bordures
  # true = fenêtre propre pour projection (recommandé prod)
  # false = fenêtre normale avec barre titre (utile pour debug)
  borderless: true

  # Cacher le curseur souris dans la fenêtre projetée
  # true = pas de flèche visible sur l'arène (recommandé prod)
  # false = curseur visible (utile pour debug)
  hide_cursor: true

# Calibration métrique
calibration:
  # Taille réelle du marqueur ArUco en mètres
  marker_size_m: 0.10

  # IDs des marqueurs
  corner_marker_ids: [0, 1, 2, 3] # Coins projetés
  robot_marker_ids: [4, 5] # Marqueurs robot

  # Dictionnaire ArUco utilisé
  aruco_dictionary: "DICT_4X4_100"


################################################################################
PATH: ./tank_project/config/robot.yaml
################################################################################
# Robot Configuration (Turtlebot Burger)

kinematics:
  wheel_base_m: 0.16 # Distance between wheels
  wheel_radius_m: 0.033 # Wheel radius

physical:
  robot_radius_m: 0.09 # Approximation as circle

velocity_limits:
  max_linear_mps: 0.22 # Max linear velocity (m/s)
  max_angular_radps: 2.84 # Max angular velocity (rad/s)

acceleration_limits:
  max_linear_accel: 0.5 # m/s²
  max_angular_accel: 5.0 # rad/s²

control:
  # Trajectory following parameters
  lookahead_distance_m: 0.3
  k_velocity: 0.5 # Linear velocity gain
  k_theta: 0.5 # Angular velocity gain
  waypoint_threshold_m: 0.1 # Distance to consider waypoint reached

ros_bridge:
  host: "localhost"
  port: 8765 # Must match safety_bridge WebSocket port
  timeout_s: 1.0


################################################################################
PATH: ./tank_project/core/control/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/core/control/kinematics.py
################################################################################
"""
Cinématique - Modèle de mouvement robot

Cinématique de robot à entraînement différentiel pour Turtlebot Burger :
- Cinématique directe : (v, ω) -> (dx, dy, dθ)
- Cinématique inverse : contraintes de vitesse
- Modèle dynamique (simplifié)

Utilisé pour la simulation et la validation du contrôle.
"""

import numpy as np
from typing import Tuple


class DifferentialDriveKinematics:
    """
    Cinématique pour robot à entraînement différentiel (Turtlebot Burger).
    
    Paramètres du robot :
    - Empattement : distance entre les roues
    - Rayon des roues
    """
    
    def __init__(self, wheel_base: float = 0.16, wheel_radius: float = 0.033):
        """
        Initialise le modèle cinématique.
        
        Args:
            wheel_base: Distance entre les roues en mètres (Burger : 0.16m)
            wheel_radius: Rayon des roues en mètres (Burger : 0.033m)
        """
        self.wheel_base = wheel_base
        self.wheel_radius = wheel_radius
        
    def forward_kinematics(self, 
                          v: float, 
                          omega: float, 
                          current_pose: Tuple[float, float, float],
                          dt: float) -> Tuple[float, float, float]:
        """
        Calcule la nouvelle pose à partir des commandes de vitesse.
        
        Args:
            v: Vitesse linéaire en m/s
            omega: Vitesse angulaire en rad/s
            current_pose: (x, y, theta) pose actuelle
            dt: Pas de temps en secondes
            
        Returns:
            (x_new, y_new, theta_new) pose mise à jour
            
        Équations :
            dx = v * cos(θ) * dt
            dy = v * sin(θ) * dt
            dθ = ω * dt
        """
        x, y, theta = current_pose
        
        # Mise à jour de l'orientation en premier
        theta_new = theta + omega * dt
        
        # Theta moyen pour une intégration plus précise
        theta_avg = theta + 0.5 * omega * dt
        
        # Mise à jour de la position
        x_new = x + v * np.cos(theta_avg) * dt
        y_new = y + v * np.sin(theta_avg) * dt
        
        # Normalisation de theta entre [-pi, pi]
        theta_new = np.arctan2(np.sin(theta_new), np.cos(theta_new))
        
        return (x_new, y_new, theta_new)
    
    def wheel_velocities_to_body(self, 
                                 v_left: float, 
                                 v_right: float) -> Tuple[float, float]:
        """
        Convertit les vitesses des roues en vitesses du corps.
        
        Args:
            v_left: Vitesse roue gauche en m/s
            v_right: Vitesse roue droite en m/s
            
        Returns:
            (v, omega): vitesses linéaire et angulaire du corps
        """
        v = (v_right + v_left) / 2.0
        omega = (v_right - v_left) / self.wheel_base
        
        return (v, omega)
    
    def body_to_wheel_velocities(self, 
                                 v: float, 
                                 omega: float) -> Tuple[float, float]:
        """
        Convertit les vitesses du corps en vitesses des roues.
        
        Args:
            v: Vitesse linéaire en m/s
            omega: Vitesse angulaire en rad/s
            
        Returns:
            (v_left, v_right): vitesses des roues en m/s
        """
        v_left = v - (omega * self.wheel_base) / 2.0
        v_right = v + (omega * self.wheel_base) / 2.0
        
        return (v_left, v_right)
    
    def validate_velocities(self, 
                           v: float, 
                           omega: float,
                           max_v: float = 0.22,
                           max_omega: float = 2.84) -> Tuple[float, float]:
        """
        Valide et limite les vitesses aux contraintes du robot.
        
        Args:
            v, omega: Vitesses désirées
            max_v: Vitesse linéaire maximum (Burger : 0.22 m/s)
            max_omega: Vitesse angulaire maximum (Burger : 2.84 rad/s)
            
        Returns:
            (v_clamped, omega_clamped)
        """
        v_clamped = np.clip(v, -max_v, max_v)
        omega_clamped = np.clip(omega, -max_omega, max_omega)
        
        return (v_clamped, omega_clamped)


################################################################################
PATH: ./tank_project/core/control/motion_constraints.py
################################################################################
"""
Contraintes de Mouvement - Limites de Vitesse & Accélération

Applique les contraintes physiques du robot :
- Vitesses maximales (linéaire, angulaire)
- Accélérations maximales
- Lissage de la vitesse
- Logique d'arrêt d'urgence

Empêche les commandes dangereuses et assure un mouvement fluide.
"""

import numpy as np
from typing import Tuple


class MotionConstraints:
    """
    Applique les contraintes physiques de mouvement pour un contrôle sûr du robot.
    
    Prévient :
    - Dépassement des limites de vitesse
    - Accélération excessive (changements brusques)
    - Commandes dangereuses
    """
    
    def __init__(self, config):
        """
        Initialise les contraintes de mouvement.
        
        Args:
            config: Configuration du robot :
                - max_linear_vel: m/s
                - max_angular_vel: rad/s
                - max_linear_accel: m/s²
                - max_angular_accel: rad/s²
        """
        self.max_v = config.get('max_linear_vel', 0.22)
        self.max_omega = config.get('max_angular_vel', 2.84)
        self.max_accel_v = config.get('max_linear_accel', 0.5)
        self.max_accel_omega = config.get('max_angular_accel', 5.0)
        
        # Commandes précédentes pour limitation d'accélération
        self.prev_v = 0.0
        self.prev_omega = 0.0
        
    def apply_constraints(self, 
                         v_desired: float, 
                         omega_desired: float,
                         dt: float) -> Tuple[float, float]:
        """
        Applique toutes les contraintes de mouvement.
        
        Args:
            v_desired: Vitesse linéaire désirée
            omega_desired: Vitesse angulaire désirée
            dt: Temps depuis la dernière commande (secondes)
            
        Returns:
            (v_safe, omega_safe): vitesses contraintes
            
        Étapes :
            1. Limite aux vitesses max
            2. Limite l'accélération
            3. Met à jour les commandes précédentes
        """
        # Limites de vitesse
        v = np.clip(v_desired, -self.max_v, self.max_v)
        omega = np.clip(omega_desired, -self.max_omega, self.max_omega)
        
        # Limites d'accélération
        if dt > 0:
            v = self._limit_acceleration(v, self.prev_v, self.max_accel_v, dt)
            omega = self._limit_acceleration(omega, self.prev_omega, 
                                            self.max_accel_omega, dt)
        
        # Stockage pour la prochaine itération
        self.prev_v = v
        self.prev_omega = omega
        
        return (v, omega)
    
    def _limit_acceleration(self, 
                           desired: float, 
                           previous: float,
                           max_accel: float, 
                           dt: float) -> float:
        """
        Limite l'accélération d'une composante de vitesse.
        
        Args:
            desired: Vitesse désirée
            previous: Vitesse précédente
            max_accel: Accélération maximum autorisée
            dt: Pas de temps
            
        Returns:
            Vitesse limitée en accélération
        """
        delta = desired - previous
        max_delta = max_accel * dt
        
        if abs(delta) > max_delta:
            delta = np.sign(delta) * max_delta
        
        return previous + delta
    
    def emergency_stop(self):
        """
        Réinitialise la vitesse à zéro immédiatement.
        
        Utilisé pour un arrêt de sécurité.
        """
        self.prev_v = 0.0
        self.prev_omega = 0.0
        
        return (0.0, 0.0)
    
    def soft_stop(self, dt: float) -> Tuple[float, float]:
        """
        Décélère graduellement jusqu'à zéro.
        
        Args:
            dt: Pas de temps
            
        Returns:
            Vitesses en décélération
        """
        return self.apply_constraints(0.0, 0.0, dt)


################################################################################
PATH: ./tank_project/core/control/ros_bridge_client.py
################################################################################
"""
Client Pont ROS - Communication avec le système ROS

Client WebSocket pour envoyer des commandes au pont ROS :
- Se connecte au serveur pont ROS via WebSocket
- Envoie des commandes de vitesse sur /cmd_vel
- Reçoit les acquittements
- Maintaint la santé de la connexion

Logs : [ROS] Commande envoyée : v=X, ω=Y
"""

import json
import time
import asyncio
import threading
from typing import Optional

try:
    import websockets
    from websockets.sync.client import connect as ws_connect
    HAS_WEBSOCKETS = True
except ImportError:
    HAS_WEBSOCKETS = False
    print("[ROS] Attention : websockets non installé, utilisation du repli")


class ROSBridgeClient:
    """
    Client pour communiquer avec le pont ROS via WebSocket.
    
    Envoie des commandes de vitesse au robot physique.
    """
    
    def __init__(self, host: str = 'localhost', port: int = 8765):
        """
        Initialise le client pont ROS.
        
        Args:
            host: Hôte du serveur pont ROS
            port: Port du serveur pont ROS (défaut 8765 pour WebSocket)
        """
        self.host = host
        self.port = port
        self.ws = None
        self.connected = False
        self.uri = f"ws://{host}:{port}"
        
    def connect(self, max_retries: int = 3, retry_interval: float = 2.0):
        """
        Établit la connexion WebSocket avec le pont ROS.
        
        Args:
            max_retries: Tentatives max
            retry_interval: Secondes entre les essais
        
        Logs :
            [ROS] Connecté au pont à host:port
            [ROS] Connexion échouée : erreur
        """
        if not HAS_WEBSOCKETS:
            print("[ROS] Bibliothèque WebSocket non disponible")
            return False
            
        attempt = 0
        while attempt < max_retries:
            attempt += 1
            try:
                self.ws = ws_connect(self.uri, open_timeout=5)
                self.connected = True
                
                # Lit le message de bienvenue
                try:
                    welcome = self.ws.recv(timeout=2)
                    print(f"[ROS] Connecté au pont à {self.host}:{self.port}")
                except:
                    print(f"[ROS] Connecté au pont à {self.host}:{self.port}")
                    
                return True
                
            except Exception as e:
                self.connected = False
                print(f"[ROS] Tentative de connexion {attempt} échouée : {e}")
                
                if attempt >= max_retries:
                    print("[ROS] Nb max d'essais atteint, exécution sans connexion ROS")
                    return False
                
                print(f"[ROS] Nouvel essai dans {retry_interval} secondes...")
                time.sleep(retry_interval)
        
        return False
    
    def disconnect(self):
        """Ferme la connexion WebSocket au pont ROS."""
        if self.ws:
            try:
                self.ws.close()
            except:
                pass
            self.connected = False
            print("[ROS] Déconnecté du pont")
    
    def send_velocity_command(self, 
                             robot_id: int, 
                             v: float, 
                             omega: float) -> bool:
        """
        Envoie une commande de vitesse au robot.
        
        Args:
            robot_id: 4 (IA) ou 5 (Humain)
            v: Vitesse linéaire en m/s
            omega: Vitesse angulaire en rad/s
            
        Returns:
            True si envoyé avec succès
            
        Format message (JSON) :
            {
                "type": "cmd_vel",
                "linear_x": v,
                "angular_z": omega,
                "timestamp": unix_time
            }
            
        Logs :
            [ROS] Robot4 cmd : v=0.15 m/s, ω=-0.30 rad/s
        """
        if not self.connected or not self.ws:
            # Essaie de reconnecter silencieusement
            if not self.connect(max_retries=1, retry_interval=0.5):
                return False
        
        # Format message correspondant aux attentes de safety_bridge.py
        message = {
            "type": "cmd_vel",
            "linear_x": round(v, 4),
            "angular_z": round(omega, 4),
            "timestamp": time.time()
        }
        
        try:
            msg_json = json.dumps(message)
            self.ws.send(msg_json)
            
            # Log (moins verbeux - seulement toutes les 30 commandes ou significatives)
            if abs(v) > 0.01 or abs(omega) > 0.1:
                print(f"[ROS] Robot{robot_id} cmd : v={v:.2f} m/s, w={omega:.2f} rad/s")
            
            # Essaie de recevoir l'acquittement (non-bloquant)
            try:
                self.ws.recv(timeout=0.01)
            except:
                pass  # Ignore si pas de réponse
            
            return True
            
        except Exception as e:
            print(f"[ROS] Envoi échoué : {e}")
            self.connected = False
            return False
    
    def receive_feedback(self, timeout: float = 0.01) -> Optional[dict]:
        """
        Reçoit le retour du pont ROS (non-bloquant).
        
        Args:
            timeout: Timeout socket en secondes
            
        Returns:
            dict avec données, ou None
        """
        if not self.connected or not self.ws:
            return None
        
        try:
            data = self.ws.recv(timeout=timeout)
            if data:
                return json.loads(data)
        except:
            pass  # Pas de données disponibles
            
        return None
    
    def send_stop_command(self, robot_id: int):
        """
        Envoie un arrêt d'urgence au robot.
        
        Args:
            robot_id: Robot à arrêter
        """
        self.send_velocity_command(robot_id, 0.0, 0.0)


################################################################################
PATH: ./tank_project/core/control/trajectory_follower.py
################################################################################
"""
Suiveur de Trajectoire - Contrôleur de Suivi de Chemin

Implémente le suivi de trajectoire pour la navigation par points de passage :
- Contrôleur Pure Pursuit
- Contrôle de cap basé sur PID
- Avancement dynamique des points de passage
- Réactions d'évitement d'obstacles

Prend un chemin (liste de waypoints) et la pose actuelle, sort (v, ω).

Logs : [CTRL] Suivi waypoint (x,y), distance : Dm
"""

import numpy as np
from typing import Tuple, List, Optional


class TrajectoryFollower:
    """
    Contrôleur de suivi de trajectoire pour la navigation par points.
    
    Utilise l'algorithme Pure Pursuit pour un suivi fluide.
    """
    
    def __init__(self, config):
        """
        Initialise le suiveur de trajectoire.
        
        Args:
            config: Paramètres du contrôleur depuis config/robot.yaml :
                - lookahead_distance: Distance de visée Pure Pursuit
                - k_v: Gain de vitesse linéaire
                - k_theta: Gain de vitesse angulaire
                - max_linear_vel: V max en m/s
                - max_angular_vel: ω max en rad/s
        """
        self.lookahead_distance = config.get('lookahead_distance', 0.3)
        self.k_v = config.get('k_v', 1.0)
        self.k_theta = config.get('k_theta', 2.0)
        self.max_linear_vel = config.get('max_linear_vel', 0.22)
        self.max_angular_vel = config.get('max_angular_vel', 2.84)
        
        self.waypoint_reached_threshold = config.get('waypoint_threshold', 0.1)
        
    def compute_control(self, 
                       current_pose: Tuple[float, float, float],
                       waypoints: List[Tuple[float, float]]) -> Tuple[float, float]:
        """
        Calcule les commandes de contrôle pour suivre les waypoints.
        
        Args:
            current_pose: (x, y, theta) pose actuelle du robot
            waypoints: Liste de waypoints (x, y) en mètres
            
        Returns:
            (v, omega): vitesses linéaire et angulaire
            
        Algorithme (Pure Pursuit) :
            1. Trouve le point de visée (lookahead) sur le chemin
            2. Calcule la courbure pour atteindre ce point
            3. Calcule v et ω à partir de la courbure
            4. Limite aux vitesses max
            
        Logs :
            [CTRL] Target waypoint (x,y), distance: Dm, heading error: θ rad
        """
        if not waypoints:
            return (0.0, 0.0)
        
        x, y, theta = current_pose
        
        # Trouve le waypoint cible (lookahead)
        target_wp = self._get_lookahead_point(current_pose, waypoints)
        
        if target_wp is None:
            return (0.0, 0.0)
        
        # Calcule le contrôle
        v, omega = self._pure_pursuit(current_pose, target_wp)
        
        # Limite les vitesses
        v = np.clip(v, -self.max_linear_vel, self.max_linear_vel)
        omega = np.clip(omega, -self.max_angular_vel, self.max_angular_vel)
        
        return (v, omega)
    
    def _get_lookahead_point(self, pose, waypoints):
        """
        Trouve le waypoint à la distance de visée.
        
        Args:
            pose: Pose actuelle du robot
            waypoints: Liste de waypoints
            
        Returns:
            (x, y) waypoint cible
        """
        x, y, _ = pose
        
        # Trouve le premier waypoint au-delà de la distance de visée
        for wp in waypoints:
            dist = np.sqrt((wp[0] - x)**2 + (wp[1] - y)**2)
            if dist >= self.lookahead_distance:
                return wp
        
        # Si tous les waypoints sont plus proches, retourne le dernier
        return waypoints[-1] if waypoints else None
    
    def _pure_pursuit(self, pose, target):
        """
        Loi de commande Pure Pursuit.
        
        Args:
            pose: (x, y, theta)
            target: (x_t, y_t)
            
        Returns:
            (v, omega)
        """
        x, y, theta = pose
        x_t, y_t = target
        
        # Calcule distance et angle vers la cible
        dx = x_t - x
        dy = y_t - y
        distance = np.sqrt(dx**2 + dy**2)
        
        # Angle cible
        target_theta = np.arctan2(dy, dx)
        
        # Erreur de cap
        theta_error = self._normalize_angle(target_theta - theta)
        
        # Vitesse linéaire proportionnelle à la distance
        v = self.k_v * distance
        
        # Vitesse angulaire proportionnelle à l'erreur de cap
        omega = self.k_theta * theta_error
        
        # Réduit la vitesse linéaire quand on tourne
        v *= np.cos(theta_error)
        
        return (v, omega)
    
    def _normalize_angle(self, angle):
        """Normalise l'angle entre [-pi, pi]."""
        while angle > np.pi:
            angle -= 2 * np.pi
        while angle < -np.pi:
            angle += 2 * np.pi
        return angle
    
    def is_waypoint_reached(self, pose, waypoint):
        """
        Vérifie si le waypoint actuel est atteint.
        
        Args:
            pose: (x, y, theta)
            waypoint: (x, y)
            
        Returns:
            True si dans le seuil
        """
        x, y, _ = pose
        dist = np.sqrt((waypoint[0] - x)**2 + (waypoint[1] - y)**2)
        return dist < self.waypoint_reached_threshold


################################################################################
PATH: ./tank_project/core/game/game_engine.py
################################################################################
"""
Moteur de Jeu - Arbitre Central

Ce module orchestre la boucle de jeu et coordonne tous les sous-systèmes.
Il agit comme l'arbitre, gérant :
- Les transitions d'état du jeu
- La gestion des chronomètres
- La validation et la résolution des tirs
- Les conditions de victoire/défaite
- Le cycle de jeu basé sur les ticks (30 FPS)

Le moteur de jeu reçoit :
- L'état du monde (poses des robots, obstacles de la perception)
- Les décisions de l'IA (cible, demande de tir)
- Les entrées humaines (déclencheurs)

Le moteur de jeu produit :
- L'état de jeu mis à jour (scores, temps de recharge, statut)
- Les événements (tirs effectués, touches enregistrées, fin de partie)

Logs : préfixe [GAME] pour tous les événements liés au jeu
"""

class GameEngine:
    """
    Arbitre central du jeu gérant la boucle de jeu et l'application des règles.
    
    Responsabilités :
    - Orchestrer le tick de jeu à 30 FPS
    - Valider et exécuter les tirs (humain + IA)
    - Mettre à jour les chronomètres et temps de recharge
    - Vérifier les conditions de victoire
    - Émettre des événements de jeu pour la visualisation
    
    NE fait PAS :
    - Prendre des décisions IA (ça c'est core/ia/)
    - Contrôler les moteurs (ça c'est core/control/)
    - Dessiner quoi que ce soit (ça c'est visualization/)
    """
    
    
    def __init__(self, config):
        """
        Initialise le moteur de jeu avec la configuration.
        
        Args:
            config: Configuration du jeu depuis config/game.yaml
                   (durée du match, temps de recharge, conditions de victoire)
        """
        self.config = config
        
        # Charge les règles
        self.rules = GameRules.from_config(config['match']) if 'match' in config else GameRules()
        
        # Sous-systèmes auxiliaires
        # Note : Raycast et Hits ont besoin de WorldModel, passé dans tick() ou initialisé plus tard
        # Pour l'instant nous créons des placeholders ou exigeons le monde dans tick
        self.raycast = None 
        self.hit_manager = None
        
        # Chronomètres
        self.cooldowns = CooldownManager(
            self.rules.ai_shot_cooldown, 
            self.rules.human_shot_cooldown
        )
        
        # État
        self.start_time = 0.0
        self.state = GameStatus.READY
        
        print("[GAME] Moteur initialisé")
    
    def _ensure_subsystems(self, world_model):
        """Initialisation paresseuse des sous-systèmes qui ont besoin du modèle du monde."""
        if self.raycast is None:
            from .raycast import Raycast
            from .hits import HitManager
            
            self.raycast = Raycast(world_model.grid)
            self.hit_manager = HitManager(self.raycast)
            print("[GAME] Sous-systèmes liés au WorldModel")

    def tick(self, world_state, ia_request, human_input):
        """
        Exécute un tick de jeu (appelé à 30 FPS).
        
        Args:
            world_state: Instance WorldModel (PAS juste un dict)
            ia_request: Décision IA (cible, demande de tir)
            human_input: Contrôles/déclencheurs humains
            
        Returns:
            dict: État du jeu mis à jour pour la visualisation
        """
        import time
        current_time = time.time()
        
        # Assure que les sous-systèmes sont prêts
        self._ensure_subsystems(world_state)
        
        # 0. Gère les transitions d'état du jeu
        if self.state == GameStatus.READY:
            # Vérifie la condition de démarrage (ex: entrée humaine)
            if human_input.get('start_game', False):
                self.start_time = current_time
                self.state = GameStatus.PLAYING
                self.hit_manager.clear_history()
                print("[GAME] Match DÉMARRÉ")
                
        elif self.state == GameStatus.PLAYING:
            # Vérifie l'expiration du temps
            elapsed = current_time - self.start_time
            if elapsed >= self.rules.match_duration_seconds:
                self.state = GameStatus.FINISHED
                self._check_win_condition()
                print("[GAME] Temps du match ÉCOULÉ")
                
            # 1. Traite les tirs
            self._handle_shooting(world_state, ia_request, human_input, current_time)
            
            # 2. Vérifie la condition de victoire (limite de score)
            game_over, winner = self._check_win_condition()
            if game_over and self.state != GameStatus.FINISHED:
                self.state = GameStatus.FINISHED
                print("[GAME] Match TERMINÉ. Vainqueur : {}".format(winner))

        # 3. Construit le dictionnaire d'état pour la vue
        scores = self.hit_manager.get_score_summary()
        
        state_dict = {
            'status': self.state.value,
            'time_remaining_s': max(0, self.rules.match_duration_seconds - (current_time - self.start_time)) if self.state == GameStatus.PLAYING else 0,
            
            # Scores
            'robot_4_hits_inflicted': scores['robot_4_hits_inflicted'],
            'robot_5_hits_inflicted': scores['robot_5_hits_inflicted'],
            'robot_4_hits_received': scores['robot_4_hits_received'],
            'robot_5_hits_received': scores['robot_5_hits_received'],
            
            # Temps de recharge
            'can_shoot_ai': self.cooldowns.can_shoot_ai(),
            'can_shoot_human': self.cooldowns.can_shoot_human(),
            
            # Info debug transmise
            'ai_has_los': ia_request.get('has_los', False),
            'ai_fire_request': ia_request.get('fire_request', False),
            'ai_state': ia_request.get('state', 'UNKNOWN')
        }
        
        return state_dict
    
    def _handle_shooting(self, world_state, ia_request, human_input, current_time):
        """Traite les demandes de tir de l'IA et de l'Humain."""
        
        # Poses des robots depuis WorldModel
        # On suppose que world_state a des méthodes ou attributs pour les poses
        # Nous avons besoin des poses les plus récentes.
        # Puisque world_state passé ici est l'objet WorldModel, on peut lui demander.
        # Mais attendez, main.py passe `world` qui est WorldModel.
        # On suppose qu'on peut obtenir les poses.
        
        r4_pose = world_state.get_robot_pose(4)
        r5_pose = world_state.get_robot_pose(5)
        
        if r4_pose is None or r5_pose is None:
            return # Impossible de tirer si les robots ne sont pas suivis
            
        # --- TIR IA ---
        if ia_request.get('fire_request', False):
            if self.cooldowns.can_shoot_ai():
                self.cooldowns.register_shot_ai()
                print("[GAME] Tir IA !")
                self.hit_manager.process_shot(4, r4_pose, r5_pose, current_time)
                
        # --- TIR HUMAIN ---
        if human_input.get('fire_request', False):
            if self.cooldowns.can_shoot_human():
                self.cooldowns.register_shot_human()
                print("[GAME] Tir Humain !")
                self.hit_manager.process_shot(5, r5_pose, r4_pose, current_time)

    def _check_win_condition(self):
        """
        Vérifie si le match doit se terminer en fonction des touches.
        
        Returns:
            (game_over: bool, winner: str or None)
        """
        scores = self.hit_manager.get_score_summary()
        ai_hits = scores['robot_4_hits_inflicted']
        human_hits = scores['robot_5_hits_inflicted']
        
        max_hits = self.rules.max_hits_to_win
        
        if ai_hits >= max_hits:
            return True, "AI"
        
        if human_hits >= max_hits:
            return True, "HUMAN"
            
        return False, None

# Imports en bas pour éviter les dépendances circulaires si nécessaire,
# ou en haut si sûr. 
from .rules import GameRules
from .timers import CooldownManager
from .state import GameStatus


################################################################################
PATH: ./tank_project/core/game/hits.py
################################################################################
"""
Touches - Gestion des Scores et Impacts

Gère la détection des touches et le score :
- Valide les touches (cible à portée, non obstruée)
- Enregistre les touches pour les deux robots
- Calcule les deltas de score
- Émet des événements de touche pour la visualisation

Fonctionne avec raycast.py pour la détection de collision.
"""

from dataclasses import dataclass
from typing import Optional


@dataclass
class HitEvent:
    """
    Représente un événement de touche unique.
    
    Utilisé pour la visualisation (effet flash, son, mise à jour score).
    """
    shooter_id: int  # 4 (AI) or 5 (Human)
    target_id: int   # 4 or 5
    impact_point: tuple  # (x, y) in meters
    timestamp: float
    damage: int = 1  # Future: variable damage
    

class HitManager:
    """
    Gère la validation des touches et le score.
    
    Collabore avec Raycast pour déterminer les touches valides.
    """
    
    def __init__(self, raycast):
        """
        Initialise le gestionnaire de touches.
        
        Args:
            raycast: Instance Raycast pour la détection de collision
        """
        self.raycast = raycast
        self.hit_history = []  # List of HitEvent
        
    
    def process_shot(self, shooter_id, shooter_pose, target_pose, current_time):
        """
        Traite une tentative de tir et détermine si elle touche.
        
        Args:
            shooter_id: 4 (IA) ou 5 (Humain)
            shooter_pose: (x, y, theta) du tireur
            target_pose: (x, y, theta) de la cible
            current_time: Temps de jeu actuel
            
        Returns:
            HitEvent si touché, None si manqué
        """
        x, y, theta = shooter_pose
        target_id = 5 if shooter_id == 4 else 4
        
        target_x, target_y, _ = target_pose
        
        # Portée max codée en dur pour l'instant (devrait venir des règles)
        MAX_RANGE = 5.0 
        
        # 1. Vérifie d'abord les obstacles
        # On ne se soucie que des obstacles plus proches que la cible
        dist_to_target = ((target_x - x)**2 + (target_y - y)**2)**0.5
        
        obstacle_hit = self.raycast.cast_shot((x, y), theta, dist_to_target)
        if obstacle_hit['hit'] and obstacle_hit['target'] == 'obstacle':
            # Obstacle touché avant la cible
            print("[HIT] Tir Robot {} bloqué par obstacle à {:.2f}m".format(shooter_id, obstacle_hit['distance']))
            return None
            
        # 2. Vérifie la collision avec le robot
        is_hit = self.raycast.check_robot_collision(
            (x, y), theta, MAX_RANGE, (target_x, target_y)
        )
        
        if is_hit:
            print("[HIT] Robot {} TOUCHE Robot {} !".format(shooter_id, target_id))
            
            # Calcule le point d'impact (approximatif)
            impact_point = (target_x, target_y) 
            
            event = HitEvent(
                shooter_id=shooter_id,
                target_id=target_id,
                impact_point=impact_point,
                timestamp=current_time
            )
            self.hit_history.append(event)
            return event
            
        return None
    
    def get_score_summary(self):
        """
        Calcule le score actuel à partir de l'historique des touches.
        
        Returns:
            dict: {
                'robot_4_hits': int,  # Touches marquées par IA
                'robot_5_hits': int,  # Touches marquées par Humain
            }
        """
        r4_hits = sum(1 for h in self.hit_history if h.shooter_id == 4)
        r5_hits = sum(1 for h in self.hit_history if h.shooter_id == 5)
        
        return {
            'robot_4_hits_inflicted': r4_hits,
            'robot_5_hits_inflicted': r5_hits,
            'robot_4_hits_received': r5_hits,
            'robot_5_hits_received': r4_hits
        }
    
    def clear_history(self):
        """Efface l'historique des touches (utilisé au démarrage d'un nouveau match)."""
        self.hit_history = []


################################################################################
PATH: ./tank_project/core/game/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/core/game/raycast.py
################################################################################
"""
Raycast - Détection de Collision de Tir

Implémente la détection de collision par lancer de rayons pour les tirs laser :
- Lance un rayon depuis la position du tireur dans la direction theta
- Vérifie les intersections avec :
  * Obstacles statiques (murs, blocs)
  * Obstacles dynamiques (robots)
- Retourne le premier impact ou None

Utilise la grille d'occupation de core/world pour la détection d'obstacles.
Implémente DDA (Digital Differential Analyzer) pour une traversée de grille efficace.

Logs : [RAYCAST] Impact détecté / Manqué
"""

import numpy as np
from typing import Optional, Tuple


class Raycast:
    """
    Détection de collision efficace basée sur les rayons pour les tirs.
    
    Utilise l'algorithme DDA pour traverser la grille d'occupation et détecter les impacts.
    """
    
    def __init__(self, occupancy_grid):
        """
        Initialise le raycast avec la grille d'occupation du monde.
        
        Args:
            occupancy_grid: Instance OccupancyGrid de core/world
        """
        self.grid = occupancy_grid
    
    
    def cast_shot(self, start_pos, theta, max_range_m):
        """
        Lance un rayon de tir et détecte les collisions.
        
        Args:
            start_pos: (x, y) position du tireur en mètres
            theta: Direction du tir en radians
            max_range_m: Portée maximale du tir
            
        Returns:
            dict: {
                'hit': bool,
                'target': 'robot4' | 'robot5' | 'obstacle' | None,
                'impact_point': (x, y) en mètres ou None,
                'distance': float en mètres
            }
        """
        start_x, start_y = start_pos
        
        # Vecteur direction du rayon
        dx = np.cos(theta)
        dy = np.sin(theta)
        
        # Parcours de grille
        current_dist = 0.0
        step_size = self.grid.resolution
        
        # Vérifie chaque point le long du rayon
        while current_dist <= max_range_m:
            curr_x = start_x + dx * current_dist
            curr_y = start_y + dy * current_dist
            
            # 1. Vérifie les limites de la carte
            if not (0 <= curr_x <= self.grid.width_m and 0 <= curr_y <= self.grid.height_m):
                break
                
            # 2. Vérifie les obstacles statiques utilisant la grille d'occupation
            grid_val = self.grid.get_value(curr_x, curr_y)
            if grid_val > 50:  # Threshold for occupied
                return {
                    'hit': True,
                    'target': 'obstacle',
                    'impact_point': (curr_x, curr_y),
                    'distance': current_dist
                }
            
            current_dist += step_size
            
        return {
            'hit': False,
            'target': None,
            'impact_point': None,
            'distance': max_range_m
        }

    def check_robot_collision(self, start_pos, theta, max_range_m, target_pos, target_radius_m=0.15):
        """
        Vérifie si le rayon touche un robot spécifique.
        
        Args:
            start_pos: (x,y) tireur
            theta: angle
            max_range_m: portée max
            target_pos: (x,y) centre cible
            target_radius_m: rayon de touche cible
        """
        # Vecteur du tireur à la cible
        sx, sy = start_pos
        tx, ty = target_pos
        
        val_x = tx - sx
        val_y = ty - sy
        
        # Projette le centre de la cible sur le rayon
        # Vecteur rayon : (cos, sin)
        ray_x, ray_y = np.cos(theta), np.sin(theta)
        
        # Produit scalaire
        t = val_x * ray_x + val_y * ray_y
        
        # Point le plus proche sur le rayon vers le centre de la cible
        closest_x = sx + t * ray_x
        closest_y = sy + t * ray_y
        
        # Vérification des distances
        if t < 0: return False # Cible derrière le tireur
        if t > max_range_m: return False # Cible hors de portée
        
        # Distance du point le plus proche au centre de la cible
        dist_sq = (closest_x - tx)**2 + (closest_y - ty)**2
        
        return dist_sq <= (target_radius_m**2)

    def _check_line_of_sight(self, pos1, pos2):
        """Vérifie si la ligne de vue (LOS) est dégagée entre deux points (version simple)."""
        x1, y1 = pos1
        x2, y2 = pos2
        
        dist = np.sqrt((x2-x1)**2 + (y2-y1)**2)
        if dist == 0: return True
        
        dx = (x2 - x1) / dist
        dy = (y2 - y1) / dist
        
        # Pas à pas dans la grille
        curr_dist = 0
        step = self.grid.resolution
        
        while curr_dist < dist:
            cx = x1 + dx * curr_dist
            cy = y1 + dy * curr_dist
            
            if self.grid.get_value(cx, cy) > 50:
                return False
                
            curr_dist += step
            
        return True



################################################################################
PATH: ./tank_project/core/game/rules.py
################################################################################
"""
Règles du Jeu - Configuration & Constantes

Définit tous les paramètres et règles du jeu :
- Temps de recharge des tirs (IA vs Humain)
- Durée du match
- Conditions de victoire
- Règles de score

Toutes les valeurs sont chargées depuis config/game.yaml.
Ce module fournit la validation et les valeurs par défaut.
"""

from dataclasses import dataclass


@dataclass
class GameRules:
    """
    Règles et paramètres du jeu.
    
    Chargé depuis config/game.yaml mais fournit des valeurs par défaut raisonnables.
    """
    
    # Chronométrage du match
    match_duration_seconds: float = 180.0  # Défaut 3 minutes
    
    # Temps de recharge des tirs
    human_shot_cooldown: float = 5.0  # L'humain peut tirer toutes les 5 secondes
    ai_shot_cooldown: float = 3.0     # L'IA peut tirer toutes les 3 secondes
    
    # Conditions de victoire
    max_hits_to_win: int = 10         # Le premier à 10 touches gagne
    sudden_death: bool = False        # Continuer après l'expiration du temps ?
    
    # Mécanique de tir
    shot_range_meters: float = 5.0    # Portée effective maximale
    shot_speed_mps: float = 10.0      # Vitesse du tir (pour l'animation)
    
    @classmethod
    def from_config(cls, config_dict):
        """
        Crée les règles à partir du dictionnaire de configuration.
        
        Args:
            config_dict: YAML analysé depuis config/game.yaml['match']
            
        Returns:
            Instance GameRules avec valeurs validées
        """
        # Map config keys to class attributes
        mapped = {}
        
        if 'duration_seconds' in config_dict:
            mapped['match_duration_seconds'] = config_dict['duration_seconds']
        if 'human_shot_seconds' in config_dict:
            mapped['human_shot_cooldown'] = config_dict['human_shot_seconds']
        if 'ai_shot_seconds' in config_dict:
            mapped['ai_shot_cooldown'] = config_dict['ai_shot_seconds']
        if 'max_hits' in config_dict:
            mapped['max_hits_to_win'] = config_dict['max_hits']
        if 'sudden_death' in config_dict:
            mapped['sudden_death'] = config_dict['sudden_death']
        if 'range_m' in config_dict:
            mapped['shot_range_meters'] = config_dict['range_m']
        if 'speed_mps' in config_dict:
            mapped['shot_speed_mps'] = config_dict['speed_mps']
        
        return cls(**mapped)
    
    def validate(self):
        """
        Valide la cohérence des règles.
        
        Raises:
            ValueError: Si les règles sont incohérentes ou invalides
        """
        if self.match_duration_seconds <= 0:
            raise ValueError("Match duration must be positive")
        if self.human_shot_cooldown <= 0 or self.ai_shot_cooldown <= 0:
            raise ValueError("Cooldowns must be positive")
        if self.max_hits_to_win < 1:
            raise ValueError("Max hits must be >= 1")


################################################################################
PATH: ./tank_project/core/game/state.py
################################################################################
"""
État du Jeu - Statut Complet du Jeu

Maintient l'état complet du match en cours :
- Scores des robots (touches données/reçues)
- Chronomètre du match (écoulé, restant)
- Chronomètres de recharge (prochain tir autorisé pour chaque robot)
- Statut du jeu (calibration, jeu, pause, fini)
- Information sur le vainqueur

Ceci est une structure de données pure sans logique.
Toutes les modifications d'état sont faites par game_engine.py.
"""

from dataclasses import dataclass
from enum import Enum

class GameStatus(Enum):
    """États du cycle de vie du jeu"""
    CALIBRATION = "calibration"
    READY = "ready"
    PLAYING = "playing"
    PAUSED = "paused"
    FINISHED = "finished"


@dataclass
class RobotScore:
    """Information de score par robot"""
    robot_id: int
    hits_inflicted: int = 0  # Touches marquées par ce robot sur l'ennemi
    hits_received: int = 0   # Touches reçues par ce robot
    shots_fired: int = 0     # Total des tirs tentés
    

@dataclass
class GameState:
    """
    Instantané complet de l'état du jeu.
    
    Ceci est la source unique de vérité pour le statut du jeu.
    Immuable entre les ticks - game_engine crée un nouvel état à chaque tick.
    """
    status: GameStatus
    
    # Suivi du temps
    match_start_time: float  # Timestamp Unix
    current_time: float      # Timestamp Unix
    match_duration: float    # Durée totale match en secondes
    
    # Scores
    robot_4_score: RobotScore  # Robot IA
    robot_5_score: RobotScore  # Robot Humain
    
    # Temps de recharge (Timestamps Unix)
    next_shot_robot_4: float
    next_shot_robot_5: float
    
    # Info vainqueur (None si en cours)
    winner: str = None  # "AI", "HUMAN", ou "DRAW"
    
    @property
    def time_remaining(self):
        """Calcule le temps restant en secondes."""
        elapsed = self.current_time - self.match_start_time
        return max(0, self.match_duration - elapsed)
    
    @property
    def can_shoot_ai(self):
        """Vérifie si le cooldown IA permet de tirer."""
        return self.current_time >= self.next_shot_robot_4
    
    @property
    def can_shoot_human(self):
        """Vérifie si le cooldown humain permet de tirer."""
        return self.current_time >= self.next_shot_robot_5


################################################################################
PATH: ./tank_project/core/game/timers.py
################################################################################
"""
Chronomètres - Gestion du Temps de Recharge & Match

Gère toutes les mécaniques de jeu basées sur le temps :
- Chronomètre de match (total écoulé, restant)
- Temps de recharge des tirs par robot
- Buffs/debuffs temporaires (futur)

Tous les temps sont en secondes (float).
Utilise l'heure système (time.time()) pour le chronométrage absolu.
"""

import time


class Timer:
    """Compte à rebours simple."""
    
    def __init__(self, duration_seconds):
        self.duration = duration_seconds
        self.start_time = None
        
    def start(self):
        """Démarre le chronomètre."""
        self.start_time = time.time()
        
    def elapsed(self):
        """Obtient le temps écoulé en secondes."""
        if self.start_time is None:
            return 0.0
        return time.time() - self.start_time
    
    def remaining(self):
        """Obtient le temps restant en secondes."""
        return max(0.0, self.duration - self.elapsed())
    
    def is_expired(self):
        """Vérifie si le chronomètre est expiré."""
        return self.elapsed() >= self.duration
    
    def reset(self):
        """Réinitialise le chronomètre au début."""
        self.start_time = None


class CooldownManager:
    """
    Gère les temps de recharge des tirs pour les deux robots.
    
    Suit quand chaque robot a tiré pour la dernière fois et quand il peut tirer à nouveau.
    """
    
    def __init__(self, ai_cooldown_sec, human_cooldown_sec):
        """
        Initialise le gestionnaire de temps de recharge.
        
        Args:
            ai_cooldown_sec: Durée de recharge robot IA
            human_cooldown_sec: Durée de recharge robot Humain
        """
        self.ai_cooldown = ai_cooldown_sec
        self.human_cooldown = human_cooldown_sec
        
        self.last_shot_ai = 0.0
        self.last_shot_human = 0.0
        
    def can_shoot_ai(self):
        """Vérifie si l'IA peut tirer maintenant."""
        return time.time() >= self.last_shot_ai + self.ai_cooldown
    
    def can_shoot_human(self):
        """Vérifie si l'humain peut tirer maintenant."""
        return time.time() >= self.last_shot_human + self.human_cooldown
    
    def register_shot_ai(self):
        """
        Enregistre que l'IA a tiré.
        
        Logs :
            [TIMER] Recharge IA commencée (X s restantes)
        """
        self.last_shot_ai = time.time()
        
    def register_shot_human(self):
        """
        Enregistre que l'humain a tiré.
        
        Logs :
            [TIMER] Recharge Humain commencée (X s restantes)
        """
        self.last_shot_human = time.time()
    
    def time_until_next_shot_ai(self):
        """Obtient les secondes jusqu'au prochain tir IA."""
        return max(0.0, self.last_shot_ai + self.ai_cooldown - time.time())
    
    def time_until_next_shot_human(self):
        """Obtient les secondes jusqu'au prochain tir Humain."""
        return max(0.0, self.last_shot_human + self.human_cooldown - time.time())


################################################################################
PATH: ./tank_project/core/ia/behavior_tree.py
################################################################################
"""
Arbre de Comportement - Framework de Décision IA

Implémente un arbre de comportement composable pour la prise de décision IA :
- Nœuds Sélecteurs (essaient les enfants jusqu'à succès)
- Nœuds Séquences (exécutent tous les enfants dans l'ordre)
- Nœuds Conditions (vérifient l'état du monde)
- Nœuds Actions (produisent des décisions)

L'IA ne modifie PAS directement l'état du jeu.
Elle retourne seulement des INTENTIONS : (position_cible, demande_tir).

Logs : [BT] Nœud X succès/échec
"""

from enum import Enum
from abc import ABC, abstractmethod
from .decisions import (
    is_enemy_too_close,
    has_line_of_sight,
    is_optimal_firing_range,
    should_retreat,
    find_nearest_cover,
    calculate_flank_position
)


class NodeStatus(Enum):
    """Statut d'exécution du nœud de l'arbre comportemental."""
    SUCCESS = "success"
    FAILURE = "failure"
    RUNNING = "running"


class BTNode(ABC):
    """
    Classe de base pour tous les nœuds de l'arbre comportemental.
    
    Tous les nœuds implémentent tick() qui retourne un NodeStatus.
    """
    
    def __init__(self, name):
        self.name = name
    
    @abstractmethod
    def tick(self, context):
        """
        Exécute ce nœud avec le contexte donné.
        
        Args:
            context: dict avec état du monde, poses robots, etc.
            
        Returns:
            NodeStatus
        """
        pass


class Selector(BTNode):
    """
    Nœud Sélecteur : essaie les enfants jusqu'à ce que l'un réussisse.
    
    Retourne SUCCESS si un enfant réussit.
    Retourne FAILURE si tous les enfants échouent.
    """
    
    def __init__(self, name, children):
        super().__init__(name)
        self.children = children
    
    def tick(self, context):
        for child in self.children:
            status = child.tick(context)
            if status == NodeStatus.SUCCESS:
                return NodeStatus.SUCCESS
            elif status == NodeStatus.RUNNING:
                return NodeStatus.RUNNING
        return NodeStatus.FAILURE


class Sequence(BTNode):
    """
    Nœud Séquence : exécute les enfants dans l'ordre.
    
    Retourne SUCCESS si tous les enfants réussissent.
    Retourne FAILURE si un enfant échoue.
    """
    
    def __init__(self, name, children):
        super().__init__(name)
        self.children = children
    
    def tick(self, context):
        for child in self.children:
            status = child.tick(context)
            if status == NodeStatus.FAILURE:
                return NodeStatus.FAILURE
            elif status == NodeStatus.RUNNING:
                return NodeStatus.RUNNING
        return NodeStatus.SUCCESS


class Condition(BTNode):
    """
    Nœud Condition : vérifie une fonction prédicat.
    
    Retourne SUCCESS si le prédicat est Vrai, FAILURE sinon.
    """
    
    def __init__(self, name, predicate_fn):
        super().__init__(name)
        self.predicate_fn = predicate_fn
    
    def tick(self, context):
        if self.predicate_fn(context):
            return NodeStatus.SUCCESS
        return NodeStatus.FAILURE


class Action(BTNode):
    """
    Nœud Action : exécute une fonction d'action.
    
    La fonction d'action modifie context['ai_output'] avec les décisions.
    """
    
    def __init__(self, name, action_fn):
        super().__init__(name)
        self.action_fn = action_fn
    
    def tick(self, context):
        return self.action_fn(context)


# --- Action Functions ---

def action_retreat_to_cover(context):
    """
    Action : Trouver une couverture et définir comme cible.
    
    Modifie context['ai_output'] avec la cible de repli.
    """
    cover_pos = find_nearest_cover(context)
    
    if cover_pos is not None:
        context['ai_output']['target_position'] = cover_pos
        context['ai_output']['state'] = 'RETREAT'
        context['ai_output']['fire_request'] = False
        print("[BT] Action : REPLI vers couverture à ({:.2f}, {:.2f})".format(
            cover_pos[0], cover_pos[1]))
        return NodeStatus.SUCCESS
    else:
        print("[BT] Action : REPLI échoué - pas de couverture")
        return NodeStatus.FAILURE


def action_aim_and_fire(context):
    """
    Action : Viser l'ennemi et demander le tir.
    
    Modifie context['ai_output'] avec la demande de tir.
    """
    human_pose = context.get('human_pose')
    
    if human_pose is None:
        return NodeStatus.FAILURE
    
    context['ai_output']['target_position'] = None  # Rester sur place
    context['ai_output']['target_orientation'] = human_pose[:2]  # Viser l'ennemi
    context['ai_output']['fire_request'] = True
    context['ai_output']['state'] = 'ATTACK'
    
    print("[BT] Action : VISER ET TIRER sur ennemi")
    return NodeStatus.SUCCESS


def action_find_flank_position(context):
    """
    Action : Calculer une position de contournement.
    """
    flank_pos = calculate_flank_position(context)
    
    if flank_pos is not None:
        context['ai_output']['target_position'] = flank_pos
        context['ai_output']['state'] = 'FLANK'
        context['ai_output']['fire_request'] = False
        print("[BT] Action : CONTOURNEMENT vers ({:.2f}, {:.2f})".format(
            flank_pos[0], flank_pos[1]))
        return NodeStatus.SUCCESS
    else:
        return NodeStatus.FAILURE


def action_move_to_flank(context):
    """
    Action : Se déplacer vers la position de contournement.
    """
    # C'est géré par le suiveur de trajectoire, confirmer juste qu'on a une cible
    target = context['ai_output'].get('target_position')
    if target is not None:
        print("[BT] Action : Déplacement vers position contournement")
        return NodeStatus.RUNNING
    return NodeStatus.FAILURE


def action_hunt_enemy(context):
    """
    Action : Se déplacer vers la dernière position connue de l'ennemi.
    """
    human_pose = context.get('human_pose')
    
    if human_pose is not None:
        context['ai_output']['target_position'] = human_pose[:2]
        context['ai_output']['state'] = 'HUNT'
        context['ai_output']['fire_request'] = False
        print("[BT] Action : CHASSE - déplacement vers position ennemie")
        return NodeStatus.SUCCESS
    
    return NodeStatus.FAILURE


def build_ai_behavior_tree():
    """
    Construit l'arbre de comportement principal de l'IA.
    
    Structure :
    
    Sélecteur (Racine)
      +-- Séquence (SURVIVAL)
      |   +-- Condition : "ennemi trop proche ?"
      |   +-- Action : "repli vers couverture"
      |
      +-- Séquence (ATTACK)
      |   +-- Condition : "ligne de vue ?"
      |   +-- Condition : "portée optimale ?"
      |   +-- Action : "viser et demander feu"
      |
      +-- Séquence (FLANK)
          +-- Action : "trouver position contournement"
          +-- Action : "déplacement contournement"
    
    Returns:
        BTNode: racine de l'arbre comportemental
    """
    # Branche SURVIVAL : repli si ennemi trop proche
    survival_sequence = Sequence("SURVIVAL", [
        Condition("enemy_too_close", is_enemy_too_close),
        Action("retreat_to_cover", action_retreat_to_cover)
    ])
    
    # Branche ATTACK : tir si tir clair et portée optimale
    attack_sequence = Sequence("ATTACK", [
        Condition("has_line_of_sight", has_line_of_sight),
        Condition("in_optimal_range", is_optimal_firing_range),
        Action("aim_and_fire", action_aim_and_fire)
    ])
    
    # Branche FLANK : essayer d'obtenir une meilleure position
    flank_sequence = Sequence("FLANK", [
        Action("find_flank_position", action_find_flank_position),
        Action("move_to_flank", action_move_to_flank)
    ])
    
    # Branche HUNT : repli - juste chasser l'ennemi
    hunt_action = Action("hunt_enemy", action_hunt_enemy)
    
    # Sélecteur racine : essaie survie d'abord, puis attaque, puis contournement, puis chasse
    root = Selector("AI_ROOT", [
        survival_sequence,
        attack_sequence,
        flank_sequence,
        hunt_action
    ])
    
    print("[BT] Arbre de comportement construit")
    return root


class BehaviorTreeExecutor:
    """
    Exécuteur qui lance l'arbre comportemental à chaque tick.
    """
    
    def __init__(self):
        self.tree = build_ai_behavior_tree()
    
    def execute(self, context):
        """
        Exécute l'arbre comportemental avec le contexte donné.
        
        Args:
            context: Dictionnaire d'état du monde. Doit contenir :
                - ai_pose: (x, y, theta)
                - human_pose: (x, y, theta)
                - occupancy_grid: objet grille
                
        Returns:
            dict: Décisions de sortie IA
        """
        # Initialise la structure de sortie
        context['ai_output'] = {
            'target_position': None,
            'target_orientation': None,
            'fire_request': False,
            'state': 'IDLE',
            'has_los': False
        }
        
        # Vérifie LOS pour la sortie
        context['ai_output']['has_los'] = has_line_of_sight(context)
        
        # Exécute l'arbre
        status = self.tree.tick(context)
        
        print("[BT] Exécution arbre : {}".format(status.value))
        
        return context['ai_output']


################################################################################
PATH: ./tank_project/core/ia/decisions.py
################################################################################
"""
Décisions - Fonctions de Décision Tactique

Fournit les fonctions d'évaluation tactique utilisées par les conditions de l'arbre comportemental :
- L'ennemi est-il trop proche ? (évaluation de la menace)
- A-t-on une ligne de vue ? (vérification visibilité)
- Sommes-nous à portée de tir optimale ?
- Y a-t-il une couverture à proximité ?
- Devrions-nous nous replier ?

Toutes les fonctions prennent un dict context et retournent bool ou une valeur tactique.

Logs : [DECISION] Évaluation X : valeur Y
"""

import numpy as np
from typing import Dict, Tuple, Optional, List


def is_enemy_too_close(context: Dict, threshold_m: float = 0.8) -> bool:
    """
    Vérifie si l'ennemi est dangereusement proche.
    
    Args:
        context: État du monde avec poses robots
        threshold_m: Seuil de danger en mètres
        
    Returns:
        True si ennemi dans le seuil
    """
    ai_pos = context['ai_pose'][:2]
    human_pos = context['human_pose'][:2]
    distance = np.linalg.norm(np.array(ai_pos) - np.array(human_pos))
    
    return distance < threshold_m


def has_line_of_sight(context: Dict) -> bool:
    """
    Vérifie si l'IA a une ligne de vue dégagée vers l'ennemi.
    
    Utilise le raycast de core.world pour vérifier les obstacles.
    
    Args:
        context: État du monde avec poses robots et raycast
        
    Returns:
        True si une ligne de vue claire existe
        
    Logs :
        [DECISION] Verif LOS : CLAIR/BLOQUE
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    raycast = context.get('raycast_sys')
    
    if ai_pose is None or human_pose is None:
        return False
    
    if raycast is None:
        # Pas de système raycast disponible, suppose LOS dégagée
        print("[DECISION] Verif LOS : PAS DE SYSTEME RAYCAST")
        return True
    
    # Utilise la vérification LOS interne du raycast
    ai_pos = ai_pose[:2]
    human_pos = human_pose[:2]
    
    los_clear = raycast._check_line_of_sight(ai_pos, human_pos)
    
    status = "CLAIR" if los_clear else "BLOQUE"
    print("[DECISION] Verif LOS : {}".format(status))
    
    return los_clear


def is_optimal_firing_range(context: Dict, 
                            min_range: float = 1.2, 
                            max_range: float = 3.5) -> bool:
    """
    Vérifie si l'ennemi est à portée de tir optimale.
    
    Trop proche : risque de riposte
    Trop loin : la précision diminue
    
    Args:
        context: État du monde
        min_range: Distance minimale de sécurité
        max_range: Distance effective maximale
        
    Returns:
        True si dans la portée optimale
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    
    if ai_pose is None or human_pose is None:
        return False
    
    ai_pos = np.array(ai_pose[:2])
    human_pos = np.array(human_pose[:2])
    
    distance = np.linalg.norm(ai_pos - human_pos)
    
    in_range = min_range <= distance <= max_range
    
    print("[DECISION] Verif portée tir : distance={:.2f}m, optimal={}".format(
        distance, in_range))
    
    return in_range


def find_nearest_cover(context: Dict) -> Optional[Tuple[float, float]]:
    """
    Trouve la position de couverture la plus proche par rapport à l'ennemi.
    
    Couverture = obstacle qui bloque la ligne de vue vers l'ennemi.
    
    Args:
        context: État du monde avec grille d'occupation
        
    Returns:
        (x, y) position de la meilleure couverture, ou None
        
    Algorithme :
        1. Récupère toutes les cellules d'obstacle de la grille
        2. Pour chaque obstacle, vérifie s'il bloque la LOS vers l'ennemi
        3. Classe par :
           - Distance à l'IA (plus proche est mieux)
           - Efficacité de la couverture (bloque bien la LOS)
        4. Retourne la meilleure position
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    grid = context.get('occupancy_grid')
    
    if ai_pose is None or human_pose is None or grid is None:
        return None
    
    ai_pos = np.array(ai_pose[:2])
    human_pos = np.array(human_pose[:2])
    
    # Direction de l'ennemi vers l'IA
    direction = ai_pos - human_pos
    dist = np.linalg.norm(direction)
    if dist < 0.1:
        return None
    direction = direction / dist
    
    # Cherche des positions de couverture : déplacement perpendiculaire à la direction ennemie
    perpendicular = np.array([-direction[1], direction[0]])
    
    # Vérifie les positions à gauche et à droite de la position actuelle
    cover_distance = 0.5  # mètres de la position actuelle
    
    candidates = [
        ai_pos + perpendicular * cover_distance,
        ai_pos - perpendicular * cover_distance,
        ai_pos + direction * cover_distance,  # S'éloigne de l'ennemi
    ]
    
    # Trouve une position de couverture valide (dans les limites de l'arène)
    for candidate in candidates:
        x, y = candidate
        if 0 < x < grid.width_m and 0 < y < grid.height_m:
            if not grid.is_occupied(x, y):
                print("[DECISION] Couverture trouvée à ({:.2f}, {:.2f})".format(x, y))
                return (x, y)
    
    print("[DECISION] Aucune couverture trouvée")
    return None


def should_retreat(context: Dict) -> bool:
    """
    Décision de repli complète.
    
    Repli si :
    - Ennemi trop proche ET a la LOS
    - Santé faible (fonctionnalité future)
    - Encerclé
    
    Args:
        context: État du monde
        
    Returns:
        True si devrait se replier
    """
    too_close = is_enemy_too_close(context)
    los = has_line_of_sight(context)
    
    should_run = too_close and los
    
    if should_run:
        print("[DECISION] REPLI déclenché : ennemi trop proche avec LOS")
    
    return should_run


def calculate_flank_position(context: Dict) -> Optional[Tuple[float, float]]:
    """
    Calcule la position de contournement optimale.
    
    But : position qui :
    - Donne à l'IA une ligne de vue sur l'ennemi
    - N'est PAS dans la ligne de vue actuelle de l'ennemi
    - Utilise une couverture pour l'approche
    
    Args:
        context: État du monde
        
    Returns:
        (x, y) position cible de contournement
        
    Algorithme :
        1. Récupère position et orientation ennemi
        2. Trouve positions 90 deg gauche/droite de l'orientation ennemie
        3. Filtre par disponibilité couverture pendant l'approche
        4. Choisit la position valide la plus proche
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    grid = context.get('occupancy_grid')
    
    if ai_pose is None or human_pose is None:
        return None
    
    ai_pos = np.array(ai_pose[:2])
    human_pos = np.array(human_pose[:2])
    human_theta = human_pose[2] if len(human_pose) > 2 else 0.0
    
    # Direction du regard ennemi
    enemy_facing = np.array([np.cos(human_theta), np.sin(human_theta)])
    
    # Positions de flanc : 90 degrés par rapport au regard ennemi
    flank_distance = 1.5  # mètres de l'ennemi
    
    # Flanc gauche (perpendiculaire)
    left_perp = np.array([-enemy_facing[1], enemy_facing[0]])
    left_flank = human_pos + left_perp * flank_distance
    
    # Flanc droit
    right_perp = np.array([enemy_facing[1], -enemy_facing[0]])
    right_flank = human_pos + right_perp * flank_distance
    
    # Choisit le flanc le plus proche de l'IA
    dist_left = np.linalg.norm(ai_pos - left_flank)
    dist_right = np.linalg.norm(ai_pos - right_flank)
    
    if dist_left < dist_right:
        chosen_flank = left_flank
    else:
        chosen_flank = right_flank
    
    x, y = chosen_flank
    
    # Valide que la position est dans l'arène
    if grid is not None:
        if not (0 < x < grid.width_m and 0 < y < grid.height_m):
            print("[DECISION] Position contournement hors limites")
            return None
        if grid.is_occupied(x, y):
            print("[DECISION] Position contournement occupée")
            return None
    
    print("[DECISION] Position contournement : ({:.2f}, {:.2f})".format(x, y))
    return (x, y)


def get_distance_to_enemy(context: Dict) -> float:
    """
    Obtient la distance entre l'IA et l'ennemi.
    
    Args:
        context: État du monde
        
    Returns:
        Distance en mètres, ou l'infini si poses inconnues
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    
    if ai_pose is None or human_pose is None:
        return float('inf')
    
    ai_pos = np.array(ai_pose[:2])
    human_pos = np.array(human_pose[:2])
    
    return float(np.linalg.norm(ai_pos - human_pos))


def get_angle_to_enemy(context: Dict) -> float:
    """
    Obtient l'angle de l'IA vers l'ennemi.
    
    Args:
        context: État du monde
        
    Returns:
        Angle en radians, ou 0 si poses inconnues
    """
    ai_pose = context.get('ai_pose')
    human_pose = context.get('human_pose')
    
    if ai_pose is None or human_pose is None:
        return 0.0
    
    dx = human_pose[0] - ai_pose[0]
    dy = human_pose[1] - ai_pose[1]
    
    return float(np.arctan2(dy, dx))


################################################################################
PATH: ./tank_project/core/ia/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/core/ia/planners/a_star.py
################################################################################
"""
Algorithme de Planification A*

Implémente la recherche de chemin A* sur la grille d'occupation :
- Trouve le chemin le plus court sans collision
- Utilise des heuristiques configurables
- Gère les obstacles dynamiques (robots)
- Retourne une liste de waypoints en mètres

Le planificateur travaille sur la carte de coût (costmap) gonflée de core/world.

Logs : [ASTAR] Chemin trouvé : N waypoints, longueur : M mètres
"""

import numpy as np
import heapq
from typing import List, Tuple, Optional
from .heuristics import euclidean_distance, manhattan_distance, diagonal_distance


class AStarPlanner:
    """
    Recherche de chemin A* sur grille d'occupation 2D.
    
    Trouve le chemin optimal du départ au but en évitant les obstacles.
    """
    
    def __init__(self, occupancy_grid, heuristic='euclidean'):
        """
        Initialise le planificateur A*.
        
        Args:
            occupancy_grid: OccupancyGrid depuis core/world
            heuristic: 'euclidean', 'manhattan', ou 'diagonal'
        """
        self.grid = occupancy_grid
        self.heuristic_name = heuristic
        
    def _heuristic(self, cell1, cell2):
        """Calcule le coût heuristique."""
        if self.heuristic_name == 'manhattan':
            return manhattan_distance(cell1, cell2)
        elif self.heuristic_name == 'diagonal':
            return diagonal_distance(cell1, cell2)
        else:
            return euclidean_distance(cell1, cell2)

    
    def plan(self, start_m: Tuple[float, float], 
             goal_m: Tuple[float, float]) -> Optional[List[Tuple[float, float]]]:
        """
        Trouve un chemin du départ au but.
        """
        start_cell = self.grid.world_to_grid(*start_m)
        goal_cell = self.grid.world_to_grid(*goal_m)
        
        print(f"[ASTAR] Planification de {start_m} vers {goal_m}")
        print(f"[ASTAR]   Cellule départ : {start_cell}, Cellule but : {goal_cell}")
        print(f"[ASTAR]   Taille grille : {self.grid.grid.shape}")
        
        # Vérification des limites
        if not self.grid._is_valid_cell(*start_cell):
            print(f"[ASTAR]   ERREUR : Cellule départ {start_cell} HORS LIMITES")
            return None
        if not self.grid._is_valid_cell(*goal_cell):
            print(f"[ASTAR]   ERREUR : Cellule but {goal_cell} HORS LIMITES")
            return None
        
        # Note : On ne vérifie pas si le départ ou le but est occupé
        # Départ : le robot est déjà là
        # But : le robot ennemi est là - on VEUT aller là-bas !
            
        # Initialisation
        open_set = []
        heapq.heappush(open_set, (0, start_cell))
        
        came_from = {}
        g_score = {start_cell: 0}
        f_score = {start_cell: self._heuristic(start_cell, goal_cell)}
        
        closed_set = set()
        
        while open_set:
            current = heapq.heappop(open_set)[1]
            
            if current == goal_cell:
                path_cells = self._reconstruct_path(came_from, current)
                simplified = self._simplify_path(path_cells)
                result = [self.grid.grid_to_world(r, c) for r, c in simplified]
                print(f"[ASTAR]   SUCCES : Chemin trouvé avec {len(result)} waypoints")
                return result
            
            closed_set.add(current)
            
            for neighbor, cost in self._get_neighbors(current, start_cell):
                if neighbor in closed_set:
                    continue
                    
                tentative_g = g_score[current] + cost
                
                if neighbor not in g_score or tentative_g < g_score[neighbor]:
                    came_from[neighbor] = current
                    g_score[neighbor] = tentative_g
                    f = tentative_g + self._heuristic(neighbor, goal_cell)
                    f_score[neighbor] = f
                    heapq.heappush(open_set, (f, neighbor))
        
        print(f"[ASTAR]   ECHEC : Aucun chemin trouvé (exploré {len(closed_set)} cellules)")
        return None
        
    def _get_neighbors(self, cell, start_cell=None, ignore_radius=5):
        """Obtient les cellules voisines valides (8-connexité).
        
        Utilise la COSTMAP (gonflée) pour la vérification de collision, pas la grille brute.
        Si start_cell est fourni et qu'on est dans ignore_radius,
        on ignore les obstacles (pour s'échapper de l'empreinte du robot).
        """
        row, col = cell
        neighbors = []
        
        # Utilise la costmap si disponible (obstacles gonflés), sinon grille
        collision_grid = getattr(self.grid, 'costmap', self.grid.grid)
        
        for dr in [-1, 0, 1]:
            for dc in [-1, 0, 1]:
                if dr == 0 and dc == 0:
                    continue
                    
                r, c = row + dr, col + dc
                
                # Vérifie la validité
                if self.grid._is_valid_cell(r, c):
                    # Si près du départ, ignore les obstacles (empreinte du robot)
                    if start_cell is not None:
                        dist_to_start = abs(r - start_cell[0]) + abs(c - start_cell[1])
                        if dist_to_start <= ignore_radius:
                            cost = 1.414 if (dr != 0 and dc != 0) else 1.0
                            neighbors.append(((r, c), cost))
                            continue
                    
                    # Vérifie l'occupation sur la COSTMAP (gonflée, marges de sécurité)
                    if collision_grid[r, c] < 0.5:
                        cost = 1.414 if (dr != 0 and dc != 0) else 1.0
                        neighbors.append(((r, c), cost))
                        
        return neighbors
    
    def _reconstruct_path(self, came_from, current):
        """Reconstruit le chemin du but au départ."""
        total_path = [current]
        while current in came_from:
            current = came_from[current]
            total_path.append(current)
        return total_path[::-1] # Inverse
    
    def _simplify_path(self, path_cells):
        """Lissage simple du chemin (saute les étapes minimes)."""
        if len(path_cells) <= 2:
            return path_cells
            
        simplified = [path_cells[0]]
        for i in range(1, len(path_cells)-1):
            # Garde chaque Nième point ou vérifie la ligne de vue (coûteux)
            # Pour l'instant, retourne tous les points pour être sûr pour le suiveur de trajectoire
            simplified.append(path_cells[i])
            
        simplified.append(path_cells[-1])
        return simplified


################################################################################
PATH: ./tank_project/core/ia/planners/heuristics.py
################################################################################
"""
Heuristiques - Fonctions de Coût pour la Planification de Chemin

Fournit des fonctions heuristiques pour A* et autres planificateurs :
- Distance Euclidienne (standard, admissible)
- Distance de Manhattan (basée grille)
- Distance Diagonale (Chebyshev + coût diagonal)
- Heuristiques personnalisées sensibles à la costmap

Toutes les heuristiques doivent être admissibles (ne jamais surestimer).
"""

import numpy as np
from typing import Tuple


def euclidean_distance(cell1: Tuple[int, int], cell2: Tuple[int, int]) -> float:
    """
    Heuristique de distance Euclidienne.
    
    La plus précise pour la planification en espace libre.
    
    Args:
        cell1: (lig, col)
        cell2: (lig, col)
        
    Returns:
        Distance Euclidienne
    """
    return np.sqrt((cell1[0] - cell2[0])**2 + (cell1[1] - cell2[1])**2)


def manhattan_distance(cell1: Tuple[int, int], cell2: Tuple[int, int]) -> float:
    """
    Distance de Manhattan (L1).
    
    Bon pour les grilles 4-connexes.
    
    Args:
        cell1: (lig, col)
        cell2: (lig, col)
        
    Returns:
        Distance de Manhattan
    """
    return abs(cell1[0] - cell2[0]) + abs(cell1[1] - cell2[1])


def diagonal_distance(cell1: Tuple[int, int], cell2: Tuple[int, int]) -> float:
    """
    Distance Diagonale (Chebyshev + coût diagonal).
    
    Bon pour les grilles 8-connexes avec coût diagonal √2.
    
    Args:
        cell1: (lig, col)
        cell2: (lig, col)
        
    Returns:
        Distance prenant en compte les diagonales
    """
    dx = abs(cell1[0] - cell2[0])
    dy = abs(cell1[1] - cell2[1])
    
    # Coût : mouvement diagonal (√2 ≈ 1.414) puis droit (1.0)
    D = 1.0  # Coût droit
    D2 = 1.414  # Coût diagonal
    
    return D * (dx + dy) + (D2 - 2*D) * min(dx, dy)


def costmap_aware_heuristic(cell1: Tuple[int, int], 
                            cell2: Tuple[int, int],
                            costmap) -> float:
    """
    Heuristique sensible à la costmap.
    
    Incorpore la proximité des obstacles dans l'heuristique.
    Reste admissible si la base est euclidienne.
    
    Args:
        cell1: (lig, col)
        cell2: (lig, col)
        costmap: OccupancyGrid avec inflation
        
    Returns:
        Heuristique modifiée favorisant les chemins plus sûrs
    """
    base_h = euclidean_distance(cell1, cell2)
    
    # Optionnel : ajouter une petite pénalité basée sur la valeur moyenne de la costmap
    # Doit rester admissible !
    
    return base_h


################################################################################
PATH: ./tank_project/core/ia/planners/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/core/ia/planners/path_utils.py
################################################################################
"""
Utilitaires de Chemin - Traitement et Optimisation de Chemin

Utilitaires pour travailler avec les chemins planifiés :
- Lissage de chemin
- Simplification de waypoints (Douglas-Peucker)
- Validation de chemin
- Calcul de distance
- Interpolation

Prend la sortie brute de A* et la rend prête à l'exécution.
"""

import numpy as np
from typing import List, Tuple, Optional


def smooth_path(waypoints: List[Tuple[float, float]], 
                weight_data: float = 0.5,
                weight_smooth: float = 0.3,
                tolerance: float = 0.01,
                max_iterations: int = 100) -> List[Tuple[float, float]]:
    """
    Lisse un chemin en utilisant la descente de gradient.
    
    Équilibre entre rester proche du chemin original vs lissage.
    
    Args:
        waypoints: Chemin original [(x1,y1), ...]
        weight_data: À quel point rester proche de l'original
        weight_smooth: À quel point lisser
        tolerance: Seuil de convergence
        max_iterations: Itérations maximum
        
    Returns:
        Chemin lissé
    """
    if len(waypoints) <= 2:
        return waypoints
    
    # Convertit en array numpy pour manipulation plus facile
    path = np.array(waypoints, dtype=np.float64)
    smoothed = path.copy()
    
    n_points = len(path)
    
    for iteration in range(max_iterations):
        change = 0.0
        
        # Ne modifie pas le premier et le dernier point
        for i in range(1, n_points - 1):
            for j in range(2):  # x et y
                old_val = smoothed[i, j]
                
                # Terme de données : rester proche de l'original
                data_term = weight_data * (path[i, j] - smoothed[i, j])
                
                # Terme de lissage : moyenne des voisins
                smooth_term = weight_smooth * (
                    smoothed[i-1, j] + smoothed[i+1, j] - 2 * smoothed[i, j]
                )
                
                smoothed[i, j] += data_term + smooth_term
                change += abs(smoothed[i, j] - old_val)
        
        # Vérifie la convergence
        if change < tolerance:
            break
    
    return [(float(p[0]), float(p[1])) for p in smoothed]


def simplify_path_douglas_peucker(waypoints: List[Tuple[float, float]], 
                                  epsilon: float = 0.05) -> List[Tuple[float, float]]:
    """
    Simplifie le chemin avec l'algorithme Douglas-Peucker.
    
    Supprime les waypoints qui sont presque colinéaires.
    
    Args:
        waypoints: Chemin original
        epsilon: Tolérance de déviation maximale en mètres
        
    Returns:
        Chemin simplifié avec moins de waypoints
        
    Algorithme :
        1. Trouve le point le plus éloigné de la ligne entre départ et fin
        2. Si distance < epsilon, supprime tous les points intermédiaires
        3. Sinon, applique récursivement à [départ, plus_lointain] et [plus_lointain, fin]
    """
    if len(waypoints) <= 2:
        return waypoints
    
    # Convertit en numpy pour les calculs
    points = np.array(waypoints)
    
    # Trouve le point avec la distance maximale de la ligne (départ -> fin)
    start = points[0]
    end = points[-1]
    
    # Vecteur ligne
    line_vec = end - start
    line_len = np.linalg.norm(line_vec)
    
    if line_len < 1e-10:
        # Départ et fin sont le même point
        return [waypoints[0], waypoints[-1]]
    
    line_unit = line_vec / line_len
    
    # Trouve les distances perpendiculaires
    max_dist = 0.0
    max_idx = 0
    
    for i in range(1, len(points) - 1):
        # Vecteur du départ au point
        vec_to_point = points[i] - start
        
        # Projette sur la ligne
        proj_length = np.dot(vec_to_point, line_unit)
        proj_point = start + proj_length * line_unit
        
        # Distance perpendiculaire
        dist = np.linalg.norm(points[i] - proj_point)
        
        if dist > max_dist:
            max_dist = dist
            max_idx = i
    
    # Si la distance max est inférieure à epsilon, simplifie aux extrémités
    if max_dist < epsilon:
        return [waypoints[0], waypoints[-1]]
    
    # Sinon, simplifie récursivement
    left_simplified = simplify_path_douglas_peucker(waypoints[:max_idx + 1], epsilon)
    right_simplified = simplify_path_douglas_peucker(waypoints[max_idx:], epsilon)
    
    # Combine (évite de dupliquer le point de coupure)
    return left_simplified[:-1] + right_simplified


def validate_path(waypoints: List[Tuple[float, float]], 
                 occupancy_grid) -> bool:
    """
    Vérifie si le chemin est sans collision.
    
    Args:
        waypoints: Chemin à valider
        occupancy_grid: Grille d'occupation actuelle
        
    Returns:
        True si le chemin est valide (pas de collisions)
    """
    if len(waypoints) < 2:
        return True
    
    # Vérifie chaque waypoint
    for x, y in waypoints:
        if not (0 <= x <= occupancy_grid.width_m and 0 <= y <= occupancy_grid.height_m):
            return False
        if occupancy_grid.is_occupied(x, y):
            return False
    
    # Vérifie les segments de ligne entre waypoints
    resolution = occupancy_grid.resolution
    
    for i in range(len(waypoints) - 1):
        x1, y1 = waypoints[i]
        x2, y2 = waypoints[i + 1]
        
        # Echantillonne les points le long du segment
        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
        n_samples = max(2, int(dist / resolution) + 1)
        
        for t in np.linspace(0, 1, n_samples):
            x = x1 + t * (x2 - x1)
            y = y1 + t * (y2 - y1)
            
            if occupancy_grid.is_occupied(x, y):
                return False
    
    return True


def calculate_path_length(waypoints: List[Tuple[float, float]]) -> float:
    """
    Calcule la longueur totale du chemin en mètres.
    
    Args:
        waypoints: Chemin [(x1,y1), ...]
        
    Returns:
        Longueur totale en mètres
    """
    if len(waypoints) < 2:
        return 0.0
    
    length = 0.0
    for i in range(len(waypoints) - 1):
        dx = waypoints[i+1][0] - waypoints[i][0]
        dy = waypoints[i+1][1] - waypoints[i][1]
        length += np.sqrt(dx**2 + dy**2)
    
    return length


def interpolate_path(waypoints: List[Tuple[float, float]], 
                    resolution: float = 0.05) -> List[Tuple[float, float]]:
    """
    Densifie le chemin en interpolant entre les waypoints.
    
    Utile pour une visualisation fluide ou un contrôle fin.
    
    Args:
        waypoints: Chemin clairsemé
        resolution: Espacement désiré en mètres
        
    Returns:
        Chemin dense avec des points tous les ~resolution mètres
    """
    if len(waypoints) < 2:
        return waypoints
    
    dense_path = [waypoints[0]]
    
    for i in range(len(waypoints) - 1):
        x1, y1 = waypoints[i]
        x2, y2 = waypoints[i + 1]
        
        # Distance entre waypoints consécutifs
        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
        
        if dist < resolution:
            # Pas d'interpolation nécessaire
            dense_path.append((x2, y2))
            continue
        
        # Nombre de points intermédiaires
        n_points = int(dist / resolution)
        
        for j in range(1, n_points + 1):
            t = j / (n_points + 1)
            x = x1 + t * (x2 - x1)
            y = y1 + t * (y2 - y1)
            dense_path.append((x, y))
        
        dense_path.append((x2, y2))
    
    return dense_path


def get_path_curvature(waypoints: List[Tuple[float, float]]) -> List[float]:
    """
    Calcule la courbure à chaque waypoint.
    
    Utile pour l'adaptation de vitesse (ralentir aux virages serrés).
    
    Args:
        waypoints: Chemin [(x1,y1), ...]
        
    Returns:
        Liste des valeurs de courbure (1/rayon, 0 pour ligne droite)
    """
    if len(waypoints) < 3:
        return [0.0] * len(waypoints)
    
    curvatures = [0.0]  # Le premier point n'a pas de courbure
    
    for i in range(1, len(waypoints) - 1):
        p0 = np.array(waypoints[i - 1])
        p1 = np.array(waypoints[i])
        p2 = np.array(waypoints[i + 1])
        
        # Vecteurs
        v1 = p1 - p0
        v2 = p2 - p1
        
        # Magnitude produit vectoriel (2D)
        cross = abs(v1[0] * v2[1] - v1[1] * v2[0])
        
        # Longueurs segments
        len1 = np.linalg.norm(v1)
        len2 = np.linalg.norm(v2)
        
        if len1 < 1e-10 or len2 < 1e-10:
            curvatures.append(0.0)
            continue
        
        # Approximation courbure : 2 * sin(angle) / longueur_corde
        # Simplifié : cross / (len1 * len2)
        curvature = cross / (len1 * len2)
        curvatures.append(curvature)
    
    curvatures.append(0.0)  # Le dernier point n'a pas de courbure
    
    return curvatures


################################################################################
PATH: ./tank_project/core/ia/strategy.py
################################################################################
"""
Stratégie - Contrôleur IA Haut-Niveau

Orchestre le système IA :
1. Lit l'état du monde
2. Exécute l'arbre de comportement
3. Déclenche la planification de chemin si nécessaire
4. Retourne les décisions IA (cible, demande_tir)

Ceci est le point d'entrée principal pour le sous-système IA.

Logs : [AI] État : ATTACK/FLANK/RETREAT, cible=(x,y), tir=True/False
"""

import numpy as np
from typing import Dict, Tuple, Optional
from .behavior_tree import BehaviorTreeExecutor, NodeStatus
from .decisions import has_line_of_sight, is_enemy_too_close, is_optimal_firing_range
from .planners.a_star import AStarPlanner


class AIStrategy:
    """
    Contrôleur IA principal.
    
    Combine arbre de comportement + planification de chemin pour produire les actions IA.
    """
    
    def __init__(self, config):
        """
        Initialise la stratégie IA.
        
        Args:
            config: Configuration IA depuis config/ia.yaml
        """
        self.config = config
        self.behavior_tree = BehaviorTreeExecutor()
        self.planner = None  # Set when world is available
        
        # État IA
        self.current_path = []
        self.current_waypoint_idx = 0
        self.state = "IDLE"  # ATTACK, FLANK, RETREAT, HUNT
        
        # Contrôle du taux de décision
        self.decision_interval = config.get('decision_rate', {}).get('replan_interval', 10)
        self.tick_count = 0
        
        print("[AI] Stratégie initialisée")
        
    def set_planner(self, occupancy_grid):
        """
        Initialise le planificateur de chemin avec la grille d'occupation.
        
        Args:
            occupancy_grid: OccupancyGrid depuis core/world
        """
        heuristic = self.config.get('strategy', {}).get('heuristic', 'euclidean')
        self.planner = AStarPlanner(occupancy_grid, heuristic)
        print("[AI] Planificateur chemin initialisé avec heuristique {}".format(heuristic))
        
    def decide(self, world_state: Dict) -> Dict:
        """
        Fonction de décision principale appelée à chaque tick.
        
        Args:
            world_state: {
                'ai_pose': (x, y, theta),
                'human_pose': (x, y, theta),
                'occupancy_grid': objet grille,
                'raycast_sys': objet raycast,
                'game_time': float,
            }
            
        Returns:
            {
                'target_position': (x, y) ou None,
                'target_orientation': theta ou None,
                'fire_request': bool,
                'state': str (ATTACK/FLANK/RETREAT),
                'has_los': bool,
            }
        """
        self.tick_count += 1
        
        ai_pose = world_state.get('ai_pose')
        enemy_pose = world_state.get('human_pose')
        
        # Sortie par défaut
        decision = {
            'target_position': None,
            'target_orientation': None,
            'fire_request': False,
            'state': self.state,
            'has_los': False
        }
        
        if ai_pose is None or enemy_pose is None:
            return decision

        # Prépare le contexte pour l'arbre de comportement
        context = {
            'ai_pose': ai_pose,
            'human_pose': enemy_pose,
            'occupancy_grid': world_state.get('occupancy_grid'),
            'raycast_sys': world_state.get('raycast_sys'),
        }
        
        # Exécute l'arbre de comportement
        bt_output = self.behavior_tree.execute(context)
        
        # Copie les décisions de l'arbre comportemental
        decision['fire_request'] = bt_output.get('fire_request', False)
        decision['has_los'] = bt_output.get('has_los', False)
        decision['state'] = bt_output.get('state', 'IDLE')
        self.state = decision['state']
        
        target_pos = bt_output.get('target_position')
        
        # Planification de Chemin - replanifie seulement périodiquement ou si la cible change significativement
        if target_pos is not None and self.planner:
            should_replan = False
            
            # Replanifie si pas de chemin ou sur intervalle
            if not self.current_path:
                should_replan = True
            elif self.tick_count % self.decision_interval == 0:
                should_replan = True
            elif len(self.current_path) > 0:
                # Replanifie si la cible a bougé significativement
                last_goal = self.current_path[-1]
                dist_to_new = np.linalg.norm(
                    np.array(last_goal) - np.array(target_pos)
                )
                if dist_to_new > 0.5:
                    should_replan = True
            
            if should_replan:
                path = self.planner.plan(ai_pose[:2], target_pos)
                if path:
                    self.current_path = path
                    self.current_waypoint_idx = 0
                    print("[AI] Nouveau chemin planifié : {} waypoints".format(len(path)))
        
        decision['target_position'] = target_pos
        
        # Log décision
        if self.tick_count % 30 == 0:  # Log chaque seconde à 30 FPS
            self._log_decision(decision)
        
        return decision
    
    def _log_decision(self, decision):
        """Log la décision IA actuelle."""
        target = decision.get('target_position')
        target_str = "({:.2f}, {:.2f})".format(target[0], target[1]) if target else "None"
        
        print("[AI] État : {}, cible={}, tir={}, LOS={}".format(
            decision['state'],
            target_str,
            decision['fire_request'],
            decision['has_los']
        ))
    
    def get_next_waypoint(self) -> Optional[Tuple[float, float]]:
        """
        Obtient le prochain waypoint du chemin actuel.
        
        Utilisé par le module de contrôle pour le suivi de trajectoire.
        
        Returns:
            (x, y) du prochain waypoint, ou None si pas de chemin
        """
        if self.current_waypoint_idx >= len(self.current_path):
            return None
        return self.current_path[self.current_waypoint_idx]
    
    def advance_waypoint(self):
        """
        Marque le waypoint actuel comme atteint, passe au suivant.
        
        Appelé par le module de contrôle quand le waypoint est atteint.
        """
        self.current_waypoint_idx += 1
        
    def get_full_path(self) -> list:
        """
        Obtient le chemin complet actuel pour la visualisation.
        
        Returns:
            Liste de waypoints (x, y)
        """
        return self.current_path


################################################################################
PATH: ./tank_project/core/__init__.py
################################################################################
"""Package principal de logique metier pour Tank Arena."""

__all__ = []


################################################################################
PATH: ./tank_project/core/world/coordinate_frames.py
################################################################################
"""
Trames de Coordonnées - Gestion des Transformations

Gère toutes les transformations de coordonnées :
- Caméra -> Arène Virtuelle (H_C2AV) - homographie depuis les coins projetés
- Arène Virtuelle -> Monde (mise à l'échelle) - étalonnage métrique
- Caméra -> Monde (H_C2W) - transformation combinée
- Monde -> Pygame (affichage projection)
- Monde -> Projecteur (affichage superposition)

Toutes les transformations sont des homographies 2D ou des transformations affines.

Logs : préfixe [TRANSFORM] pour toutes les opérations de transformation
"""

import numpy as np
import cv2
from typing import Tuple, List


class TransformManager:
    """
    Gère les transformations de trames de coordonnées.
    
    Stocke et applique les homographies entre différents systèmes de coordonnées.
    """
    
    def __init__(self):
        """Initialise le gestionnaire de transformations."""
        self.H_C2AV = None  # Caméra -> Arène Virtuelle
        self.H_AV2W = None  # Arène Virtuelle -> Monde (échelle)
        self.H_C2W = None   # Caméra -> Monde (combiné)
        self.H_W2Proj = None  # Monde -> Projecteur (affichage)
        
        self.scale_m_per_av = None  # Metric scale factor
        
    def set_camera_to_av(self, src_points: np.ndarray, dst_points: np.ndarray):
        """
        Calcule H_C2AV à partir des correspondances de coins.
        
        Args:
            src_points: Tableau 4x2 de coordonnées pixels caméra
            dst_points: Tableau 4x2 de coordonnées arène virtuelle (ex: carré unitaire)
            
        Calcule l'homographie utilisant cv2.findHomography.
        
        Logs:
            [TRANSFORM] H_C2AV calculé à partir de 4 coins
        """
        self.H_C2AV, _ = cv2.findHomography(src_points, dst_points)
        self._update_combined()
        
    def set_av_to_world_scale(self, scale: float):
        """
        Définit l'échelle de l'Arène Virtuelle vers le Monde (mètres).
        
        Args:
            scale: mètres par unité AV
            
        Crée la transformation d'échelle H_AV2W.
        
        Logs:
            [TRANSFORM] Echelle définie : 1.15 m/unité_AV
        """
        self.scale_m_per_av = scale
        self.H_AV2W = np.array([
            [scale, 0, 0],
            [0, scale, 0],
            [0, 0, 1]
        ], dtype=np.float32)
        self._update_combined()
        
    def _update_combined(self):
        """Update H_C2W = H_AV2W @ H_C2AV."""
        if self.H_C2AV is not None and self.H_AV2W is not None:
            self.H_C2W = self.H_AV2W @ self.H_C2AV
            
    def camera_to_world(self, u: float, v: float) -> Tuple[float, float]:
        """
        Transforme pixel caméra en mètres monde.
        
        Args:
            u, v: Coordonnées pixel caméra
            
        Returns:
            (x, y) en mètres
        """
        if self.H_C2W is None:
            raise ValueError("H_C2W non défini, lancez l'étalonnage d'abord")
        
        # Coordonnées homogènes
        p_cam = np.array([u, v, 1.0])
        p_world = self.H_C2W @ p_cam
        
        # Normalisation
        x = p_world[0] / p_world[2]
        y = p_world[1] / p_world[2]
        
        return (x, y)
    
    def world_to_projector(self, x: float, y: float, 
                          arena_width_m: float, arena_height_m: float,
                          proj_width_px: int, proj_height_px: int,
                          margin_px: int = 50) -> Tuple[int, int]:
        """
        Transforme position monde en pixel projecteur.
        
        Args:
            x, y: Position monde en mètres
            arena_width_m, arena_height_m: Taille arène
            proj_width_px, proj_height_px: Résolution projecteur
            margin_px: Marge de sécurité
            
        Returns:
            (px, py) coordonnées pixel projecteur
        """
        # Mise à l'échelle vers projecteur (avec marge)
        draw_width = proj_width_px - 2 * margin_px
        draw_height = proj_height_px - 2 * margin_px
        
        scale_x = draw_width / arena_width_m
        scale_y = draw_height / arena_height_m
        scale = min(scale_x, scale_y)  # Conserve le ratio d'aspect
        
        px = margin_px + int(x * scale)
        py = margin_px + int((arena_height_m - y) * scale)  # Inverse Y (origine pygame en haut à gauche)
        
        return (px, py)
    
    def batch_camera_to_world(self, points_cam: np.ndarray) -> np.ndarray:
        """
        Transforme plusieurs points caméra vers monde.
        
        Args:
            points_cam: Tableau Nx2 de coordonnées caméra
            
        Returns:
            Tableau Nx2 de coordonnées monde
        """
        if self.H_C2W is None:
            raise ValueError("H_C2W non défini")
        
        # Ajoute coordonnée homogène
        ones = np.ones((points_cam.shape[0], 1))
        points_h = np.hstack([points_cam, ones])
        
        # Transform
        points_world_h = (self.H_C2W @ points_h.T).T
        
        # Normalisation
        points_world = points_world_h[:, :2] / points_world_h[:, 2:3]
        
        return points_world


################################################################################
PATH: ./tank_project/core/world/inflation.py
################################################################################
"""
Inflation - Gonflement du Coût des Obstacles

Gonfle les obstacles dans la costmap pour une planification de chemin sûre :
- Ajoute une marge de sécurité autour des obstacles
- Crée un gradient pour une planification plus douce
- Prend en compte la taille du robot

Utilise la transformée de distance pour un calcul efficace.

Logs : [INFLATION] Gonflé avec rayon : Xm -> Y cellules
"""

import numpy as np
from scipy.ndimage import distance_transform_edt


class CostmapInflation:
    """
    Gonfle les obstacles dans la costmap pour une planification sûre.
    
    Crée un gradient de coût autour des obstacles.
    """
    
    def __init__(self, inflation_radius_m: float, resolution_m: float):
        """
        Initialise l'inflation.
        
        Args:
            inflation_radius_m: Jusqu'où gonfler en mètres
            resolution_m: Résolution de la grille
        """
        self.inflation_radius_m = inflation_radius_m
        self.resolution = resolution_m
        self.inflation_cells = int(inflation_radius_m / resolution_m)
        
    def inflate(self, binary_grid: np.ndarray) -> np.ndarray:
        """
        Gonfle les obstacles dans la grille.
        
        Args:
            binary_grid: Grille avec 0 = libre, 1 = occupé
            
        Returns:
            Costmap gonflée avec gradient (0-1 float)
            
        Algorithme :
            1. Calcule la transformée de distance (distance à l'obstacle le plus proche)
            2. Convertit les distances en coûts :
               - d = 0 : coût = 1.0 (occupé)
               - d < inflation_radius : coût = 1.0 - (d / rayon)
               - d >= inflation_radius : coût = 0.0 (libre)
               
        Logs:
            [INFLATION] Grille gonflée avec rayon : 0.24m (12 cellules)
        """
        # Transformée de distance : chaque cellule = distance à l'obstacle le plus proche
        distances = distance_transform_edt(1 - binary_grid) * self.resolution
        
        # Convertit en coûts
        costmap = np.zeros_like(distances, dtype=np.float32)
        
        # Cellules occupées
        costmap[binary_grid == 1] = 1.0
        
        # Région gonflée
        inflation_mask = (distances > 0) & (distances < self.inflation_radius_m)
        costmap[inflation_mask] = 1.0 - (distances[inflation_mask] / self.inflation_radius_m)
        
        return costmap
    
    def inflate_discrete(self, binary_grid: np.ndarray, 
                        lethal: int = 100, inscribed: int = 99) -> np.ndarray:
        """
        Gonfle avec des valeurs de coût discrètes (style costmap ROS).
        
        Args:
            binary_grid: Grille d'occupation binaire
            lethal: Coût pour les cellules occupées (défaut 100)
            inscribed: Coût pour les cellules dans le rayon d'inflation
            
        Returns:
            Costmap avec valeurs [0, inscribed, lethal]
        """
        distances = distance_transform_edt(1 - binary_grid)
        
        costmap = np.zeros_like(distances, dtype=np.uint8)
        
        # Obstacles létaux
        costmap[binary_grid == 1] = lethal
        
        # Région inscrite
        inflation_mask = (distances > 0) & (distances <= self.inflation_cells)
        costmap[inflation_mask] = inscribed
        
        return costmap


################################################################################
PATH: ./tank_project/core/world/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/core/world/occupancy_grid.py
################################################################################
"""
Grille d'Occupation - Représentation Spatiale 2D

Représente l'arène comme une grille 2D avec résolution métrique :
- Valeurs cellules : 0 = libre, 1 = occupé, 0-1 = partiel
- Résolution : typiquement 2cm (0.02m) par cellule
- Dimensions : dérivées de l'étalonnage

La grille stocke :
- Obstacles statiques (depuis l'étalonnage)
- Obstacles dynamiques (robots, mis à jour chaque frame)
- Obstacles gonflés (marges de sécurité)

Système de coordonnées : mètres, origine en bas à gauche de l'arène.

Logs : préfixe [GRID] pour toutes les opérations de grille
"""

import numpy as np
from typing import Tuple, List


class OccupancyGrid:
    """
    Grille d'occupation 2D pour représentation spatiale.
    
    Fournit une vérification de collision efficace et des requêtes spatiales.
    """
    
    def __init__(self, width_m: float, height_m: float, resolution_m: float = 0.02):
        """
        Initialise la grille d'occupation.
        
        Args:
            width_m: Largeur de l'arène en mètres
            height_m: Hauteur de l'arène en mètres  
            resolution_m: Taille de cellule en mètres (défaut 2cm)
            
        La grille aura les dimensions :
            n_cols = ceil(width_m / resolution_m)
            n_rows = ceil(height_m / resolution_m)
            
        Logs:
            [GRID] Grille créée : 2.85m x 1.90m @ 0.02m -> 143 x 95 cellules
        """
        self.width_m = width_m
        self.height_m = height_m
        self.resolution = resolution_m
        
        self.n_cols = int(np.ceil(width_m / resolution_m))
        self.n_rows = int(np.ceil(height_m / resolution_m))
        
        # Données grille : 0 = libre, 1 = occupé
        self.grid = np.zeros((self.n_rows, self.n_cols), dtype=np.float32)
        
        # Obstacles statiques (depuis étalonnage, ne changent jamais)
        self.static_grid = np.zeros((self.n_rows, self.n_cols), dtype=np.float32)
        
    def world_to_grid(self, x_m: float, y_m: float) -> Tuple[int, int]:
        """
        Convertit coordonnées monde en cellule grille.
        
        Args:
            x_m: Position X en mètres
            y_m: Position Y en mètres
            
        Returns:
            (lig, col) indices cellule grille
        """
        col = int(x_m / self.resolution)
        row = int(y_m / self.resolution)
        return (row, col)
    
    def grid_to_world(self, row: int, col: int) -> Tuple[float, float]:
        """
        Convertit cellule grille en coordonnées monde (centre cellule).
        
        Args:
            row: Ligne grille
            col: Colonne grille
            
        Returns:
            (x_m, y_m) en mètres
        """
        x_m = (col + 0.5) * self.resolution
        y_m = (row + 0.5) * self.resolution
        return (x_m, y_m)
    
    def is_occupied(self, x_m: float, y_m: float, threshold: float = 0.5) -> bool:
        """
        Vérifie si une position monde est occupée.
        
        Args:
            x_m: Position X en mètres
            y_m: Position Y en mètres
            threshold: Seuil d'occupation (0-1)
            
        Returns:
            True si occupée
        """
        row, col = self.world_to_grid(x_m, y_m)
        
        if not self._is_valid_cell(row, col):
            return True  # Hors limites = occupé
        
        return self.grid[row, col] >= threshold
    
    def get_value(self, x_m: float, y_m: float) -> float:
        """
        Obtient la valeur d'occupation à une position monde.
        
        Args:
            x_m: Position X en mètres
            y_m: Position Y en mètres
            
        Returns:
            Valeur d'occupation 0-100 (0=libre, 100=occupé)
        """
        row, col = self.world_to_grid(x_m, y_m)
        
        if not self._is_valid_cell(row, col):
            return 100  # Hors limites = occupé
        
        return self.grid[row, col] * 100
    
    def set_static_obstacles(self, obstacle_cells: List[Tuple[int, int]]):
        """
        Définit les obstacles statiques depuis l'étalonnage.
        
        Args:
            obstacle_cells: Liste des cellules occupées (lig, col)
            
        Logs:
            [GRID] Obstacles statiques définis : N cellules
        """
        for row, col in obstacle_cells:
            if self._is_valid_cell(row, col):
                self.static_grid[row, col] = 1.0
        
        # Par défaut, inflated_grid = static_grid (pas d'inflation)
        self.inflated_grid = self.static_grid.copy()
        self.grid = self.inflated_grid.copy()
        
        print(f"[GRID] Obstacles statiques définis : {len(obstacle_cells)} cellules")
    
    def inflate_static_obstacles(self, robot_radius_m: float, safety_margin_m: float = 0.0):
        """
        Génère une Costmap en gonflant les obstacles avec cv2.dilate (RAPIDE).
        
        Utilise OpenCV pour un calcul instantané même sur Raspberry Pi.
        Crée une zone tampon autour de chaque obstacle basée sur la taille physique du robot.
        
        Args:
            robot_radius_m: Rayon physique du robot (ex: 0.09m pour Turtlebot)
            safety_margin_m: Marge de sécurité supplémentaire (ex: 0.05m)
            
        Logs:
            [GRID] Inflation calculée: rayon + marge = total => kernel size
        """
        import cv2
        
        # 1. Calcul du rayon total à gonfler
        total_inflation_m = robot_radius_m + safety_margin_m
        
        # 2. Conversion Mètres -> Cellules (dynamique selon résolution)
        radius_cells = int(np.ceil(total_inflation_m / self.resolution))
        
        # 3. Calcul du Kernel pour OpenCV (doit être impair: 3x3, 5x5, 7x7...)
        kernel_size = (radius_cells * 2) + 1
        
        print(f"[GRID] Inflation calculée :")
        print(f"       Robot : {robot_radius_m}m + Marge : {safety_margin_m}m = {total_inflation_m}m")
        print(f"       Cellules : {total_inflation_m:.3f}m / {self.resolution}m = {radius_cells} cellules")
        print(f"       Noyau OpenCV : {kernel_size}x{kernel_size}")
        
        # 4. Création du Kernel Circulaire (forme du robot)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        
        # 5. Application de la dilatation (ULTRA RAPIDE vs boucles Python)
        static_u8 = (self.static_grid * 255).astype(np.uint8)
        inflated_u8 = cv2.dilate(static_u8, kernel)
        
        # 6. Sauvegarde dans costmap (pour A*) et inflated_grid
        self.costmap = (inflated_u8 > 127).astype(np.float32)
        self.inflated_grid = self.costmap.copy()
        
        # Appliquer à la grille courante
        self.grid = self.inflated_grid.copy()
    
    def update_dynamic_obstacles(self, robot_poses: List[Tuple[float, float, float]], 
                                 robot_radius_m: float):
        """
        Met à jour la grille avec les positions actuelles des robots.
        
        Args:
            robot_poses: Liste de (x, y, theta) pour chaque robot
            robot_radius_m: Rayon du robot en mètres
            
        Algorithm:
            1. Réinitialise la grille aux obstacles statiques gonflés
            2. Pour chaque robot, marque les cellules dans le rayon comme occupées
        """
        # Reset to inflated static (pas static_grid brut)
        self.grid = self.inflated_grid.copy() if hasattr(self, 'inflated_grid') else self.static_grid.copy()
        
        # Ajoute les empreintes des robots
        radius_cells = int(np.ceil(robot_radius_m / self.resolution))
        
        for x, y, _ in robot_poses:
            center_row, center_col = self.world_to_grid(x, y)
            
            # Marque le cercle de cellules
            for dr in range(-radius_cells, radius_cells + 1):
                for dc in range(-radius_cells, radius_cells + 1):
                    if dr**2 + dc**2 <= radius_cells**2:
                        r, c = center_row + dr, center_col + dc
                        if self._is_valid_cell(r, c):
                            self.grid[r, c] = 1.0
    
    def _is_valid_cell(self, row: int, col: int) -> bool:
        """Vérifie si la cellule est dans les limites de la grille."""
        return 0 <= row < self.n_rows and 0 <= col < self.n_cols
    
    def get_costmap(self):
        """
        Retourne la costmap actuelle pour la planification.
        
        Returns:
            numpy array (n_rows x n_cols) avec coûts 0-100
        """
        return (self.grid * 100).astype(np.uint8)



################################################################################
PATH: ./tank_project/core/world/world_model.py
################################################################################
"""
Modèle du Monde - Représentation Unifiée du Monde

Référentiel central pour tout l'état du monde :
- Poses robots (filtrées par Kalman)
- Grille d'occupation (obstacles)
- Limites de l'arène
- Trames de coordonnées

C'est la source unique de vérité pour l'information spatiale.
Tous les autres modules interrogent le modèle du monde.

NE contient PAS la logique de jeu (scores, etc.) - seulement l'état spatial.
"""

from typing import Dict, List, Tuple
from .occupancy_grid import OccupancyGrid
from .coordinate_frames import TransformManager


class WorldModel:
    """
    Représentation spatiale complète du monde.
    
    Gère :
    - État des robots (positions, vitesses, orientations)
    - Obstacles (statiques + dynamiques)
    - Transformations de coordonnées
    - Limites de l'arène
    """
    
    def __init__(self, arena_width_m: float, arena_height_m: float, 
                 grid_resolution_m: float = 0.02,
                 robot_radius_m: float = 0.09,
                 inflation_margin_m: float = 0.05):
        """
        Initialise le modèle du monde.
        
        Args:
            arena_width_m: Largeur de l'arène depuis l'étalonnage
            arena_height_m: Hauteur de l'arène depuis l'étalonnage
            grid_resolution_m: Taille de cellule grille
            robot_radius_m: Rayon physique du robot (depuis config)
            inflation_margin_m: Marge de sécurité pour pathfinding (depuis config)
        """
        self.arena_width = arena_width_m
        self.arena_height = arena_height_m
        self.robot_radius_m = robot_radius_m
        self.inflation_margin_m = inflation_margin_m
        
        # Grille d'occupation
        self.grid = OccupancyGrid(arena_width_m, arena_height_m, grid_resolution_m)
        
        # État du robot
        self.robots = {
            4: {  # Robot IA
                'pose': (0.0, 0.0, 0.0),  # (x, y, theta)
                'velocity': (0.0, 0.0, 0.0),  # (vx, vy, omega)
                'radius_m': robot_radius_m,
            },
            5: {  # Robot Humain
                'pose': (0.0, 0.0, 0.0),
                'velocity': (0.0, 0.0, 0.0),
                'radius_m': robot_radius_m,
            }
        }
        
        # Transformations de coordonnées
        self.transforms = TransformManager()
        
    def update_robot_pose(self, robot_id: int, pose: Tuple[float, float, float]):
        """
        Met à jour la pose du robot depuis le filtre de Kalman.
        
        Args:
            robot_id: 4 ou 5
            pose: (x, y, theta) en mètres/radians
        """
        if robot_id in self.robots:
            self.robots[robot_id]['pose'] = pose
    
    def update_robot_velocity(self, robot_id: int, 
                             velocity: Tuple[float, float, float]):
        """
        Met à jour la vitesse du robot depuis le filtre de Kalman.
        
        Args:
            robot_id: 4 ou 5
            velocity: (vx, vy, omega) en m/s et rad/s
        """
        if robot_id in self.robots:
            self.robots[robot_id]['velocity'] = velocity
    
    def update_occupancy(self):
        """
        Met à jour la grille d'occupation avec les positions actuelles des robots.
        
        Appelé chaque frame après la mise à jour des poses des robots.
        """
        robot_poses = [self.robots[rid]['pose'] for rid in [4, 5]]
        self.grid.update_dynamic_obstacles(robot_poses, self.robot_radius_m)
    
    def generate_costmap(self):
        """
        Génère la costmap gonflée pour le pathfinding A*.
        
        Appelle après avoir chargé les obstacles statiques.
        Utilise les paramètres robot du config.
        """
        self.grid.inflate_static_obstacles(self.robot_radius_m, self.inflation_margin_m)
        print(f"[WORLD] Costmap générée avec rayon={self.robot_radius_m}m, marge={self.inflation_margin_m}m")
    
    def get_robot_pose(self, robot_id: int) -> Tuple[float, float, float]:
        """Obtient la pose actuelle du robot."""
        return self.robots[robot_id]['pose']
    
    def get_robot_velocity(self, robot_id: int) -> Tuple[float, float, float]:
        """Obtient la vitesse actuelle du robot."""
        return self.robots[robot_id]['velocity']
    
    def is_position_valid(self, x: float, y: float) -> bool:
        """
        Vérifie si une position est dans l'arène et non occupée.
        
        Args:
            x, y: Position en mètres
            
        Returns:
            True si la position est valide (dans les limites et libre)
        """
        # Vérifie les limites
        if not (0 <= x <= self.arena_width and 0 <= y <= self.arena_height):
            return False
        
        # Vérifie l'occupation
        return not self.grid.is_occupied(x, y)
    
    def get_state_dict(self) -> Dict:
        """
        Exporte l'état complet du monde sous forme de dictionnaire.
        
        Utilisé par l'IA, le moteur de jeu, la visualisation.
        
        Returns:
            dict avec toutes les informations du monde
        """
        return {
            'arena_size': (self.arena_width, self.arena_height),
            'robot_4_pose': self.robots[4]['pose'],
            'robot_5_pose': self.robots[5]['pose'],
            'robot_4_velocity': self.robots[4]['velocity'],
            'robot_5_velocity': self.robots[5]['velocity'],
            'occupancy_grid': self.grid,
        }


################################################################################
PATH: ./tank_project/__main__.py
################################################################################
"""
Tank Project - Module Package
"""

__version__ = '1.0.0'
__author__ = 'Julien'

# Point d'entrée module
if __name__ == '__main__':
    from main import main
    main()


################################################################################
PATH: ./tank_project/main.py
################################################################################
#!/usr/bin/env python3
"""
Tank Arena - Point d'Entrée Principal

Point d'entrée unique pour le projet tank arena.

Usage:
    python3 main.py [mode]
    
    Modes:
    - game        : Lancer le jeu (défaut)
    - calibration : Lancer l'assistant de calibration
    - export      : Exporter données debug
    
Exemples:
    python3 main.py
    python3 main.py game
    python3 main.py calibration
    python3 main.py export
    
Ou en tant que module:
    python3 -m tank_project.main
    cd /home/julien/ros2_ws/src && python3 -m tank_project.main
"""

import sys
import argparse
from pathlib import Path

# Ajouter le répertoire courant au path
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))


def main():
    """Point d'entrée principal."""
    parser = argparse.ArgumentParser(
        description='Tank Arena - Système de combat de chars robotiques',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  %(prog)s                  Lance le jeu
  %(prog)s game             Lance le jeu
  %(prog)s calibration      Lance la calibration
  %(prog)s export           Exporte les données debug
        """
    )
    
    parser.add_argument(
        'mode',
        nargs='?',
        default='game',
        choices=['game', 'calibration', 'export'],
        help='Mode de lancement (défaut: game)'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("      TANK ARENA - Système Combat Chars Robotiques")
    print("=" * 60)
    print()
    
    # Lancer le mode approprié
    if args.mode == 'calibration':
        print("[MAIN] Mode: CALIBRATION")
        print("-" * 60)
        from scripts.run_calibration import main as run_calibration
        run_calibration()
        
    elif args.mode == 'export':
        print("[MAIN] Mode: EXPORT DEBUG DATA")
        print("-" * 60)
        from scripts.export_debug_data import main as run_export
        run_export()
        
    else:  # game
        print("[MAIN] Mode: GAME")
        print("-" * 60)
        from scripts.run_game import main as run_game
        run_game()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n[MAIN] Interruption utilisateur (Ctrl+C)")
        sys.exit(0)
    except Exception as e:
        print("\n[MAIN] ERREUR: {}".format(e))
        import traceback
        traceback.print_exc()
        sys.exit(1)


################################################################################
PATH: ./tank_project/perception/calibration/arena_solver.py
################################################################################
"""
Arena Solver - Calcul Dimensions Arène

Déduit les dimensions physiques de l'arène (Lx, Ly)
à partir de la calibration.

Logs: [ARENA_SOLVER] prefix
"""

import numpy as np
from typing import Tuple


class ArenaSolver:
    """
    Calcule dimensions arène depuis calibration.
    """
    
    def __init__(self):
        """Initialize arena solver."""
        self.width_m = None
        self.height_m = None
        
    def solve_from_av_and_scale(self,
                                av_width: float,
                                av_height: float,
                                scale: float) -> Tuple[float, float]:
        """
        Calcule dimensions arène depuis taille AV et échelle.
        
        Args:
            av_width: Largeur en unités AV (typiquement 1.0)
            av_height: Hauteur en unités AV (typiquement 1.0)
            scale: Échelle m/unité_av
            
        Returns:
            (width_m, height_m) dimensions en mètres
            
        Logs:
            [ARENA_SOLVER] Arena dimensions: Lx x Ly meters
        """
        self.width_m = av_width * scale
        self.height_m = av_height * scale
        
        print("[ARENA_SOLVER] Dimensions de l'arène : "
              "{:.2f}m x {:.2f}m".format(self.width_m, self.height_m))
        
        return (self.width_m, self.height_m)
    
    def solve_from_corners(self,
                          corners_world: np.ndarray) -> Tuple[float, float]:
        """
        Calcule dimensions depuis coins arène en coordonnées monde.
        
        Args:
            corners_world: 4 coins en mètres (ordre: BL, BR, TR, TL)
            
        Returns:
            (width_m, height_m)
        """
        # Distance entre coins bas
        width = np.linalg.norm(corners_world[1] - corners_world[0])
        
        # Distance entre coins gauche
        height = np.linalg.norm(corners_world[3] - corners_world[0])
        
        self.width_m = width
        self.height_m = height
        
        print("[ARENA_SOLVER] Dimensions de l'arène depuis coins : "
              "{:.2f}m x {:.2f}m".format(width, height))
        
        return (width, height)
    
    def get_dimensions(self) -> Tuple[float, float]:
        """
        Retourne dimensions calculées.
        
        Returns:
            (width_m, height_m)
            
        Raises:
            ValueError: Si dimensions pas encore calculées
        """
        if self.width_m is None:
            raise ValueError("Dimensions pas encore calculées")
        
        return (self.width_m, self.height_m)
    
    def get_aspect_ratio(self) -> float:
        """Retourne ratio aspect width/height."""
        if self.width_m is None:
            raise ValueError("Dimensions pas encore calculées")
        
        return self.width_m / self.height_m


################################################################################
PATH: ./tank_project/perception/calibration/calibration_wizard.py
################################################################################
"""
Assistant de Calibration - Processus Interactif

Guide l'utilisateur à travers la séquence de calibration :
1. Définition de la zone sûre (marges de projection)
2. Calibration géométrique (H_C2AV à partir des coins projetés)
3. Calibration métrique (échelle à partir d'un ArUco physique)
4. Cartographie des obstacles (détection d'obstacles statiques)

Sauvegarde la calibration dans config/arena.yaml pour la phase de jeu.

Logs : Préfixe [CALIB] pour toutes les étapes
"""

import cv2
import numpy as np
import yaml
import time
import sys
from typing import Tuple, List
from ..camera.aruco_detector import ArucoDetector
from core.world.coordinate_frames import TransformManager
from .projector_display import ProjectorDisplay


class CalibrationWizard:
    """
    Processus de calibration interactif pour la configuration de l'arène.
    
    Produit la transformation H_C2W et les paramètres de l'arène.
    """
    
    def __init__(self, camera, projector_width=1024, projector_height=768, 
                 margin_px=50, monitor_offset_x=1920, monitor_offset_y=0,
                 borderless=True, hide_cursor=True, marker_size_m=0.10):
        """
        Initialise l'assistant de calibration.
        
        Args:
            camera: Instance de RealSenseStream
            projector_width: Largeur de la résolution du projecteur
            projector_height: Hauteur de la résolution du projecteur
            margin_px: Marge de sécurité depuis les bords (pixels)
            monitor_offset_x: Position X pour le moniteur secondaire
            monitor_offset_y: Position Y pour le moniteur secondaire
            borderless: Utiliser le mode fenêtre sans bordure
            hide_cursor: Masquer le curseur de la souris
            marker_size_m: Taille physique du marqueur en mètres
        """
        self.camera = camera
        self.proj_w = projector_width
        self.proj_h = projector_height
        self.marker_size_m = marker_size_m
        
        self.aruco = ArucoDetector()
        self.transform_mgr = TransformManager()
        
        # Initialise l'affichage du projecteur avec toute la config
        self.projector = ProjectorDisplay(
            width=projector_width,
            height=projector_height,
            margin=margin_px,
            monitor_offset_x=monitor_offset_x,
            monitor_offset_y=monitor_offset_y,
            borderless=borderless,
            hide_cursor=hide_cursor
        )
        
        # Résultats de calibration
        self.margin_px = margin_px
        self.arena_width_m = None
        self.arena_height_m = None
        self.H_C2W = None
        self.static_obstacles = []
    
    def _wait_for_user_validation(self, message: str = "Appuyez sur ESPACE pour continuer..."):
        """
        Attend la touche ESPACE dans la fenêtre Pygame tout en la gardant réactive.
        
        Cela empêche l'erreur "ne répond pas" en traitant toutes les entrées
        exclusivement via Pygame au lieu de mélanger console/Pygame.
        
        Args:
            message: Message à afficher à l'utilisateur
        """
        print(f"[CALIB] ATTENTE : {message}")
        
        # Affiche le message sur le projecteur
        self.projector.show_message(message, color=(255, 255, 255), bg_color=(50, 50, 50))
        
        import pygame
        waiting = True
        while waiting:
            # Traite tous les événements Pygame
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    print("[CALIB] L'utilisateur a fermé la fenêtre, sortie...")
                    sys.exit(0)
                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_SPACE:
                        waiting = False
                        print("[CALIB] Validé !")
                    elif event.key == pygame.K_ESCAPE:
                        print("[CALIB] Calibration annulée par l'utilisateur")
                        sys.exit(0)
                    elif event.key == pygame.K_q:
                        print("[CALIB] Calibration annulée par l'utilisateur")
                        sys.exit(0)
            
            # Petite pause pour éviter de saturer le CPU
            time.sleep(0.01)
        
    def run(self) -> dict:
        """
        Exécute l'assistant de calibration complet.
        
        Returns:
            dict: Résultats de calibration à sauvegarder dans la config
            
        Étapes :
            1. Définir la zone sûre (marges)
            2. Détecter les coins projetés -> H_C2AV
            3. Détecter le marqueur physique -> échelle -> H_C2W
            4. Cartographier les obstacles statiques
            5. Calculer les dimensions de l'arène
            
        Logs :
            [CALIB] Étape X/4 : Description
        """
        print("[CALIB] ========== Démarrage de l'Assistant de Calibration ==========")
        
        # Démarre l'affichage du projecteur
        print("[CALIB] Démarrage de l'affichage projecteur...")
        self.projector.start()
        
        try:
            # Step 1: Safe zone
            self._step_safe_zone()
            
            # Step 2: Geometric calibration
            H_C2AV = self._step_geometric_calibration()
            
            # Step 3: Metric calibration
            scale = self._step_metric_calibration(H_C2AV)
            
            # Step 4: Obstacle mapping
            obstacles = self._step_obstacle_mapping()
            
            # Build results
            results = {
                'projector': {
                    'width': self.proj_w,
                    'height': self.proj_h,
                    'margin': self.margin_px,
                    'margin_px': self.margin_px  # Alias for compatibility
                },
                'display': {
                    'fullscreen': False,
                    'display_index': 0
                },
                'arena': {
                    'width_m': self.arena_width_m,
                    'height_m': self.arena_height_m
                },
                'transform': {
                    'H_C2W': self.H_C2W.tolist() if self.H_C2W is not None else None,
                    'scale': scale,
                    'scale_m_per_av': scale  # Alias for compatibility
                },
                'grid': {
                    'resolution_m': 0.02,  # 2cm grid resolution
                    'inflation_radius_m': 0.15  # 15cm safety margin
                },
                'obstacles': obstacles
            }
            
            print("[CALIB] Calibration complete!")
            return results
            
        finally:
            # Always stop projector
            print("[CALIB] Stopping projector display...")
            self.projector.stop()
    
    def _step_safe_zone(self):
        """
        Étape 1 : Définir la zone sûre pour la projection.
        
        Logs :
            [CALIB] MARGE définie à X px
            [CALIB] Rect arène dans projecteur : (x1,y1) -> (x2,y2)
        """
        print("[CALIB] MARGE définie à {} px".format(self.margin_px))
        
        x1, y1 = self.margin_px, self.margin_px
        x2 = self.proj_w - self.margin_px
        y2 = self.proj_h - self.margin_px
        
        print("[CALIB] Rect arène dans projecteur : ({},{}) -> ({},{})".format(x1, y1, x2, y2))
        
    def _step_geometric_calibration(self) -> np.ndarray:
        """
        Étape 2 : Détecter les coins projetés et calculer H_C2AV.
        
        Returns:
            H_C2AV: Matrice d'homographie
            
        Logs :
            [CALIB] 4 coins projetés détectés
            [CALIB] H_C2AV calculé avec succès
        """
        print("[CALIB] Étape 2/4 : Calibration géométrique (détection des coins projetés)")
        
        # Projette les marqueurs ArUco aux coins
        print("[CALIB] Projection des marqueurs ArUco (IDs 0-3) aux coins de l'arène...")
        self.projector.show_corner_markers(marker_size_px=200)
        
        print("[CALIB] Marqueurs ArUco affichés sur le projecteur")
        print("[CALIB] Vérifiez que la caméra voit les 4 marqueurs, puis appuyez sur ESPACE...")
        
        self._wait_for_user_validation("Vérifiez les 4 marqueurs et appuyez sur ESPACE")
        
        # Capture l'image
        color, _ = self.camera.get_frames()
        
        # Détecte ArUco
        detections = self.aruco.detect(color)
        
        # Vérifie les coins (IDs 0-3)
        corner_ids = [0, 1, 2, 3]
        detected_corners = {k: v for k, v in detections.items() if k in corner_ids}
        
        if len(detected_corners) != 4:
            print("[CALIB] ERREUR : Attendu 4 coins, trouvé {}".format(len(detected_corners)))
            print("[CALIB] IDs détectés : {}".format(list(detected_corners.keys())))
            raise ValueError("Coins projetés manquants")
        
        print("[CALIB] 4 coins projetés détectés")
        
        # Construit les correspondances
        src_points = []
        dst_points = []
        
        # Coordonnées virtuelles de l'arène (rectangle proportionnel au ratio du projecteur)
        ar = self.proj_w / self.proj_h
        av_coords = {
            0: (0.0, 0.0),  # Bas-Gauche
            1: (ar, 0.0),   # Bas-Droite
            2: (ar, 1.0),   # Haut-Droite
            3: (0.0, 1.0)   # Haut-Gauche
        }
        
        for marker_id in corner_ids:
            center = detected_corners[marker_id]['center']
            src_points.append(center)
            dst_points.append(av_coords[marker_id])
        
        src_points = np.array(src_points, dtype=np.float32)
        dst_points = np.array(dst_points, dtype=np.float32)
        
        # Calcule l'homographie
        H_C2AV, _ = cv2.findHomography(src_points, dst_points)
        
        print("[CALIB] H_C2AV calculé avec succès")
        
        return H_C2AV
    
    def _step_metric_calibration(self, H_C2AV: np.ndarray) -> float:
        """
        Étape 3 : Estimer l'échelle métrique à partir d'un marqueur physique en utilisant l'homographie.
        
        Cette méthode utilise l'homographie pour corriger la perspective de la caméra,
        garantissant des mesures précises quelle que soit la position du marqueur.
        
        Args:
            H_C2AV: Homographie de l'étape 2 (pixels caméra -> arène virtuelle)
            
        Returns:
            scale: mètres par unité AV
            
        Logs :
            [CALIB] Taille réelle du marqueur : X m
            [CALIB] Taille marqueur dans AV : Y unités
            [CALIB] Échelle : Z m / unité_AV
        """
        print("[CALIB] Étape 3/4 : Calibration métrique (placez le marqueur physique dans l'arène)")
        
        # Affiche les instructions sur le projecteur
        self.projector.show_message("Placez le robot (ID 4 ou 5) au centre", 
                                    color=(255, 255, 255), bg_color=(50, 50, 50))
        
        # Utilise la taille de marqueur configurée
        marker_size_real = self.marker_size_m
        print(f"[CALIB] Utilisation taille marqueur : {marker_size_real} m (depuis config/projector.yaml)")
        
        self._wait_for_user_validation("Placez le marqueur robot et appuyez sur ESPACE")
        
        # Capture l'image
        color, _ = self.camera.get_frames()
        
        # Détecte les marqueurs
        detections = self.aruco.detect(color)
        
        # Trouve le marqueur robot (ID 4 ou 5)
        marker_data = None
        robot_marker_id = None
        for mid in [4, 5]:
            if mid in detections:
                marker_data = detections[mid]
                robot_marker_id = mid
                break
        
        if marker_data is None:
            raise ValueError("Aucun marqueur robot détecté (ID 4 ou 5) !")
        
        print(f"[CALIB] Marqueur robot ID {robot_marker_id} détecté")
        
        # ============================================================
        # CORRECT METHOD: Use homography to transform marker corners
        # This accounts for camera perspective distortion
        # ============================================================
        
        corners_pix = marker_data['corners']  # List of 4 corner tuples in pixels
        
        # Transform corners from camera pixels to Arena Virtual space using H_C2AV
        pts_src = np.array([corners_pix], dtype=np.float32)
        pts_av = cv2.perspectiveTransform(pts_src, H_C2AV)  # Output: AV coordinates
        
        corners_av = pts_av[0]  # Shape: (4, 2)
        
        # Calculate marker size in AV space (average of all 4 sides)
        side_lengths = []
        for i in range(4):
            j = (i + 1) % 4
            length = np.linalg.norm(corners_av[j] - corners_av[i])
            side_lengths.append(length)
        
        size_av = np.mean(side_lengths)
        
        print(f"[CALIB] Taille du marqueur dans l'espace virtuel: {size_av:.4f} unités")
        
        # Compute scale: meters per AV unit
        scale_m_per_av = marker_size_real / size_av
        
        print(f"[CALIB] ÉCHELLE VALIDÉE: 1.0 unité virtuelle = {scale_m_per_av:.4f} mètres")
        
        # ============================================================
        # Build H_C2W using corner markers (IDs 0-3)
        # ============================================================
        
        ar = self.proj_w / self.proj_h
        av_coords = {
            0: [0.0, 0.0],  # Bottom-left
            1: [ar, 0.0],   # Bottom-right
            2: [ar, 1.0],   # Top-right
            3: [0.0, 1.0]   # Top-left
        }
        
        src_centers = []
        dst_coords = []
        for mid in corner_ids:
            if mid in detections:
                src_centers.append(detections[mid]['center'])
                dst_coords.append(av_coords[mid])
        
        if len(src_centers) < 4:
            print(f"[CALIB] WARNING: Seulement {len(src_centers)}/4 marqueurs de coin détectés")
        
        self.transform_mgr.set_camera_to_av(
            np.array(src_centers, dtype=np.float32),
            np.array(dst_coords, dtype=np.float32)
        )
        self.transform_mgr.set_av_to_world_scale(scale_m_per_av)
        
        self.H_C2W = self.transform_mgr.H_C2W
        
        # ============================================================
        # Calculate arena dimensions using homography-corrected scale
        # In AV space, the arena is always 1.0 x 1.0 (unit square)
        # So real dimensions = scale * 1.0
        # ============================================================
        
        # The arena width in meters is simply the scale * aspect_ratio (since AV width = ar)
        self.arena_width_m = scale_m_per_av * ar
        
        # For height, we just need scale * 1.0 (since AV height = 1.0)
        self.arena_height_m = scale_m_per_av * 1.0
        
        aspect_ratio = ar
        
        print(f"[CALIB] Dimensions de l'arène: {self.arena_width_m:.2f}m x {self.arena_height_m:.2f}m")
        print(f"[CALIB] Ratio d'aspect: {aspect_ratio:.2f}")
        
        print("[CALIB] H_C2W calculé")
        print("[CALIB] Calibration métrique OK")
        
        return scale_m_per_av
    
    def _step_obstacle_mapping(self) -> List:
        """
        Étape 4 : Cartographier les obstacles statiques.
        
        Returns:
            Liste des régions d'obstacles
            
        Logs :
            [CALIB] Taille arène estimée : XmxYm
            [CALIB] Obstacles statiques cartographiés
        """
        print("[CALIB] Étape 4/4 : Cartographie des obstacles")
        
        # Affiche un écran blanc pour le contraste des obstacles
        print("[CALIB] Affichage écran blanc pour détection obstacles...")
        self.projector.show_white_screen()
        
        print("[CALIB] Placez les obstacles dans l'arène, puis appuyez sur ESPACE...")
        
        self._wait_for_user_validation("Placez les obstacles et appuyez sur ESPACE")
        
        # Simplifié : retourne vide pour l'instant
        # L'implémentation complète ferait un seuillage et une détection de contours
        
        print("[CALIB] Taille arène estimée : {:.2f}m x {:.2f}m".format(self.arena_width_m, self.arena_height_m))
        print("[CALIB] Obstacles statiques cartographiés")
        
        return []


################################################################################
PATH: ./tank_project/perception/calibration/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/perception/calibration/projector_display.py
################################################################################
"""
Affichage Projecteur pour Étalonnage - VERSION FINALE

Affiche les marqueurs ArUco sur le projecteur pour l'assistant d'étalonnage.
Fonctionnalités :
- Positionnement automatique sur l'écran secondaire (VGA/HDMI)
- Mode san bordure pour masquer les décorations de fenêtre
- Curseur masqué pour l'immersion

Logs : préfixe [PROJ_DISPLAY]
"""

import os
import pygame
import cv2
import numpy as np
from typing import Tuple, Optional


class ProjectorDisplay:
    """
    Fenêtre Pygame pour projeter les motifs d'étalonnage.
    Force l'affichage sur le moniteur secondaire en utilisant les variables d'environnement SDL.
    """
    
    def __init__(self, width=1024, height=768, margin=50, monitor_offset_x=1920, monitor_offset_y=0,
                 borderless=True, hide_cursor=True):
        """
        Initialise l'affichage projecteur.
        
        Args:
            width: Largeur résolution projecteur (ex: 1024 pour VGA)
            height: Hauteur résolution projecteur (ex: 768 pour VGA)
            margin: Marge de sécurité depuis les bords (px)
            monitor_offset_x: Position X du projecteur (généralement largeur écran principal, ex: 1920)
            monitor_offset_y: Position Y (généralement 0)
            borderless: Utilise mode fenêtre sans bordure (NOFRAME)
            hide_cursor: Masque le curseur souris
        """
        self.width = width
        self.height = height
        self.margin = margin
        
        # --- CONFIGURATION MULTI-ECRAN ---
        self.monitor_x = monitor_offset_x
        self.monitor_y = monitor_offset_y
        self.borderless = borderless
        self.hide_cursor = hide_cursor
        
        self.screen = None
        self.running = False
        
        # Rectangle arène (avec marges)
        self.arena_x1 = margin
        self.arena_y1 = margin
        self.arena_x2 = width - margin
        self.arena_y2 = height - margin
        self.arena_w = self.arena_x2 - self.arena_x1
        self.arena_h = self.arena_y2 - self.arena_y1
        
        print("[PROJ_DISPLAY] Init : {}x{}, marge={}px".format(width, height, margin))
        print("[PROJ_DISPLAY] Décalage Moniteur Cible : X={}, Y={}".format(self.monitor_x, self.monitor_y))
    
    def start(self):
        """Démarre Pygame et crée la fenêtre sur le projecteur."""
        
        # 1. LE HACK: On force la position avant l'init de l'écran
        os.environ['SDL_VIDEO_WINDOW_POS'] = "%d,%d" % (self.monitor_x, self.monitor_y)
        
        pygame.init()
        
        # 2. Configure les drapeaux de fenêtre selon paramètres
        flags = pygame.DOUBLEBUF
        if self.borderless:
            flags |= pygame.NOFRAME
        
        self.screen = pygame.display.set_mode((self.width, self.height), flags)
        
        # 3. IMMERSION - Masque curseur si configuré
        if self.hide_cursor:
            pygame.mouse.set_visible(False)
        
        pygame.display.set_caption("Arène Tank - Vue Projecteur")
        self.running = True
        
        mode_str = "borderless" if self.borderless else "windowed"
        print(f"[PROJ_DISPLAY] Fenêtre ouverte au décalage {self.monitor_x} ({mode_str})")
    
    def stop(self):
        """Ferme l'affichage."""
        if self.running:
            pygame.quit()
            self.running = False
            print("[PROJ_DISPLAY] Affichage fermé")
    
    def clear(self, color=(0, 0, 0)):
        """Efface l'écran avec une couleur unie."""
        if self.screen:
            self.screen.fill(color)
    
    def get_events(self):
        """
        Retourne les événements au contrôleur externe (Wizard).
        Utilisez ceci au lieu de handle_events quand la logique est contrôlée à l'extérieur.
        """
        if not self.running:
            return []
        return pygame.event.get()

    def show_corner_markers(self, marker_size_px=200, aruco_dict=cv2.aruco.DICT_4X4_100):
        """
        Affiche les marqueurs ArUco aux 4 coins de l'arène.
        """
        if not self.running:
            return
        
        # Efface avec fond blanc
        self.clear((255, 255, 255))
        
        # Génère marqueurs
        aruco_dict_obj = cv2.aruco.getPredefinedDictionary(aruco_dict)
        
        # Positions coins (centre du marqueur)
        corners = {
            0: (self.arena_x1 + marker_size_px // 2, self.arena_y2 - marker_size_px // 2),  # Bottom-left
            1: (self.arena_x2 - marker_size_px // 2, self.arena_y2 - marker_size_px // 2),  # Bottom-right
            2: (self.arena_x2 - marker_size_px // 2, self.arena_y1 + marker_size_px // 2),  # Top-right
            3: (self.arena_x1 + marker_size_px // 2, self.arena_y1 + marker_size_px // 2),  # Top-left
        }
        
        print("[PROJ_DISPLAY] Projection de 4 marqueurs de coin (IDs 0-3)")
        
        for marker_id, (cx, cy) in corners.items():
            # Génère image marqueur
            marker_img = cv2.aruco.generateImageMarker(aruco_dict_obj, marker_id, marker_size_px)
            
            # Convertit en surface pygame
            marker_img_rgb = cv2.cvtColor(marker_img, cv2.COLOR_GRAY2RGB)
            marker_surface = pygame.surfarray.make_surface(
                np.transpose(marker_img_rgb, (1, 0, 2))
            )
            
            # Calcule coin haut-gauche
            x = cx - marker_size_px // 2
            y = cy - marker_size_px // 2
            
            # Dessine marqueur
            self.screen.blit(marker_surface, (x, y))
            
            # Ajoute étiquette ID sous marqueur
            font = pygame.font.Font(None, 36)
            text = font.render(f"ID {marker_id}", True, (0, 0, 0))
            text_rect = text.get_rect(center=(cx, cy + marker_size_px // 2 + 30))
            self.screen.blit(text, text_rect)
        
        # Met à jour affichage
        pygame.display.flip()
        
        print("[PROJ_DISPLAY] Marqueurs de coin affichés")
    
    def show_white_screen(self):
        """Affiche écran blanc uni (pour détection obstacles)."""
        if not self.running:
            return
        
        self.clear((255, 255, 255))
        
        # Ajoute instruction texte
        font = pygame.font.Font(None, 48)
        text = font.render("Placez des obstacles dans l'arène", True, (0, 0, 0))
        text_rect = text.get_rect(center=(self.width // 2, 100))
        self.screen.blit(text, text_rect)
        
        pygame.display.flip()
        print("[PROJ_DISPLAY] Écran blanc affiché")
    
    def show_message(self, message: str, color=(255, 255, 255), bg_color=(0, 0, 0)):
        """
        Affiche un message texte.
        """
        if not self.running:
            return
        
        self.clear(bg_color)
        
        # Ajustement taille police selon longueur
        font_size = 48
        if len(message) > 30:
            font_size = 36
            
        font = pygame.font.Font(None, font_size)
        text = font.render(message, True, color)
        text_rect = text.get_rect(center=(self.width // 2, self.height // 2))
        self.screen.blit(text, text_rect)
        
        pygame.display.flip()
    
    def _pump_events(self):
        """
        Interne : Garde la fenêtre réactive sans consommer les événements.
        Appelez ceci dans les opérations longues si vous n'utilisez pas get_events().
        """
        pygame.event.pump()


################################################################################
PATH: ./tank_project/perception/calibration/projector_mapping.py
################################################################################
"""
Projector Mapping - Transformation Monde -> Projecteur

Gère la conversion des coordonnées monde (mètres)
vers pixels projecteur pour affichage Pygame.

Logs: [PROJ_MAP] prefix
"""

import numpy as np
from typing import Tuple


class ProjectorMapping:
    """
    Mapping Monde -> Pixels Projecteur.
    """
    
    def __init__(self,
                 projector_width: int = 1024,
                 projector_height: int = 768,
                 margin: int = 50):
        """
        Initialize projector mapping.
        
        Args:
            projector_width: Résolution projecteur largeur
            projector_height: Résolution projecteur hauteur
            margin: Marge sécurité (pixels)
        """
        self.proj_w = projector_width
        self.proj_h = projector_height
        self.margin = margin
        
        self.draw_w = projector_width - 2 * margin
        self.draw_h = projector_height - 2 * margin
        
        # Paramètres monde (à définir après calibration)
        self.arena_width_m = None
        self.arena_height_m = None
        self.scale = None
        
    def set_arena_dimensions(self, width_m: float, height_m: float):
        """
        Définit dimensions arène et calcule échelle d'affichage.
        
        Args:
            width_m: Largeur arène en mètres
            height_m: Hauteur arène en mètres
            
        Logs:
            [PROJ_MAP] Arena set: WxH m, scale: S px/m
        """
        self.arena_width_m = width_m
        self.arena_height_m = height_m
        
        # Calculer échelle (maintenir aspect ratio)
        scale_x = self.draw_w / width_m
        scale_y = self.draw_h / height_m
        self.scale = min(scale_x, scale_y)
        
        print("[PROJ_MAP] Arène définie : {:.2f}x{:.2f}m, "
              "échelle : {:.1f} px/m".format(width_m, height_m, self.scale))
        
    def world_to_projector(self, x_m: float, y_m: float) -> Tuple[int, int]:
        """
        Convertit coordonnées monde -> pixels projecteur.
        
        Args:
            x_m, y_m: Position en mètres
            
        Returns:
            (px, py) position en pixels projecteur
        """
        if self.scale is None:
            raise ValueError("Appeler set_arena_dimensions d'abord")
        
        # Conversion avec flip Y (pygame origin top-left)
        px = self.margin + int(x_m * self.scale)
        py = self.margin + int((self.arena_height_m - y_m) * self.scale)
        
        return (px, py)
    
    def projector_to_world(self, px: int, py: int) -> Tuple[float, float]:
        """
        Convertit pixels projecteur -> coordonnées monde.
        
        Args:
            px, py: Position en pixels
            
        Returns:
            (x_m, y_m) position en mètres
        """
        if self.scale is None:
            raise ValueError("Appeler set_arena_dimensions d'abord")
        
        x_m = (px - self.margin) / self.scale
        y_m = self.arena_height_m - (py - self.margin) / self.scale
        
        return (x_m, y_m)
    
    def scale_length(self, length_m: float) -> int:
        """
        Convertit longueur mètres -> pixels.
        
        Args:
            length_m: Longueur en mètres
            
        Returns:
            Longueur en pixels
        """
        if self.scale is None:
            raise ValueError("Appeler set_arena_dimensions d'abord")
        
        return int(length_m * self.scale)
    
    def get_safe_zone_rect(self) -> Tuple[int, int, int, int]:
        """
        Retourne rectangle zone sécurité.
        
        Returns:
            (x, y, width, height) en pixels
        """
        return (self.margin, self.margin, self.draw_w, self.draw_h)


################################################################################
PATH: ./tank_project/perception/calibration/scale_estimator.py
################################################################################
"""
Scale Estimator - Estimation Échelle Métrique

Estime le facteur d'échelle de AV -> Monde en mètres
à partir d'un marqueur ArUco physique de taille connue.

Logs: [SCALE_EST] prefix
"""

import numpy as np
from typing import List, Tuple


class ScaleEstimator:
    """
    Estime l'échelle métrique depuis marqueur physique.
    """
    
    def __init__(self, marker_real_size_m: float = 0.10):
        """
        Initialize scale estimator.
        
        Args:
            marker_real_size_m: Taille réelle marqueur en mètres
        """
        self.marker_size_real = marker_real_size_m
        self.samples = []
        
    def estimate_from_corners(self,
                            corners_av: np.ndarray) -> float:
        """
        Estime échelle depuis coins marqueur en coordonnées AV.
        
        Args:
            corners_av: 4 coins en unités AV (4x2)
            
        Returns:
            Échelle en m/unité_av
        """
        # Calculer longueur moyenne des côtés en AV
        side_lengths = []
        for i in range(4):
            j = (i + 1) % 4
            length = np.linalg.norm(corners_av[j] - corners_av[i])
            side_lengths.append(length)
        
        avg_size_av = np.mean(side_lengths)
        
        # Échelle
        scale = self.marker_size_real / avg_size_av
        
        return scale
    
    def add_sample(self, corners_av: np.ndarray):
        """
        Ajoute une mesure d'échelle.
        
        Args:
            corners_av: Coins marqueur en AV
        """
        scale = self.estimate_from_corners(corners_av)
        self.samples.append(scale)
        print("[SCALE_EST] Échantillon {} : échelle={:.4f} m/unité".format(len(self.samples), scale))
        
    def get_average_scale(self) -> float:
        """
        Retourne échelle moyenne de tous les échantillons.
        
        Returns:
            Échelle moyenne
            
        Logs:
            [SCALE_EST] Average scale from N samples: X m/unit (std=Y)
        """
        if not self.samples:
            raise ValueError("Aucun échantillon disponible")
        
        avg = np.mean(self.samples)
        std = np.std(self.samples)
        
        print("[SCALE_EST] Échelle moyenne sur {} échantillons : "
              "{:.4f} m/unité (std={:.4f})".format(len(self.samples), avg, std))
        
        return avg
    
    def reset(self):
        """Réinitialise les échantillons."""
        self.samples = []


################################################################################
PATH: ./tank_project/perception/camera/aruco_detector.py
################################################################################
"""
Détecteur ArUco - Détection de Marqueurs & Estimation de Pose

Détecte les marqueurs ArUco dans les images caméra :
- Marqueurs projetés (ID 0-3) : coins de l'arène pour l'étalonnage
- Marqueurs robots (ID 4, 5) : suivi des robots

Fournit :
- Positions centrales des marqueurs (pixels)
- Orientations des marqueurs (radians)
- Positions des coins pour l'estimation de l'échelle

Logs : [ARUCO] Détecté N marqueurs : [IDs]
"""

import cv2
import numpy as np
from typing import List, Dict, Tuple, Optional


class ArucoDetector:
    """
    Détection de marqueurs ArUco et estimation de pose.
    
    Utilise cv2.aruco pour la détection de marqueurs.
    """
    
    def __init__(self, 
                 dictionary_type=cv2.aruco.DICT_4X4_50,
                 marker_size_m: float = 0.10):
        """
        Initialise le détecteur ArUco.
        
        Args:
            dictionary_type: Dictionnaire ArUco (défaut : 4x4, 50 marqueurs)
            marker_size_m: Taille physique du marqueur en mètres (pour estimation échelle)
        """
        self.dictionary = cv2.aruco.getPredefinedDictionary(dictionary_type)
        self.parameters = cv2.aruco.DetectorParameters()
        self.detector = cv2.aruco.ArucoDetector(self.dictionary, self.parameters)
        
        self.marker_size_m = marker_size_m
        
    def detect(self, image: np.ndarray) -> Dict[int, Dict]:
        """
        Détecte les marqueurs ArUco dans l'image.
        
        Args:
            image: Image d'entrée (BGR ou niveaux de gris)
            
        Returns:
            dict: {
                marker_id: {
                    'center': (u, v),  # coordonnées pixel
                    'corners': [(u1,v1), (u2,v2), (u3,v3), (u4,v4)],
                    'orientation': theta  # radians
                }
            }
            
        Logs:
            [ARUCO] Détecté N marqueurs : [IDs]
        """
        # Convertit en niveaux de gris si nécessaire
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # Détecte les marqueurs
        corners, ids, rejected = self.detector.detectMarkers(gray)
        
        results = {}
        
        if ids is not None:
            for i, marker_id in enumerate(ids.flatten()):
                marker_corners = corners[i][0]  # Shape: (4, 2)
                
                # Calcule le centre
                center = marker_corners.mean(axis=0)
                
                # Calcule l'orientation (du coin 0 au coin 1)
                # Ordre des coins : haut-gauche, haut-droite, bas-droite, bas-gauche
                dx = marker_corners[1][0] - marker_corners[0][0]
                dy = marker_corners[1][1] - marker_corners[0][1]
                orientation = np.arctan2(dy, dx)
                
                results[marker_id] = {
                    'center': tuple(center),
                    'corners': [tuple(c) for c in marker_corners],
                    'orientation': orientation
                }
            
            print("[ARUCO] Détecté {} marqueurs : {}".format(len(ids), ids.flatten().tolist()))
        
        return results
    
    def estimate_marker_size_av(self, marker_corners, H_C2AV):
        """
        Estime la taille du marqueur en unités de l'Arène Virtuelle.
        
        Utilisé pendant l'étalonnage pour calculer l'échelle métrique.
        
        Args:
            marker_corners: Liste des 4 positions de coins en pixels
            H_C2AV: Homographie caméra -> arène virtuelle
            
        Returns:
            float: Longueur du côté du marqueur en unités AV
        """
        # Transforme les coins vers l'espace AV
        corners_av = []
        for u, v in marker_corners:
            p_cam = np.array([u, v, 1.0])
            p_av = H_C2AV @ p_cam
            p_av = p_av[:2] / p_av[2]  # Normalize
            corners_av.append(p_av)
        
        # Calcule la longueur moyenne des côtés
        corners_av = np.array(corners_av)
        side_lengths = []
        for i in range(4):
            j = (i + 1) % 4
            length = np.linalg.norm(corners_av[j] - corners_av[i])
            side_lengths.append(length)
        
        avg_length = np.mean(side_lengths)
        
        return avg_length
    
    def draw_detections(self, image: np.ndarray, detections: Dict) -> np.ndarray:
        """
        Dessine les marqueurs détectés sur l'image (pour débogage).
        
        Args:
            image: Image d'entrée
            detections: Résultats de détection de detect()
            
        Returns:
            Image avec marqueurs dessinés
        """
        img_draw = image.copy()
        
        for marker_id, data in detections.items():
            center = data['center']
            corners = data['corners']
            
            # Dessine les coins
            corners_array = np.array(corners, dtype=np.int32)
            cv2.polylines(img_draw, [corners_array], True, (0, 255, 0), 2)
            
            # Dessine le centre
            cv2.circle(img_draw, (int(center[0]), int(center[1])), 5, (0, 0, 255), -1)
            
            # Dessine l'ID
            cv2.putText(img_draw, f"ID:{marker_id}", 
                       (int(center[0]), int(center[1]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        return img_draw


################################################################################
PATH: ./tank_project/perception/camera/color_segmentation.py
################################################################################
"""
Color Segmentation - Détection Obstacles par Seuillage

Segmente les obstacles sur fond blanc par seuillage couleur:
- Détection zones sombres (obstacles)
- Masques binaires
- Filtrage bruit

Utilisé pendant la calibration pour cartographier obstacles statiques.

Logs: [SEGMENT] prefix
"""

import cv2
import numpy as np
from typing import Tuple


def threshold_obstacles(image: np.ndarray, 
                       threshold_value: int = 200) -> np.ndarray:
    """
    Seuillage simple pour détecter obstacles sur fond blanc.
    
    Args:
        image: Image BGR ou grayscale
        threshold_value: Seuil (pixels < threshold = obstacles)
        
    Returns:
        Masque binaire (0 = libre, 255 = obstacle)
    """
    # Convertir en niveaux de gris si nécessaire
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # Seuillage inverse (obstacles sont sombres)
    _, binary = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)
    
    return binary


def adaptive_threshold_obstacles(image: np.ndarray) -> np.ndarray:
    """
    Seuillage adaptatif pour conditions éclairage variables.
    
    Args:
        image: Image BGR ou grayscale
        
    Returns:
        Masque binaire
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # Seuillage adaptatif
    binary = cv2.adaptiveThreshold(
        gray, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        blockSize=11,
        C=2
    )
    
    return binary


def remove_noise(binary_mask: np.ndarray, 
                kernel_size: int = 5) -> np.ndarray:
    """
    Retire le bruit du masque binaire.
    
    Args:
        binary_mask: Masque binaire
        kernel_size: Taille kernel morphologie
        
    Returns:
        Masque filtré
    """
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    
    # Opening (erosion puis dilatation) pour retirer petits points
    opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
    
    # Closing (dilatation puis erosion) pour remplir trous
    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
    
    return closed


def segment_obstacles(image: np.ndarray, 
                     method: str = 'simple',
                     denoise: bool = True) -> np.ndarray:
    """
    Pipeline complet de segmentation obstacles.
    
    Args:
        image: Image source
        method: 'simple' ou 'adaptive'
        denoise: Appliquer filtrage bruit
        
    Returns:
        Masque binaire nettoyé
        
    Logs:
        [SEGMENT] Obstacles detected: N pixels
    """
    if method == 'adaptive':
        mask = adaptive_threshold_obstacles(image)
    else:
        mask = threshold_obstacles(image)
    
    if denoise:
        mask = remove_noise(mask)
    
    # Compter pixels obstacles
    obstacle_pixels = np.count_nonzero(mask)
    print("[SEGMENT] Obstacles détectés : {} pixels".format(obstacle_pixels))
    
    return mask


################################################################################
PATH: ./tank_project/perception/camera/homography.py
################################################################################
"""
Homography - Calculs Transformations Homographiques

Calcule et applique les homographies:
- H_C2AV: Caméra -> Arène Virtuelle
- H_AV2W: Arène Virtuelle -> Monde (scaling)
- H_C2W: Caméra -> Monde (combinée)

Utilisé par calibration_wizard et coordinate_frames.

Logs: [HOMOGRAPHY] prefix
"""

import cv2
import numpy as np
from typing import List, Tuple


def compute_homography(src_points: np.ndarray,
                      dst_points: np.ndarray) -> np.ndarray:
    """
    Calcule homographie entre points source et destination.
    
    Args:
        src_points: Points source (Nx2) en pixels caméra
        dst_points: Points destination (Nx2) en coordonnées cible
        
    Returns:
        Matrice homographie 3x3
        
    Raises:
        ValueError: Si moins de 4 points
        
    Logs:
        [HOMOGRAPHY] Computed from N points
    """
    if len(src_points) < 4 or len(dst_points) < 4:
        raise ValueError("Au moins 4 points requis pour homographie")
    
    # Assurer type float32
    src = np.array(src_points, dtype=np.float32)
    dst = np.array(dst_points, dtype=np.float32)
    
    # Calculer homographie
    H, _ = cv2.findHomography(src, dst)
    
    print("[HOMOGRAPHY] Calculé depuis {} points".format(len(src_points)))
    
    return H


def apply_homography(points: np.ndarray, H: np.ndarray) -> np.ndarray:
    """
    Applique homographie à des points.
    
    Args:
        points: Points à transformer (Nx2)
        H: Matrice homographie 3x3
        
    Returns:
        Points transformés (Nx2)
    """
    # Convertir en coordonnées homogènes
    ones = np.ones((points.shape[0], 1))
    points_h = np.hstack([points, ones])
    
    # Appliquer transformation
    transformed_h = (H @ points_h.T).T
    
    # Normaliser (diviser par coordonnée w)
    transformed = transformed_h[:, :2] / transformed_h[:, 2:3]
    
    return transformed


def apply_homography_single(point: Tuple[float, float], 
                           H: np.ndarray) -> Tuple[float, float]:
    """
    Applique homographie à un point unique.
    
    Args:
        point: (x, y) point source
        H: Matrice homographie
        
    Returns:
        (x', y') point transformé
    """
    # Coordonnées homogènes
    p_h = np.array([point[0], point[1], 1.0])
    
    # Transformation
    p_transformed = H @ p_h
    
    # Normalisation
    x = p_transformed[0] / p_transformed[2]
    y = p_transformed[1] / p_transformed[2]
    
    return (x, y)


def create_scaling_matrix(scale: float) -> np.ndarray:
    """
    Crée matrice de scaling homogène.
    
    Args:
        scale: Facteur d'échelle
        
    Returns:
        Matrice 3x3
    """
    S = np.array([
        [scale, 0, 0],
        [0, scale, 0],
        [0, 0, 1]
    ], dtype=np.float32)
    
    return S


def combine_homographies(H1: np.ndarray, H2: np.ndarray) -> np.ndarray:
    """
    Combine deux homographies: H_combined = H2 @ H1.
    
    Args:
        H1: Première transformation
        H2: Deuxième transformation
        
    Returns:
        Homographie combinée
    """
    return H2 @ H1


def estimate_scale_from_marker(marker_corners_px: List[Tuple[float, float]],
                               H_C2AV: np.ndarray,
                               real_size_m: float) -> float:
    """
    Estime échelle métrique depuis marqueur ArUco.
    
    Args:
        marker_corners_px: 4 coins marqueur en pixels caméra
        H_C2AV: Homographie Caméra -> Arène Virtuelle
        real_size_m: Taille réelle marqueur en mètres
        
    Returns:
        Scale en mètres/unité AV
        
    Algorithm:
        1. Transformer coins en AV
        2. Calculer taille moyenne en AV
        3. scale = real_size_m / size_av
        
    Logs:
        [HOMOGRAPHY] Scale estimation: real=Xm, av=Y units -> scale=Z m/unit
    """
    # Transformer coins en AV
    corners_av = apply_homography(np.array(marker_corners_px), H_C2AV)
    
    # Calculer longueurs des 4 côtés
    side_lengths = []
    for i in range(4):
        j = (i + 1) % 4
        length = np.linalg.norm(corners_av[j] - corners_av[i])
        side_lengths.append(length)
    
    # Moyenne
    avg_size_av = np.mean(side_lengths)
    
    # Échelle
    scale = real_size_m / avg_size_av
    
    print("[HOMOGRAPHY] Estimation échelle : réel={:.3f}m, "
          "av={:.3f} unités -> échelle={:.3f} m/unité".format(real_size_m, avg_size_av, scale))
    
    return scale


################################################################################
PATH: ./tank_project/perception/camera/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/perception/camera/kalman_filter.py
################################################################################
"""
Filtre de Kalman - Suivi de Pose Robot

Filtre de Kalman Étendu (EKF) pour l'estimation d'état du robot :
- État : [x, y, vx, vy, theta, omega]
- Mesures : [x, y, theta] depuis ArUco
- Prédiction : modèle à vitesse constante

Lisse les détections ArUco bruitées et estime les vitesses.

Logs : [KALMAN] RobotX state: x=X, y=Y, theta=T, vx=VX, vy=VY
"""

import numpy as np
from typing import Tuple


class KalmanFilter:
    """
    Filtre de Kalman Étendu pour l'estimation de pose et vitesse du robot 2D.
    
    Vecteur d'état : [x, y, vx, vy, theta, omega]
    """
    
    def __init__(self, dt: float = 1/30.0):
        """
        Initialise le filtre de Kalman.
        
        Args:
            dt: Pas de temps (défaut 30 FPS = 0.033s)
        """
        self.dt = dt
        
        # État : [x, y, vx, vy, theta, omega]
        self.state = np.zeros(6)
        
        # Covariance de l'état
        self.P = np.eye(6) * 1.0
        
        # Bruit de processus
        self.Q = np.diag([0.01, 0.01, 0.1, 0.1, 0.01, 0.1])
        
        # Bruit de mesure
        self.R = np.diag([0.05, 0.05, 0.1])  # [x, y, theta]
        
    def predict(self):
        """
        Étape de prédiction : propage l'état vers l'avant.
        
        Transition d'état :
            x += vx * dt
            y += vy * dt
            vx (constant)
            vy (constant)
            theta += omega * dt
            omega (constant)
        """
        # Matrice de transition d'état
        F = np.array([
            [1, 0, self.dt, 0, 0, 0],
            [0, 1, 0, self.dt, 0, 0],
            [0, 0, 1, 0, 0, 0],
            [0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 1, self.dt],
            [0, 0, 0, 0, 0, 1]
        ])
        
        # Prédit l'état
        self.state = F @ self.state
        
        # Normalise theta
        self.state[4] = np.arctan2(np.sin(self.state[4]), np.cos(self.state[4]))
        
        # Prédit la covariance
        self.P = F @ self.P @ F.T + self.Q
        
    def update(self, measurement: Tuple[float, float, float]):
        """
        Étape de mise à jour : incorpore la mesure.
        
        Args:
            measurement: (x, y, theta) depuis la détection ArUco
        """
        # Matrice de mesure (observe x, y, theta)
        H = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0],
            [0, 0, 0, 0, 1, 0]
        ])
        
        z = np.array(measurement)
        
        # Innovation
        y = z - H @ self.state
        
        # Normalise l'innovation angulaire
        y[2] = np.arctan2(np.sin(y[2]), np.cos(y[2]))
        
        # Covariance de l'innovation
        S = H @ self.P @ H.T + self.R
        
        # Gain de Kalman
        K = self.P @ H.T @ np.linalg.inv(S)
        
        # Met à jour l'état
        self.state = self.state + K @ y
        
        # Normalise theta
        self.state[4] = np.arctan2(np.sin(self.state[4]), np.cos(self.state[4]))
        
        # Met à jour la covariance
        self.P = (np.eye(6) - K @ H) @ self.P
        
    def get_pose(self) -> Tuple[float, float, float]:
        """
        Obtient l'estimation de pose actuelle.
        
        Returns:
            (x, y, theta)
        """
        return (self.state[0], self.state[1], self.state[4])
    
    def get_velocity(self) -> Tuple[float, float, float]:
        """
        Obtient l'estimation de vitesse actuelle.
        
        Returns:
            (vx, vy, omega)
        """
        return (self.state[2], self.state[3], self.state[5])
    
    def get_full_state(self) -> np.ndarray:
        """
        Obtient le vecteur d'état complet.
        
        Returns:
            [x, y, vx, vy, theta, omega]
        """
        return self.state.copy()
    
    def reset(self, initial_pose: Tuple[float, float, float]):
        """
        Réinitialise le filtre avec une nouvelle pose initiale.
        
        Args:
            initial_pose: (x, y, theta)
        """
        self.state = np.array([
            initial_pose[0],  # x
            initial_pose[1],  # y
            0.0,              # vx
            0.0,              # vy
            initial_pose[2],  # theta
            0.0               # omega
        ])
        
        self.P = np.eye(6) * 1.0


################################################################################
PATH: ./tank_project/perception/camera/realsense_stream.py
################################################################################
"""
Flux RealSense - Interface Caméra Intel RealSense

Gère la caméra RealSense D435/D455 :
- Acquisition flux couleur
- Flux profondeur (optionnel)
- Configuration caméra
- Gestion fréquence d'images

Fournit frames couleur et profondeur synchronisées à 30 FPS.

Logs : préfixe [REALSENSE] pour les opérations caméra
"""

import pyrealsense2 as rs
import numpy as np
from typing import Tuple, Optional


class RealSenseStream:
    """
    Interface pour caméra Intel RealSense.
    
    Gère l'initialisation de la caméra et l'acquisition des frames.
    """
    
    def __init__(self, 
                 width: int = 640, 
                 height: int = 480, 
                 fps: int = 30,
                 enable_depth: bool = False):
        """
        Initialise la caméra RealSense.
        
        Args:
            width: Largeur frame
            height: Hauteur frame
            fps: Fréquence d'images
            enable_depth: Activer flux profondeur
            
        Logs:
            [REALSENSE] Camera initialized: WxH @ FPS fps
        """
        self.width = width
        self.height = height
        self.fps = fps
        self.enable_depth = enable_depth
        
        self.pipeline = None
        self.config = None
        
    def start(self):
        """
        Démarre le pipeline caméra.
        
        Logs:
            [REALSENSE] Pipeline démarré
            [REALSENSE] Échec du démarrage : erreur
        """
        try:
            self.pipeline = rs.pipeline()
            self.config = rs.config()
            
            # Configure les flux
            self.config.enable_stream(rs.stream.color, 
                                     self.width, self.height, 
                                     rs.format.bgr8, self.fps)
            
            if self.enable_depth:
                self.config.enable_stream(rs.stream.depth, 
                                         self.width, self.height, 
                                         rs.format.z16, self.fps)
            
            # Démarre pipeline
            self.pipeline.start(self.config)
            
            print("[REALSENSE] Pipeline démarré : {}x{} @ {} fps".format(self.width, self.height, self.fps))
            
        except Exception as e:
            print("[REALSENSE] Échec du démarrage : {}".format(e))
            raise
    
    def stop(self):
        """Arrête le pipeline caméra."""
        if self.pipeline:
            self.pipeline.stop()
            print("[REALSENSE] Pipeline arrêté")
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        Obtient les dernières frames couleur et profondeur.
        
        Returns:
            (color_frame, depth_frame): tableaux numpy
            color_frame: Image BGR HxWx3
            depth_frame: Carte profondeur HxW (mm) ou None
        """
        if not self.pipeline:
            return (None, None)
        
        try:
            # Attend les frames
            frames = self.pipeline.wait_for_frames()
            
            # Obtient frame couleur
            color_frame = frames.get_color_frame()
            color_image = np.asanyarray(color_frame.get_data()) if color_frame else None
            
            # Obtient frame profondeur (si activé)
            depth_image = None
            if self.enable_depth:
                depth_frame = frames.get_depth_frame()
                depth_image = np.asanyarray(depth_frame.get_data()) if depth_frame else None
            
            return (color_image, depth_image)
            
        except Exception as e:
            print("[REALSENSE] Erreur d'acquisition frame : {}".format(e))
            return (None, None)
    
    def get_intrinsics(self):
        """
        Obtient les paramètres intrinsèques de la caméra.
        
        Returns:
            objet rs.intrinsics avec fx, fy, cx, cy
        """
        if self.pipeline:
            profile = self.pipeline.get_active_profile()
            color_stream = profile.get_stream(rs.stream.color)
            intrinsics = color_stream.as_video_stream_profile().get_intrinsics()
            return intrinsics
        return None


################################################################################
PATH: ./tank_project/perception/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/perception/preprocessing/contours.py
################################################################################
"""
Contours - Extraction Contours

Extraction et traitement des contours d'image.

Logs: [CONTOURS] prefix
"""

import cv2
import numpy as np
from typing import List, Tuple


def find_contours(binary_image: np.ndarray) -> List[np.ndarray]:
    """
    Trouve contours dans image binaire.
    
    Args:
        binary_image: Image binaire
        
    Returns:
        Liste de contours
    """
    contours, _ = cv2.findContours(
        binary_image,
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )
    
    print("[CONTOURS] Trouvé {} contours".format(len(contours)))
    
    return contours


def filter_contours_by_area(contours: List[np.ndarray],
                           min_area: float = 100.0,
                           max_area: float = np.inf) -> List[np.ndarray]:
    """
    Filtre contours par aire.
    
    Args:
        contours: Liste contours
        min_area: Aire minimum
        max_area: Aire maximum
        
    Returns:
        Contours filtrés
    """
    filtered = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if min_area <= area <= max_area:
            filtered.append(cnt)
    
    print("[CONTOURS] Filtré {} -> {} contours".format(len(contours), len(filtered)))
    
    return filtered


def get_bounding_boxes(contours: List[np.ndarray]) -> List[Tuple[int, int, int, int]]:
    """
    Extrait rectangles englobants.
    
    Args:
        contours: Liste contours
        
    Returns:
        Liste (x, y, w, h) rectangles
    """
    boxes = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        boxes.append((x, y, w, h))
    
    return boxes


def approximate_polygons(contours: List[np.ndarray],
                        epsilon_factor: float = 0.02) -> List[np.ndarray]:
    """
    Approxime contours par polygones.
    
    Args:
        contours: Liste contours
        epsilon_factor: Facteur précision (% périmètre)
        
    Returns:
        Contours approximés
    """
    approximated = []
    for cnt in contours:
        epsilon = epsilon_factor * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        approximated.append(approx)
    
    return approximated


################################################################################
PATH: ./tank_project/perception/preprocessing/image_utils.py
################################################################################
"""
Image Utils - Utilitaires Traitement Image

Fonctions utilitaires pour traitement d'images.

Logs: [IMG_UTILS] prefix
"""

import cv2
import numpy as np
from typing import Tuple


def convert_to_grayscale(image: np.ndarray) -> np.ndarray:
    """
    Convertit image en niveaux de gris.
    
    Args:
        image: Image BGR ou RGB
        
    Returns:
        Image grayscale
    """
    if len(image.shape) == 2:
        return image  # Déjà grayscale
    
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)


def resize_image(image: np.ndarray,
                width: int,
                height: int,
                interpolation=cv2.INTER_LINEAR) -> np.ndarray:
    """
    Redimensionne image.
    
    Args:
        image: Image source
        width: Nouvelle largeur
        height: Nouvelle hauteur
        interpolation: Méthode interpolation
        
    Returns:
        Image redimensionnée
    """
    return cv2.resize(image, (width, height), interpolation=interpolation)


def gaussian_blur(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """
    Applique flou gaussien.
    
    Args:
        image: Image source
        kernel_size: Taille kernel (impair)
        
    Returns:
        Image floutée
    """
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)


def morphological_open(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """
    Opening morphologique (erosion puis dilatation).
    
    Args:
        image: Image binaire
        kernel_size: Taille kernel
        
    Returns:
        Image traitée
    """
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)


def morphological_close(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """
    Closing morphologique (dilatation puis erosion).
    
    Args:
        image: Image binaire
        kernel_size: Taille kernel
        
    Returns:
        Image traitée
    """
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)


def warp_perspective(image: np.ndarray,
                     H: np.ndarray,
                     output_size: Tuple[int, int]) -> np.ndarray:
    """
    Applique transformation perspective (warp).
    
    Args:
        image: Image source
        H: Matrice homographie 3x3
        output_size: (width, height) sortie
        
    Returns:
        Image transformée
    """
    return cv2.warpPerspective(image, H, output_size)


def equalize_histogram(image: np.ndarray) -> np.ndarray:
    """
    Égalisation histogramme.
    
    Args:
        image: Image grayscale
        
    Returns:
        Image égalisée
    """
    return cv2.equalizeHist(image)


################################################################################
PATH: ./tank_project/perception/preprocessing/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/perception/preprocessing/thresholding.py
################################################################################
"""
Thresholding - Seuillage Image

Fonctions de seuillage pour détection obstacles.

Logs: [THRESHOLD] prefix
"""

import cv2
import numpy as np


def simple_threshold(image: np.ndarray,
                    threshold: int = 200,
                    max_value: int = 255) -> np.ndarray:
    """
    Seuillage binaire simple.
    
    Args:
        image: Image grayscale
        threshold: Valeur seuil
        max_value: Valeur maximum
        
    Returns:
        Image binaire
    """
    _, binary = cv2.threshold(image, threshold, max_value, cv2.THRESH_BINARY)
    return binary


def inverse_threshold(image: np.ndarray,
                     threshold: int = 200) -> np.ndarray:
    """
    Seuillage inverse (pour obstacles sombres sur fond clair).
    
    Args:
        image: Image grayscale
        threshold: Valeur seuil
        
    Returns:
        Image binaire (obstacles = 255)
    """
    _, binary = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY_INV)
    return binary


def otsu_threshold(image: np.ndarray) -> np.ndarray:
    """
    Seuillage automatique Otsu.
    
    Args:
        image: Image grayscale
        
    Returns:
        Image binaire
    """
    _, binary = cv2.threshold(image, 0, 255, 
                              cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary


def adaptive_threshold(image: np.ndarray,
                      block_size: int = 11,
                      C: int = 2) -> np.ndarray:
    """
    Seuillage adaptatif.
    
    Args:
        image: Image grayscale
        block_size: Taille bloc voisinage (impair)
        C: Constante soustraite de moyenne
        
    Returns:
        Image binaire
    """
    binary = cv2.adaptiveThreshold(
        image, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        block_size, C
    )
    return binary


################################################################################
PATH: ./tank_project/QUICKSTART.md
################################################################################
# Guide Rapide - Lancement du Projet

## Methodes de Lancement

### 1. Depuis le repertoire du projet

```bash
cd /home/julien/ros2_ws/src/VA-51/tank_project

# Afficher l'aide
python3 main.py --help

# Lancer le jeu
python3 main.py
python3 main.py game

# Lancer la calibration
python3 main.py calibration

# Exporter donnees debug
python3 main.py export
```

### 2. En tant que module Python

```bash
cd /home/julien/ros2_ws/src/VA-51

# Afficher l'aide
python3 -m tank_project --help

# Lancer le jeu
python3 -m tank_project
python3 -m tank_project game

# Lancer la calibration
python3 -m tank_project calibration

# Exporter donnees debug
python3 -m tank_project export
```

### 3. Via les scripts directs

```bash
cd /home/julien/ros2_ws/src/VA-51/tank_project

# Calibration
python3 scripts/run_calibration.py

# Jeu
python3 scripts/run_game.py

# Export debug
python3 scripts/export_debug_data.py --output-dir logs/debug_custom
```

## Prerequisites

### Installation des dependances

```bash
cd /home/julien/ros2_ws/src/VA-51/tank_project
pip3 install -r requirements.txt
```

Dependances principales:
- `numpy` - Calculs numeriques
- `opencv-python` - Vision par ordinateur
- `pyrealsense2` - Interface camera RealSense
- `pygame` - Rendu graphique
- `scipy` - Traitement signal
- `pyyaml` - Configuration

## Workflow Complet

### Premiere Utilisation

```bash
# 1. Installer dependances
pip3 install -r requirements.txt

# 2. Lancer calibration (obligatoire la premiere fois)
python3 scripts/run_calibration.py

# Suivre les instructions a l'ecran:
# - Appuyer sur ESPACE pour valider chaque etape
# - Detecter coins projetes (ArUco 0-3)
# - Mesurer marqueur physique (ArUco 4 ou 5)
# - Cartographier obstacles

# 3. Verifier calibration sauvegardee
cat config/arena.yaml

# 4. Valider visuellement l'homographie (RECOMMANDE)
python3 scripts/show_grid.py
# - Poser un marqueur dans un coin -> la cible cyan doit etre au bon endroit
# - Appuyer sur D pour voir l'inflation (zones oranges)
# - ESC pour quitter

# 5. Lancer le jeu
python3 scripts/run_game.py
```

### Utilisation Normale

```bash
# Lancer directement le jeu (calibration deja faite)
python3 main.py
```

## Debug et Diagnostic

### Export donnees debug

```bash
# Exporter snapshot complet
python3 main.py export

# Donnees exportees dans:
# logs/debug_YYYYMMDD_HHMMSS/
```

### Verifier imports

```bash
# Tester que tous les modules s'importent correctement
python3 -c "
from core.game import game_engine
from core.ia import strategy
from perception.camera import aruco_detector
from visualization import pygame_renderer
print('Tous les imports OK')
"
```

### Logs

Les logs sont stockes dans `logs/`:
- `runtime.log` - Logs d'execution jeu
- `calibration.log` - Logs calibration
- `debug.log` - Logs debug general

Filtrer logs par module:
```bash
# Logs IA uniquement
python3 main.py 2>&1 | grep "\[AI\]"

# Logs vision uniquement
python3 main.py 2>&1 | grep "\[VISION\]"

# Logs calibration
python3 main.py calibration 2>&1 | tee logs/calibration.log
```

## Configuration

Modifier les parametres dans `config/*.yaml`:

- `arena.yaml` - Dimensions arene, transformations, affichage
- `camera.yaml` - Parametres RealSense, ArUco
- `game.yaml` - Regles jeu (duree, cooldowns)
- `ia.yaml` - Comportement IA (distances, seuils)
- `robot.yaml` - Specs Turtlebot (vitesses, dimensions)

Exemple:
```bash
# Editer duree match (defaut: 180s)
nano config/game.yaml
```

## Depannage

### Erreur "No module named 'cv2'"
```bash
pip3 install opencv-python
```

### Erreur "No module named 'pyrealsense2'"
```bash
# Installer SDK RealSense
sudo apt-get install librealsense2-dev
pip3 install pyrealsense2
```

### Pygame ne demarre pas
```bash
pip3 install --upgrade pygame
```

### ROS bridge connection failed
Verifier que le pont ROS est actif sur les robots:
```bash
# Sur le robot
ros2 run ros_bridge server
```

## Plus d'Informations

Voir le [README.md](README.md) complet pour:
- Architecture detaillee
- Description modules
- Mecaniques de jeu
- Details techniques


################################################################################
PATH: ./tank_project/README.md
################################################################################
# Tank Project

Moteur de jeu principal pour Tank Arena avec IA comportementale, vision par ordinateur, et contrôle robot.

## Structure

```
tank_project/
├── config/              # Configuration YAML
├── core/
│   ├── control/         # Cinématique, trajectoire, ROS bridge
│   ├── game/            # GameEngine, Raycast, Hits
│   ├── ia/              # Behavior Tree, A*, Decisions
│   └── world/           # WorldModel, OccupancyGrid
├── perception/
│   ├── calibration/     # Calibration arène/projecteur
│   └── camera/          # ArUco, Kalman, RealSense
├── visualization/       # Pygame renderer, HUD
└── scripts/
    └── run_game.py      # Point d'entrée
```

## Lancement

```bash
cd tank_project
python3 scripts/run_game.py
```

## Configuration

| Fichier       | Description                  |
| ------------- | ---------------------------- |
| `arena.yaml`  | Dimensions arène, projecteur |
| `camera.yaml` | RealSense, ArUco, Kalman     |
| `game.yaml`   | Règles du jeu, cooldowns     |
| `ia.yaml`     | Comportement IA              |
| `robot.yaml`  | Cinématique, port 8765       |

## Connexion au Bridge

Le `ROSBridgeClient` se connecte au Safety Bridge avec retry automatique :

```python
client = ROSBridgeClient(host='localhost', port=8765)
client.connect(max_retries=0, retry_interval=8.0)  # Retry infini
```

## Contrôles

| Touche    | Action                     |
| --------- | -------------------------- |
| `Espace`  | Démarrer match             |
| `Flèches` | Contrôler robot humain     |
| `F`       | Tirer                      |
| `D`       | Toggle debug paths / inflation |
| `ESC`     | Quitter                    |

## Scripts Utiles

```bash
# Calibration (obligatoire 1ère fois)
python3 scripts/run_calibration.py

# Validation visuelle homographie
python3 scripts/show_grid.py

# Lancer le jeu
python3 scripts/run_game.py
```


################################################################################
PATH: ./tank_project/requirements.txt
################################################################################
# Dépendances Projet Tank Arena

# Vision & Traitement Image
numpy>=1.20.0
opencv-python>=4.5.0
pyrealsense2>=2.50.0

# Visualisation
pygame>=2.1.0

# Traitement Signal & Math
scipy>=1.7.0

# Configuration
pyyaml>=5.4.0

# Utilitaires
matplotlib>=3.3.0


################################################################################
PATH: ./tank_project/scripts/detect_projector_resolution.py
################################################################################
#!/usr/bin/env python3
"""
Détecter et Configurer la Résolution du Projecteur

Ce script :
1. Liste les écrans connectés.
2. Vous permet d'identifier le projecteur.
3. Met à jour automatiquement config/projector.yaml.

Usage :
    python3 scripts/detect_projector_resolution.py
"""

import pygame
import sys
import yaml
from pathlib import Path

def load_projector_config():
    config_path = Path(__file__).parent.parent / 'config' / 'projector.yaml'
    if config_path.exists():
        with open(config_path) as f:
            return yaml.safe_load(f), config_path
    return None, config_path

def save_projector_config(config, path):
    with open(path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    print(f"✅ Configuration sauvegardée dans {path}")

def main():
    print("=" * 60)
    print("  CONFIGURATION AUTOMATIQUE DU PROJECTEUR")
    print("=" * 60)
    
    pygame.init()
    
    # 1. Détection des écrans
    try:
        displays = pygame.display.get_desktop_sizes()
    except AttributeError:
        # Fallback Pygame ancien
        info = pygame.display.Info()
        displays = [(info.current_w, info.current_h)]
        print("Note: Pygame ancien, détection limitée.")

    print(f"\n🖥️  Écrans détectés : {len(displays)}\n")
    
    for i, (w, h) in enumerate(displays):
        print(f"  [{i}] {w} x {h} px  {'<-- Probablement le PC' if i==0 else '<-- Probablement le Projecteur'}")

    print("\nQuelle est l'ID de votre projecteur ?")
    
    try:
        choice = input(f"Entrez le numéro (0-{len(displays)-1}) ou 'q' pour quitter : ")
        if choice.lower() == 'q':
            return
        
        idx = int(choice)
        if idx < 0 or idx >= len(displays):
            print("❌ ID invalide.")
            return
            
        target_w, target_h = displays[idx]
        print(f"\n👌 Vous avez choisi : {target_w} x {target_h} px")
        
        # 2. Mise à jour de la config
        config, path = load_projector_config()
        if config is None:
            print("❌ Erreur : config/projector.yaml introuvable.")
            return
            
        print(f"\nAncienne configuration : {config['projector']['width']} x {config['projector']['height']}")
        
        # Mise à jour resolution
        config['projector']['width'] = target_w
        config['projector']['height'] = target_h
        
        # Mise à jour offset (si 2 écrans et projecteur est le 2eme)
        # On suppose que l'offset X est la largeur du premier écran si on choisit le 2eme
        if len(displays) > 1 and idx == 1:
            offset_x = displays[0][0]
            print(f"Mise à jour de l'offset X à {offset_x} (largeur écran principal)")
            config['display']['monitor_offset_x'] = offset_x
        
        # Confirmation
        confirm = input("\nSauvegarder cette configuration ? (o/n) : ")
        if confirm.lower() == 'o':
            save_projector_config(config, path)
            print("\n✨ SUCCÈS ! La résolution est corrigée.")
            print("Relancez maintenant 'python3 scripts/run_calibration.py'")
        else:
            print("Annulé.")

    except ValueError:
        print("Entrée invalide.")
    except Exception as e:
        print(f"Erreur : {e}")
    finally:
        pygame.quit()

if __name__ == "__main__":
    main()

################################################################################
PATH: ./tank_project/scripts/export_debug_data.py
################################################################################
#!/usr/bin/env python3
"""
Export Debug Data - Sauvegarde Donnees Debug

Export snapshots debug pour analyse offline:
- Images camera (capture live ou test)
- Grilles occupation (NumPy + visualisation)
- Homographies et calibration
- Etat jeu (JSON)
- Logs

Modes:
    - Standalone : Export config + logs (sans systeme actif)
    - Live       : Capture snapshot depuis camera (avec --live)

Usage:
    python3 export_debug_data.py [--output-dir DIR] [--live]
    
Examples:
    # Export config + logs seulement
    python3 export_debug_data.py
    
    # Capture live depuis camera
    python3 export_debug_data.py --live
    
    # Export vers repertoire specifique
    python3 export_debug_data.py --output-dir ~/mon_debug --live
"""

import sys
import argparse
import json
import time
import cv2
import numpy as np
import yaml
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))


def create_debug_export(output_dir: str = None, live_capture: bool = False):
    """
    Cree export debug complet.
    
    Args:
        output_dir: Repertoire sortie (defaut: logs/debug_TIMESTAMP/)
        live_capture: Si True, tente capture live depuis camera
    """
    # Creer repertoire output
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path(__file__).parent.parent / 'logs' / ('debug_' + timestamp)
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("[EXPORT] ========== Debug Export ==========")
    print("[EXPORT] Output directory: {}".format(output_dir.absolute()))
    print("[EXPORT] Live capture: {}".format('ENABLED' if live_capture else 'DISABLED'))
    print()
    
    # Creer fichier manifest
    manifest = {
        'export_timestamp': datetime.now().isoformat(),
        'mode': 'live' if live_capture else 'standalone',
        'exported_items': []
    }
    
    # 1. Sauvegarder configuration
    config_success = _export_config(output_dir)
    if config_success:
        manifest['exported_items'].append('config')
    
    # 2. Sauvegarder frame camera + detections ArUco
    if live_capture:
        camera_success = _export_camera_frame(output_dir)
        if camera_success:
            manifest['exported_items'].append('camera_frame')
            manifest['exported_items'].append('aruco_detections')
    
    # 3. Sauvegarder grille occupation (exemple synthetique)
    grid_success = _export_occupancy_grid(output_dir, live_capture)
    if grid_success:
        manifest['exported_items'].append('occupancy_grid')
    
    # 4. Sauvegarder etat jeu (exemple synthetique)
    state_success = _export_game_state(output_dir, live_capture)
    if state_success:
        manifest['exported_items'].append('game_state')
    
    # 5. Copier logs recents
    logs_count = _export_logs(output_dir)
    if logs_count > 0:
        manifest['exported_items'].append('logs')
        manifest['logs_count'] = logs_count
    
    # 6. Sauvegarder manifest
    with open(output_dir / 'manifest.json', 'w') as f:
        json.dump(manifest, f, indent=2)
    
    print()
    print("[EXPORT] ========== Export Complete ==========")
    print("[EXPORT] Location: {}".format(output_dir.absolute()))
    print("[EXPORT] Items exported: {}".format(len(manifest['exported_items'])))
    print("[EXPORT] Manifest: manifest.json")


def _export_config(output_dir: Path) -> bool:
    """
    Export fichiers configuration.
    
    Returns:
        True si au moins un fichier exporte
    """
    print("[EXPORT] Exporting configuration...")
    
    config_dir = Path(__file__).parent.parent / 'config'
    
    if not config_dir.exists():
        print("[EXPORT]   [FAIL] config/ directory not found")
        return False
    
    config_export = output_dir / 'config'
    config_export.mkdir(exist_ok=True)
    
    exported = 0
    for config_file in config_dir.glob('*.yaml'):
        try:
            with open(config_file) as f:
                data = yaml.safe_load(f)
            
            out_file = config_export / config_file.name
            with open(out_file, 'w') as f:
                yaml.dump(data, f, default_flow_style=False, sort_keys=False)
            
            print("[EXPORT]   [OK] {}".format(config_file.name))
            exported += 1
        except Exception as e:
            print("[EXPORT]   [FAIL] {}: {}".format(config_file.name, e))
    
    return exported > 0


def _export_camera_frame(output_dir: Path) -> bool:
    """
    Export capture camera live + detections ArUco.
    
    Returns:
        True si capture reussie
    """
    print("[EXPORT] Capturing live camera frame...")
    
    try:
        from perception.camera.realsense_stream import RealSenseStream
        from perception.camera.aruco_detector import ArucoDetector
        
        # Initialiser camera
        print("[EXPORT]   Initializing RealSense camera...")
        camera = RealSenseStream(width=640, height=480, fps=30)
        camera.start()
        
        # Attendre stabilisation
        time.sleep(1.0)
        
        # Capturer frame
        color_frame, depth_frame = camera.get_frames()
        
        if color_frame is None:
            print("[EXPORT]   [FAIL] Failed to capture frame")
            camera.stop()
            return False
        
        # Sauvegarder frame couleur
        cv2.imwrite(str(output_dir / 'camera_frame.png'), color_frame)
        print("[EXPORT]   [OK] camera_frame.png ({}x{})".format(
            color_frame.shape[1], color_frame.shape[0]))
        
        # Sauvegarder depth si disponible
        if depth_frame is not None:
            np.save(str(output_dir / 'depth_frame.npy'), depth_frame)
            
            # Visualisation depth
            depth_colormap = cv2.applyColorMap(
                cv2.convertScaleAbs(depth_frame, alpha=0.03),
                cv2.COLORMAP_JET
            )
            cv2.imwrite(str(output_dir / 'depth_frame_viz.png'), depth_colormap)
            print("[EXPORT]   [OK] depth_frame.npy")
        
        # Detecter ArUco
        print("[EXPORT]   Detecting ArUco markers...")
        aruco = ArucoDetector()
        detections = aruco.detect(color_frame)
        
        # Dessiner detections sur frame
        frame_annotated = color_frame.copy()
        for marker_id, data in detections.items():
            center = data['center']
            corners = data['corners']
            
            # Dessiner contour
            cv2.polylines(frame_annotated, [corners.astype(int)], True, (0, 255, 0), 2)
            
            # Dessiner centre + ID
            cv2.circle(frame_annotated, tuple(center.astype(int)), 5, (0, 0, 255), -1)
            cv2.putText(
                frame_annotated,
                "ID:{}".format(marker_id),
                tuple((center + [10, -10]).astype(int)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 0),
                2
            )
        
        cv2.imwrite(str(output_dir / 'camera_frame_annotated.png'), frame_annotated)
        
        # Sauvegarder detections JSON
        detections_json = {}
        for marker_id, data in detections.items():
            detections_json[int(marker_id)] = {
                'center': data['center'].tolist(),
                'corners': data['corners'].tolist()
            }
        
        with open(output_dir / 'aruco_detections.json', 'w') as f:
            json.dump(detections_json, f, indent=2)
        
        print("[EXPORT]   [OK] ArUco detected: {} markers".format(len(detections)))
        print("[EXPORT]   [OK] camera_frame_annotated.png")
        print("[EXPORT]   [OK] aruco_detections.json")
        
        camera.stop()
        return True
        
    except ImportError as e:
        print("[EXPORT]   [FAIL] Import error: {}".format(e))
        print("[EXPORT]   -> Live capture requires RealSense dependencies")
        return False
    except Exception as e:
        print("[EXPORT]   [FAIL] Camera capture failed: {}".format(e))
        return False


def _export_occupancy_grid(output_dir: Path, live_capture: bool) -> bool:
    """
    Export grille occupation.
    
    Cree exemple synthetique si pas de systeme actif.
    
    Args:
        output_dir: Repertoire sortie
        live_capture: Si True, tente connexion a systeme actif
        
    Returns:
        True si export reussi
    """
    print("[EXPORT] Exporting occupancy grid...")
    
    # Parametres grille par defaut
    width_m = 2.85
    height_m = 1.90
    resolution_m = 0.02
    grid = None
    
    # Tenter connexion a WorldModel actif si en mode live
    if live_capture:
        try:
            from core.world.world_model import WorldModel
            
            # Charger config pour dimensions arena
            config_dir = Path(__file__).parent.parent / 'config'
            with open(config_dir / 'arena.yaml') as f:
                arena_cfg = yaml.safe_load(f)
            
            width_m = arena_cfg['arena']['width_m']
            height_m = arena_cfg['arena']['height_m']
            resolution_m = arena_cfg['grid']['resolution_m']
            
            # Creer WorldModel avec vraies dimensions
            world = WorldModel(width_m, height_m, resolution_m)
            grid = (world.grid.grid * 100).astype(np.uint8)
            
            print("[EXPORT]   Connected to WorldModel ({}x{}m @ {}m resolution)".format(
                width_m, height_m, resolution_m))
        except Exception as e:
            print("[EXPORT]   Could not connect to WorldModel: {}".format(e))
            print("[EXPORT]   Falling back to synthetic grid")
            grid = None
    
    nx = int(width_m / resolution_m)
    ny = int(height_m / resolution_m)
    
    # Creer grille synthetique si pas de WorldModel actif
    if grid is None:
        grid = np.zeros((ny, nx), dtype=np.uint8)
    
    # Ajouter quelques obstacles exemple
    # Obstacle central
    grid[40:60, 60:80] = 100
    
    # Murs bordure
    grid[0:5, :] = 100  # Bas
    grid[-5:, :] = 100  # Haut
    grid[:, 0:5] = 100  # Gauche
    grid[:, -5:] = 100  # Droite
    
    # Sauvegarder array NumPy
    np.save(str(output_dir / 'occupancy_grid.npy'), grid)
    print("[EXPORT]   [OK] occupancy_grid.npy ({}x{}, {}m/cell)".format(
        nx, ny, resolution_m))
    
    # Creer visualisation
    grid_viz = np.zeros((ny, nx, 3), dtype=np.uint8)
    grid_viz[grid == 0] = [240, 240, 240]    # Libre = gris clair
    grid_viz[grid == 100] = [50, 50, 50]     # Obstacle = gris fonce
    
    # Agrandir pour visualisation
    scale = 4
    grid_viz_large = cv2.resize(
        grid_viz,
        (nx * scale, ny * scale),
        interpolation=cv2.INTER_NEAREST
    )
    
    cv2.imwrite(str(output_dir / 'occupancy_grid.png'), grid_viz_large)
    print("[EXPORT]   [OK] occupancy_grid.png (visualization)")
    
    # Sauvegarder metadonnees
    grid_meta = {
        'width_m': width_m,
        'height_m': height_m,
        'resolution_m': resolution_m,
        'grid_size': [nx, ny],
        'note': 'Synthetic example grid' if not live_capture else 'Live captured grid'
    }
    
    with open(output_dir / 'occupancy_grid_meta.json', 'w') as f:
        json.dump(grid_meta, f, indent=2)
    
    print("[EXPORT]   [OK] occupancy_grid_meta.json")
    
    return True


def _export_game_state(output_dir: Path, live_capture: bool) -> bool:
    """
    Export etat jeu.
    
    Cree exemple synthetique si pas de jeu actif.
    
    Args:
        output_dir: Repertoire sortie
        live_capture: Si True, tente connexion a jeu actif
        
    Returns:
        True si export reussi
    """
    print("[EXPORT] Exporting game state...")
    
    state_dict = None
    
    # Tenter connexion a GameEngine actif si en mode live
    if live_capture:
        try:
            from core.game.game_engine import GameEngine
            from core.game.state import GameStatus
            
            # Charger config jeu
            config_dir = Path(__file__).parent.parent / 'config'
            with open(config_dir / 'game.yaml') as f:
                game_cfg = yaml.safe_load(f)
            
            # Creer GameEngine pour avoir acces aux regles
            engine = GameEngine(game_cfg)
            
            # Exporter etat actuel (note: sans WorldModel actif, c'est un etat initial)
            state_dict = {
                'timestamp': datetime.now().isoformat(),
                'mode': 'live',
                'engine_status': engine.state.value if engine.state else 'unknown',
                'rules': {
                    'match_duration_s': engine.rules.match_duration_seconds,
                    'max_hits_to_win': engine.rules.max_hits_to_win,
                    'ai_cooldown_s': engine.rules.ai_shot_cooldown,
                    'human_cooldown_s': engine.rules.human_shot_cooldown
                },
                'note': 'GameEngine connected - rules exported'
            }
            
            print("[EXPORT]   Connected to GameEngine (status: {})".format(engine.state.value))
        except Exception as e:
            print("[EXPORT]   Could not connect to GameEngine: {}".format(e))
            print("[EXPORT]   Falling back to synthetic state")
            state_dict = None
    
    # Creer etat synthetique si pas de GameEngine actif
    if state_dict is None:
        state_dict = {
            'timestamp': datetime.now().isoformat(),
            'mode': 'live' if live_capture else 'synthetic_example',
            'match': {
                'duration_s': 180,
                'elapsed_s': 67.3,
                'time_remaining_s': 112.7,
                'status': 'in_progress'
            },
            'robots': {
                'robot_4': {
                    'name': 'AI Robot',
                    'pose': {
                        'x_m': 1.23,
                        'y_m': 0.87,
                        'theta_rad': 1.57
                    },
                    'velocity': {
                        'vx_m_s': 0.03,
                        'vy_m_s': -0.01,
                        'omega_rad_s': 0.02
                    },
                    'hits_received': 2,
                    'hits_inflicted': 3,
                    'last_shot_time': 61.2
                },
                'robot_5': {
                    'name': 'Human Robot',
                    'pose': {
                        'x_m': 1.85,
                        'y_m': 1.42,
                        'theta_rad': -0.52
                    },
                    'velocity': {
                        'vx_m_s': -0.08,
                        'vy_m_s': 0.05,
                        'omega_rad_s': -0.10
                    },
                    'hits_received': 3,
                    'hits_inflicted': 2,
                    'last_shot_time': 58.7
                }
            },
            'ai_state': {
                'current_behavior': 'ATTACK',
                'target_position': [1.85, 1.42],
                'path_waypoints_count': 12,
                'has_line_of_sight': True,
                'fire_request': True,
                'safe_distance_m': 0.8
            },
            'cooldowns': {
                'human_next_shot': 72.7,
                'ai_next_shot': 64.2
            }
        }
    
    with open(output_dir / 'game_state.json', 'w') as f:
        json.dump(state_dict, f, indent=2)
    
    print("[EXPORT]   [OK] game_state.json")
    
    # Afficher details selon le mode
    if 'match' in state_dict:
        print("[EXPORT]     - Time: {:.1f}s / {}s".format(
            state_dict['match']['elapsed_s'], state_dict['match']['duration_s']))
        print("[EXPORT]     - AI state: {}".format(state_dict['ai_state']['current_behavior']))
        print("[EXPORT]     - Hits: R4={}, R5={}".format(
            state_dict['robots']['robot_4']['hits_received'],
            state_dict['robots']['robot_5']['hits_received']))
    else:
        print("[EXPORT]     - Rules exported from GameEngine")
    
    return True


def _export_logs(output_dir: Path) -> int:
    """
    Copie logs recents.
    
    Returns:
        Nombre de fichiers copies
    """
    print("[EXPORT] Copying logs...")
    
    logs_dir = Path(__file__).parent.parent / 'logs'
    
    if not logs_dir.exists():
        logs_dir.mkdir(exist_ok=True)
        print("[EXPORT]   [FAIL] No logs found (logs/ directory created)")
        return 0
    
    # Copier fichiers .log
    copied = 0
    for log_file in logs_dir.glob('*.log'):
        try:
            out_file = output_dir / log_file.name
            with open(log_file) as f:
                content = f.read()
            with open(out_file, 'w') as f:
                f.write(content)
            
            # Compter lignes
            lines = len(content.splitlines())
            size_kb = len(content) / 1024
            
            print("[EXPORT]   [OK] {} ({} lines, {:.1f}KB)".format(
                log_file.name, lines, size_kb))
            copied += 1
        except Exception as e:
            print("[EXPORT]   [FAIL] {}: {}".format(log_file.name, e))
    
    if copied == 0:
        print("[EXPORT]   [FAIL] No .log files found")
    
    return copied


def main():
    """Point d'entree script."""
    parser = argparse.ArgumentParser(
        description='Export donnees debug pour analyse offline',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                        Export config + logs
  %(prog)s --live                 Capture live depuis camera
  %(prog)s --output-dir ~/debug   Export vers repertoire specifique
        """
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='Repertoire sortie (defaut: logs/debug_TIMESTAMP/)'
    )
    parser.add_argument(
        '--live',
        action='store_true',
        help='Activer capture live depuis camera'
    )
    
    args = parser.parse_args()
    
    create_debug_export(args.output_dir, args.live)


if __name__ == '__main__':
    main()


################################################################################
PATH: ./tank_project/scripts/install_deps.sh
################################################################################
#!/bin/bash
# Script pour installer les dépendances dans l'environnement pyenv ubuntu

echo "Installation des dépendances Python pour tank_project..."
echo "Environnement: pyenv ubuntu"
echo ""

# S'assurer d'être dans le bon répertoire
cd /home/julien/ros2_ws/src/VA50/tank_project

# Installer les dépendances
pip3 install -r requirements.txt

echo ""
echo "Installation terminée!"
echo "Vous pouvez maintenant lancer la calibration avec:"
echo "  python -m tank_project.main calibration"


################################################################################
PATH: ./tank_project/scripts/run_calibration.py
################################################################################
#!/usr/bin/env python3
"""
Calibration Wizard Runner

Interactive calibration process to set up the arena:
1. Safe zone definition
2. Geometric calibration (projected corners)
3. Metric calibration (physical marker)
4. Obstacle mapping

Saves results to config/arena.yaml

Usage:
    python3 run_calibration.py
    
Prerequisites:
    - RealSense camera connected
    - Projector showing Pygame window with projected ArUco corners
"""

import sys
import yaml
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from perception.camera.realsense_stream import RealSenseStream
from perception.calibration.calibration_wizard import CalibrationWizard


def main():
    print("[CALIB_RUNNER] ========== Calibration Wizard ==========")
    
    # Load configuration
    print("[CALIB_RUNNER] Loading configuration...")
    config_dir = Path(__file__).parent.parent / 'config'
    
    with open(config_dir / 'camera.yaml') as f:
        camera_config = yaml.safe_load(f)
    
    with open(config_dir / 'projector.yaml') as f:
        projector_config = yaml.safe_load(f)
    
    # Initialize camera with config
    print("[CALIB_RUNNER] Initializing camera...")
    camera = RealSenseStream(
        width=camera_config['realsense']['width'],
        height=camera_config['realsense']['height'],
        fps=camera_config['realsense']['fps']
    )
    camera.start()
    
    # Run wizard with projector config
    proj = projector_config['projector']
    disp = projector_config['display']
    calib = projector_config['calibration']
    
    wizard = CalibrationWizard(
        camera, 
        projector_width=proj['width'],
        projector_height=proj['height'],
        margin_px=proj['margin_px'],
        monitor_offset_x=disp['monitor_offset_x'],
        monitor_offset_y=disp['monitor_offset_y'],
        borderless=disp['borderless'],
        hide_cursor=disp['hide_cursor'],
        marker_size_m=calib['marker_size_m']
    )
    
    try:
        print("[CALIB_RUNNER] Running calibration wizard...")
        results = wizard.run()
        print("[CALIB_RUNNER] Calibration wizard completed!")
        
        # Save to config
        config_path = Path(__file__).parent.parent / 'config' / 'arena.yaml'
        
        print("[CALIB_RUNNER] Saving calibration to {}".format(config_path))
        
        # Convert numpy types to Python native types for clean YAML
        import numpy as np
        
        def numpy_to_python(obj):
            """Recursively convert numpy types to Python native types."""
            if isinstance(obj, dict):
                return {k: numpy_to_python(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [numpy_to_python(item) for item in obj]
            elif isinstance(obj, np.ndarray):
                return numpy_to_python(obj.tolist())
            elif isinstance(obj, (np.floating, np.float64, np.float32)):
                return float(obj)
            elif isinstance(obj, (np.integer, np.int64, np.int32)):
                return int(obj)
            else:
                return obj
        
        clean_results = numpy_to_python(results)
        
        with open(config_path, 'w') as f:
            yaml.dump(clean_results, f, default_flow_style=False)
        
        print("[CALIB_RUNNER] Calibration saved successfully!")
        print("[CALIB_RUNNER] You can now run the game with: python3 run_game.py")
        
    except Exception as e:
        print("[CALIB_RUNNER] ERROR: {}".format(e))
        
    finally:
        camera.stop()
        print("[CALIB_RUNNER] Done")


if __name__ == '__main__':
    main()


################################################################################
PATH: ./tank_project/scripts/run_game.py
################################################################################
#!/usr/bin/env python3
"""
Boucle de Jeu Principale

Exécute le jeu de l'arène de tanks à 30 FPS :
1. Vision et suivi (détection ArUco, filtrage Kalman)
2. Mise à jour du monde (grille d'occupation, poses des robots)
3. Moteur de jeu (tirs, impacts, chronomètres)
4. Décision IA (arbre de comportement, planification de chemin)
5. Contrôle (suivi de trajectoire, commandes ROS)
6. Visualisation (rendu Pygame)

Utilisation :
    python3 run_game.py
    
Prérequis :
    - Calibration terminée (config/arena.yaml existe)
    - Pont ROS en cours d'exécution
    - Caméra RealSense connectée
    - Projecteur configuré
"""

import sys
import time
import yaml
import pygame
import numpy as np
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from perception.camera.realsense_stream import RealSenseStream
from perception.camera.aruco_detector import ArucoDetector
from perception.camera.kalman_filter import KalmanFilter
from perception.camera.homography import apply_homography_single
from core.world.world_model import WorldModel
from core.world.coordinate_frames import TransformManager
from core.game.game_engine import GameEngine
from core.ia.strategy import AIStrategy
from core.control.trajectory_follower import TrajectoryFollower
from core.control.ros_bridge_client import ROSBridgeClient
from visualization.pygame_renderer import PygameRenderer


def load_config():
    """Charge tous les fichiers de configuration."""
    config_dir = Path(__file__).parent.parent / 'config'
    
    configs = {}
    for config_file in ['arena', 'camera', 'game', 'ia', 'robot', 'projector']:
        if (config_dir / '{}.yaml'.format(config_file)).exists():
            with open(config_dir / '{}.yaml'.format(config_file)) as f:
                configs[config_file] = yaml.safe_load(f)
    
    return configs


def setup_transform_manager(configs):
    """
    Configure la transformation de coordonnées à partir des données de calibration.
    
    Returns:
        TransformManager avec H_C2W défini, ou None si non calibré
    """
    transform_mgr = TransformManager()
    
    # Charge H_C2W depuis la calibration si disponible
    transform_data = configs['arena'].get('transform', {})
    scale = transform_data.get('scale_m_per_av', 1.0)
    h_c2w = transform_data.get('H_C2W')
    
    if h_c2w is not None:
        transform_mgr.H_C2W = np.array(h_c2w)
        print("[MAIN] H_C2W chargé depuis la calibration")
    else:
        # Repli : utilise une échelle simple (suppose caméra alignée avec l'arène)
        transform_mgr.set_av_to_world_scale(scale)
        print("[MAIN] ATTENTION : Pas de H_C2W trouvé, utilisation de l'échelle de repli")
    
    return transform_mgr


def camera_to_world(detection_center, transform_mgr, fallback_scale=1.0):
    """
    Transforme une détection ArUco des pixels caméra vers mètres monde.
    
    Args:
        detection_center: (u, v) coordonnées pixel
        transform_mgr: Instance TransformManager
        fallback_scale: Échelle à utiliser si pas d'homographie
        
    Returns:
        (x, y) en mètres
    """
    u, v = detection_center
    
    if transform_mgr.H_C2W is not None:
        return transform_mgr.camera_to_world(u, v)
    else:
        # Repli : échelle simple depuis le centre
        x = u * fallback_scale / 1000.0
        y = v * fallback_scale / 1000.0
        return (x, y)


def get_robot_pose_in_world(detection_data, transform_mgr, fallback_scale=1.0):
    """
    Calcule (x, y, theta) complet dans le référentiel Monde.
    
    CRITIQUE: L'orientation pixel doit être transformée via homographie
    sinon le robot croira avancer vers l'Est alors qu'il va vers le Nord.
    
    Args:
        detection_data: Dict avec 'center' et 'orientation' (pixels)
        transform_mgr: TransformManager instance
        fallback_scale: Fallback si pas d'homographie
        
    Returns:
        (x, y, theta) en mètres et radians (référentiel monde)
    """
    # 1. Centre du robot (Pixels)
    u, v = detection_data['center']
    
    # 2. Point "Devant" le robot (Pixels) - utilise l'orientation pixel
    theta_pix = detection_data['orientation']
    dist_px = 20  # 20 pixels devant
    u_front = u + dist_px * np.cos(theta_pix)
    v_front = v + dist_px * np.sin(theta_pix)
    
    # 3. Projection dans le monde (Mètres)
    x, y = camera_to_world((u, v), transform_mgr, fallback_scale)
    x_front, y_front = camera_to_world((u_front, v_front), transform_mgr, fallback_scale)
    
    # 4. Calcul du vrai angle Monde
    theta_world = np.arctan2(y_front - y, x_front - x)
    
    return x, y, theta_world


def main():
    print("[MAIN] ========== Jeu d'Arène de Tanks ==========")
    
    # Charge la configuration
    print("[MAIN] Chargement de la configuration...")
    configs = load_config()
    
    # Configure les transformations de coordonnées
    transform_mgr = setup_transform_manager(configs)
    
    # Initialise les sous-systèmes
    print("[MAIN] Initialisation des sous-systèmes...")
    
    # 1. Vision
    camera = RealSenseStream(
        width=configs['camera']['realsense']['width'],
        height=configs['camera']['realsense']['height'],
        fps=configs['camera']['realsense']['fps']
    )
    camera.start()
    
    aruco = ArucoDetector()
    kalman_ai = KalmanFilter()
    kalman_human = KalmanFilter()
    
    # 2. Monde - avec config robot
    robot_config = configs['arena'].get('robot', {})
    world = WorldModel(
        arena_width_m=configs['arena']['arena']['width_m'],
        arena_height_m=configs['arena']['arena']['height_m'],
        grid_resolution_m=configs['arena']['grid']['resolution_m'],
        robot_radius_m=robot_config.get('radius_m', 0.09),
        inflation_margin_m=robot_config.get('inflation_margin_m', 0.05)
    )
    
    # CRITIQUE: Générer la costmap AVANT de donner la grille à l'IA
    # Sinon le robot frôlera les murs
    world.generate_costmap()
    
    # 3. Game
    game_engine = GameEngine(configs['game'])
    
    # 4. IA (utilise maintenant la costmap gonflée)
    ai_strategy = AIStrategy(configs['ia'])
    ai_strategy.set_planner(world.grid)
    
    # 5. Contrôle - récupère les limites de vitesse depuis le bon chemin de config
    velocity_limits = configs['robot'].get('velocity_limits', {})
    max_linear_vel = velocity_limits.get('max_linear_mps', 0.22)
    max_angular_vel = velocity_limits.get('max_angular_radps', 2.84)
    
    controller = TrajectoryFollower(configs['robot'].get('control', {}))
    ros_bridge = ROSBridgeClient(
        host=configs['robot']['ros_bridge']['host'],
        port=configs['robot']['ros_bridge']['port']
    )
    ros_bridge.connect()
    
    # 6. Visualization
    # Prioritise projector.yaml if available, else fallback to arena.yaml
    if 'projector' in configs and 'projector' in configs['projector']:
        proj_conf = configs['projector']['projector']
        disp_conf = configs['projector'].get('display', {})
    else:
        proj_conf = configs['arena']['projector']
        disp_conf = configs['arena'].get('display', {})

    renderer = PygameRenderer(
        width=proj_conf['width'],
        height=proj_conf['height'],
        margin=proj_conf.get('margin_px', 50),
        fullscreen=disp_conf.get('fullscreen', False),
        display_index=disp_conf.get('display_index', 0)
    )
    renderer.set_arena_dimensions(
        configs['arena']['arena']['width_m'],
        configs['arena']['arena']['height_m']
    )
    
    print("[MAIN] Tous les sous-systèmes initialisés")
    print("[MAIN] Démarrage de la boucle de jeu à 30 FPS...")
    
    # Initialise les Entrées (Joystick/Clavier)
    joystick = None
    if pygame.joystick.get_count() > 0:
        joystick = pygame.joystick.Joystick(0)
        joystick.init()
        print("[MAIN] Joystick détecté : {}".format(joystick.get_name()))
    
    # Boucle de jeu
    dt = 1.0 / configs['game']['match']['tick_rate_fps']
    running = True
    
    # Échelle de repli depuis la config
    fallback_scale = configs['arena'].get('transform', {}).get('scale_m_per_av', 1.0)
    
    # État initial du jeu - utilisé pour vérifier si on joue avant l'appel à game_engine.tick()
    game_state = {'status': 'ready'}
    tick_counter = 0
    
    print("[LOG] === BOUCLE DE JEU DÉMARRÉE ===")
    print(f"[LOG] État initial game_state : {game_state}")
    print(f"[LOG] État Renderer : {renderer.match_state}")
    
    try:
        while running:
            tick_start = time.time()
            tick_counter += 1
            
            # --- GESTION DES ENTRÉES ---
            human_input = {
                'v': 0.0,
                'omega': 0.0,
                'fire_request': False,
                'start_game': False
            }
            
            # Traite les événements Pygame
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                    print("[LOG] Événement QUIT reçu")
                elif event.type == pygame.VIDEORESIZE:
                    # Gère le redimensionnement de la fenêtre
                    renderer.handle_resize(event.w, event.h)
                elif event.type == pygame.KEYDOWN:
                    print(f"[LOG] KEYDOWN : {pygame.key.name(event.key)}")
                    if event.key == pygame.K_ESCAPE:
                        if renderer.fullscreen:
                            renderer.toggle_fullscreen()
                        else:
                            running = False
                    elif event.key == pygame.K_F11:
                        renderer.toggle_fullscreen()
                    elif event.key == pygame.K_SPACE:
                        human_input['fire_request'] = True
                        if renderer.match_state == renderer.STATE_WAITING:
                            human_input['start_game'] = True
                            print("[LOG] ESPACE pressé -> start_game = True")
                    elif event.key == pygame.K_RETURN:
                        human_input['start_game'] = True
                        print("[LOG] ENTRÉE pressé -> start_game = True")
                    elif event.key == pygame.K_d:
                        renderer.show_debug_path = not renderer.show_debug_path
                        print(f"[LOG] Chemin de débogue : {'ON' if renderer.show_debug_path else 'OFF'}")
            
            # Synchronise l'état du renderer avec le démarrage du jeu
            if human_input['start_game']:
                print(f"[LOG] start_game=True, renderer.match_state={renderer.match_state}")
                if renderer.match_state == renderer.STATE_WAITING:
                    renderer.start_match(countdown_seconds=3.0)
                    print("[LOG] >>> COMPTE À REBOURS DU MATCH DÉMARRÉ <<<")
                         
            # Joystick Input (PS4/Xbox)
            if joystick:
                v = -joystick.get_axis(1) * max_linear_vel
                omega = -joystick.get_axis(3) * max_angular_vel
                
                if abs(v) > 0.05:
                    human_input['v'] = v
                if abs(omega) > 0.05:
                    human_input['omega'] = omega
                
                if joystick.get_button(5) or joystick.get_button(0):
                    human_input['fire_request'] = True
                if joystick.get_button(9):
                    human_input['start_game'] = True

            # Repli Clavier pour mouvement (Flèches directionnelles)
            keys = pygame.key.get_pressed()
            if keys[pygame.K_UP]:
                human_input['v'] = max_linear_vel
            if keys[pygame.K_DOWN]:
                human_input['v'] = -max_linear_vel
            if keys[pygame.K_LEFT]:
                human_input['omega'] = max_angular_vel
            if keys[pygame.K_RIGHT]:
                human_input['omega'] = -max_angular_vel

            
            # 1. Vision
            color_frame, _ = camera.get_frames()
            if color_frame is None:
                continue
                
            detections = aruco.detect(color_frame)
            
            # 2. Update robot poses with proper coordinate transform (ANGLE CORRIGÉ)
            if 4 in detections:  # AI robot
                x, y, theta = get_robot_pose_in_world(detections[4], transform_mgr, fallback_scale)
                
                # FIX: Initialiser Kalman à la première détection (évite téléportation depuis 0,0)
                if np.all(kalman_ai.state == 0):
                    kalman_ai.state = np.array([x, y, 0, 0, theta, 0], dtype=float)
                
                kalman_ai.predict()
                kalman_ai.update((x, y, theta))
                filtered_pose = kalman_ai.get_pose()
                world.update_robot_pose(4, filtered_pose)
                 
            if 5 in detections:  # Human robot
                x, y, theta = get_robot_pose_in_world(detections[5], transform_mgr, fallback_scale)
                
                # FIX: Initialiser Kalman à la première détection (évite téléportation depuis 0,0)
                if np.all(kalman_human.state == 0):
                    kalman_human.state = np.array([x, y, 0, 0, theta, 0], dtype=float)
                
                kalman_human.predict()
                kalman_human.update((x, y, theta))
                filtered_pose = kalman_human.get_pose()
                world.update_robot_pose(5, filtered_pose)
            
            # 3. Mise à jour occupation monde
            world.update_occupancy()
            
            # 4. Tick Jeu EN PREMIER - pour avoir l'état actuel du jeu
            ai_decision = {'state': 'IDLE', 'fire_request': False, 'has_los': False, 'target_position': None}
            game_state = game_engine.tick(world, ai_decision, human_input)
            
            # Log state changes
            if tick_counter % 30 == 0:  # Every second
                print(f"[LOG] Tick {tick_counter}: game_state.status={game_state.get('status')}, renderer={renderer.match_state}")
                print(f"[LOG]   Robot4: {world.get_robot_pose(4)}, Robot5: {world.get_robot_pose(5)}")
            
            # 5. Décision IA (seulement si le jeu est en cours)
            if game_state.get('status', 'ready') == 'playing':
                if tick_counter % 30 == 0:
                    print("[LOG] >>> JEU EN COURS - L'IA DÉCIDE <<<")
                
                # Construit le contexte IA
                ai_context = world.get_state_dict()
                ai_context['ai_pose'] = world.get_robot_pose(4)
                ai_context['human_pose'] = world.get_robot_pose(5)
                ai_context['raycast_sys'] = game_engine.raycast
                ai_context['game_time'] = time.time()
                
                ai_decision = ai_strategy.decide(ai_context)
                
                if tick_counter % 30 == 0:
                    print(f"[LOG]   Décision IA : state={ai_decision.get('state')}, target={ai_decision.get('target_position')}")
                    print(f"[LOG]   Longueur chemin IA : {len(ai_strategy.current_path)}")
            
            # 6. Contrôle (seulement si le jeu est en cours)
            if game_state.get('status', 'ready') == 'playing':
                
                # --- CAS 1 : DÉPLACEMENT (On a un chemin) ---
                if ai_decision.get('target_position'):
                    path = ai_strategy.current_path
                    if path:
                        v_ai, omega_ai = controller.compute_control(world.get_robot_pose(4), path)
                        ros_bridge.send_velocity_command(4, v_ai, omega_ai)
                        renderer.set_ai_path(path)
                        
                        if tick_counter % 30 == 0:
                            print(f"[LOG]   Envoi cmd : v={v_ai:.3f}, omega={omega_ai:.3f}")
                    else:
                        ros_bridge.send_velocity_command(4, 0, 0)
                        if tick_counter % 30 == 0:
                            print("[LOG]   Pas de chemin - envoi STOP")

                # --- CAS 2 : TIR (Mode Tourelle / Aiming) ---
                elif ai_decision.get('fire_request'):
                    # Le robot s'arrête (v=0) mais TOURNE pour s'aligner
                    
                    # 1. Où est l'ennemi ?
                    # target_orientation contient la position (x,y) de l'ennemi quand on veut tirer
                    enemy_pos = ai_decision.get('target_orientation') # (x, y) de l'ennemi
                    
                    if enemy_pos:
                        # 2. Calcul de l'angle vers l'ennemi
                        ai_pose = world.get_robot_pose(4) # (x, y, theta)
                        dx = enemy_pos[0] - ai_pose[0]
                        dy = enemy_pos[1] - ai_pose[1]
                        desired_theta = np.arctan2(dy, dx)
                        
                        # 3. Calcul de l'erreur d'angle (Normalisée entre -PI et PI)
                        error_theta = desired_theta - ai_pose[2]
                        while error_theta > np.pi: error_theta -= 2 * np.pi
                        while error_theta < -np.pi: error_theta += 2 * np.pi
                        
                        # 4. Commande Proportionnelle (P-Controller)
                        # Kp = 2.0 (Gain : plus c'est haut, plus il tourne vite)
                        # On clipe pour ne pas dépasser la vitesse max
                        omega_cmd = np.clip(2.0 * error_theta, -max_angular_vel, max_angular_vel)
                        
                        # Zone morte : Si on est aligné à 5° près, on arrête de bouger pour être stable
                        if abs(error_theta) < 0.08: # ~5 degrés
                            omega_cmd = 0.0
                            
                        ros_bridge.send_velocity_command(4, 0.0, omega_cmd)
                        
                        if tick_counter % 30 == 0:
                            print(f"[CTRL] VISÉE : Err={error_theta:.2f} rad -> Cmd={omega_cmd:.2f}")
                    else:
                        ros_bridge.send_velocity_command(4, 0, 0)

                # --- CAS 3 : ATTENTE ---
                else:
                    ros_bridge.send_velocity_command(4, 0, 0)
                    if tick_counter % 30 == 0:
                        print("[LOG]   Pas de cible - envoi STOP")
                     
                # Human Control (for RC mode)
                if human_input['v'] != 0 or human_input['omega'] != 0:
                    ros_bridge.send_velocity_command(5, human_input['v'], human_input['omega'])
            else:
                # Pas en jeu - s'assure que les robots sont stoppés
                ros_bridge.send_velocity_command(4, 0, 0)
                ros_bridge.send_velocity_command(5, 0, 0)

            
            # 7. Rendu
            renderer.render_frame(world.get_state_dict(), game_state)
            
            # Maintien du taux de rafraîchissement
            elapsed = time.time() - tick_start
            if elapsed < dt:
                time.sleep(dt - elapsed)
                
    except KeyboardInterrupt:
        print("\n[MAIN] Arrêt en cours...")
        
    finally:
        # Nettoyage
        camera.stop()
        ros_bridge.disconnect()
        renderer.cleanup()
        print("[MAIN] Au revoir !")


if __name__ == '__main__':
    main()


################################################################################
PATH: ./tank_project/scripts/show_grid.py
################################################################################
#!/usr/bin/env python3
"""
Check Homography & Grid - Outil de Validation Visuelle

Cet outil permet de vérifier la correspondance entre le Monde Réel et le Monde Virtuel.
A lancer APRES la calibration et AVANT le jeu.

Commandes :
    [D]   : Basculer l'affichage de l'Inflation (Costmap / Grille brute)
    [ESC] : Quitter
"""

import sys
import yaml
import pygame
import numpy as np
from pathlib import Path

# Ajout du chemin racine pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from perception.camera.realsense_stream import RealSenseStream
from perception.camera.aruco_detector import ArucoDetector
from core.world.world_model import WorldModel
from core.world.coordinate_frames import TransformManager

# Couleurs
C_BG = (10, 10, 15)
C_GRID = (40, 40, 50)
C_OBSTACLE = (200, 50, 50)       # Rouge (Mur physique)
C_INFLATION = (200, 100, 0)      # Orange (Zone de danger)
C_MARKER = (0, 255, 255)         # Cyan (Position calculée du marqueur)
C_THEORY = (0, 255, 0)           # Vert (Coins théoriques)
C_TEXT = (255, 255, 255)

def main():
    print("[CHECK] Démarrage validation Homographie...")

    # 1. Configs
    config_dir = Path(__file__).parent.parent / 'config'
    try:
        with open(config_dir / 'arena.yaml') as f: arena_cfg = yaml.safe_load(f)
        with open(config_dir / 'camera.yaml') as f: camera_cfg = yaml.safe_load(f)
        with open(config_dir / 'robot.yaml') as f: robot_cfg = yaml.safe_load(f)
    except FileNotFoundError:
        print("[CHECK] ERREUR: Config manquante. Lancez la calibration d'abord.")
        return

    # 2. Vision
    cam_cfg = camera_cfg.get('realsense', {})
    camera = RealSenseStream(width=848, height=480, fps=60) 
    camera.start()
    aruco = ArucoDetector()
    
    transform_mgr = TransformManager()
    if 'transform' in arena_cfg and 'H_C2W' in arena_cfg['transform']:
        transform_mgr.H_C2W = np.array(arena_cfg['transform']['H_C2W'])
    else:
        print("[CHECK] ERREUR: Pas de matrice H_C2W dans arena.yaml")
        camera.stop()
        return

    # 3. World (pour l'inflation)
    # On récupère le rayon du robot depuis robot.yaml (plus fiable que arena.yaml qui est écrasé)
    robot_radius = robot_cfg.get('physical', {}).get('robot_radius_m', 0.09)
    inflation_margin = 0.05 # Marge par défaut
    
    world = WorldModel(
        arena_width_m=arena_cfg['arena']['width_m'],
        arena_height_m=arena_cfg['arena']['height_m'],
        grid_resolution_m=arena_cfg['grid']['resolution_m'],
        robot_radius_m=robot_radius,
        inflation_margin_m=inflation_margin
    )
    world.generate_costmap()

    # 4. Pygame
    pygame.init()
    info = pygame.display.Info()
    win_h = int(info.current_h * 0.8)
    aspect_ratio = world.arena_width / world.arena_height
    win_w = int(win_h * aspect_ratio)
    screen = pygame.display.set_mode((win_w, win_h))
    pygame.display.set_caption("Calibration Check - [D] Toggle Inflation")
    font = pygame.font.SysFont("Consolas", 18)

    scale_px = win_w / world.arena_width

    def to_screen(x_m, y_m):
        sx = int(x_m * scale_px)
        sy = int(win_h - (y_m * scale_px)) # Flip Y
        return sx, sy

    # Boucle
    running = True
    show_inflation = False

    try:
        while running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT: running = False
                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE: running = False
                    elif event.key == pygame.K_d: show_inflation = not show_inflation

            # Vision
            color_frame, _ = camera.get_frames()
            detections = aruco.detect(color_frame) if color_frame is not None else {}

            # Rendu Fond
            screen.fill(C_BG)
            
            # Grille 10cm
            for x in np.arange(0, world.arena_width, 0.1):
                p1 = to_screen(x, 0); p2 = to_screen(x, world.arena_height)
                pygame.draw.line(screen, C_GRID, p1, p2, 1)
            for y in np.arange(0, world.arena_height, 0.1):
                p1 = to_screen(0, y); p2 = to_screen(world.arena_width, y)
                pygame.draw.line(screen, C_GRID, p1, p2, 1)

            # Obstacles
            grid_data = world.grid.costmap if (show_inflation and hasattr(world.grid, 'costmap')) else world.grid.grid
            rows, cols = grid_data.shape
            cell_w_px = world.grid.resolution * scale_px
            
            # Optimisation: affichage sparse
            occupied_indices = np.argwhere(grid_data > 0.5)
            for r, c in occupied_indices:
                xm, ym = world.grid.grid_to_world(r, c)
                sx, sy = to_screen(xm, ym)
                rect = pygame.Rect(sx - cell_w_px/2, sy - cell_w_px/2, cell_w_px+1, cell_w_px+1)
                pygame.draw.rect(screen, C_INFLATION if show_inflation else C_OBSTACLE, rect)

            # Coins Théoriques (Vert)
            corners = [(0,0), (world.arena_width,0), (world.arena_width, world.arena_height), (0, world.arena_height)]
            for cx, cy in corners:
                pygame.draw.circle(screen, C_THEORY, to_screen(cx, cy), 10, 2)

            # ArUco Live (Cyan)
            for mid, data in detections.items():
                u, v = data['center']
                xm, ym = transform_mgr.camera_to_world(u, v)
                sx, sy = to_screen(xm, ym)
                
                pygame.draw.circle(screen, C_MARKER, (sx, sy), 8, 0)
                pygame.draw.line(screen, (0,0,0), (sx-8, sy), (sx+8, sy), 1)
                pygame.draw.line(screen, (0,0,0), (sx, sy-8), (sx, sy+8), 1)
                
                lbl = font.render(f"ID {mid}", True, C_TEXT)
                screen.blit(lbl, (sx+12, sy-10))

            # UI
            mode_txt = "COSTMAP" if show_inflation else "RAW"
            ui = font.render(f"[D] View: {mode_txt}", True, (0, 255, 0))
            screen.blit(ui, (10, 10))

            pygame.display.flip()

    except KeyboardInterrupt: pass
    finally:
        camera.stop()
        pygame.quit()

if __name__ == '__main__':
    main()


################################################################################
PATH: ./tank_project/visualization/colors.py
################################################################################
"""
Colors - Palette Couleurs

Définit toutes les couleurs utilisées dans le projet.
"""

# Couleurs de base
WHITE = (255, 255, 255)
BLACK = (0, 0, 0)
RED = (255, 50, 50)
GREEN = (50, 255, 50)
BLUE = (50, 150, 255)
YELLOW = (255, 255, 50)
ORANGE = (255, 165, 0)
PURPLE = (160, 32, 240)
CYAN = (0, 255, 255)
MAGENTA = (255, 0, 255)

# Nuances de gris
GRAY_LIGHT = (200, 200, 200)
GRAY = (150, 150, 150)
GRAY_DARK = (100, 100, 100)

# Couleurs robots
ROBOT_AI_COLOR = BLUE
ROBOT_HUMAN_COLOR = RED

# Couleurs interface
HUD_TEXT_COLOR = BLACK
HUD_BG_COLOR = (255, 255, 255, 180)  # Semi-transparent
TIMER_COLOR = BLACK
SCORE_AI_COLOR = BLUE
SCORE_HUMAN_COLOR = RED

# Couleurs visualisation
ARENA_BORDER_COLOR = BLACK
ARENA_BG_COLOR = WHITE
OBSTACLE_COLOR = GRAY_DARK
GRID_LINE_COLOR = (220, 220, 220)

# Couleurs tir
SHOT_AI_COLOR = (100, 200, 255)
SHOT_HUMAN_COLOR = (255, 100, 100)
HIT_FLASH_COLOR = (255, 255, 0, 200)

# Couleurs lock-on
LOCKON_COLOR = RED
LOCKON_PULSE_COLOR = (255, 100, 100)

# Couleurs debug
PATH_COLOR = (0, 255, 0, 100)
WAYPOINT_COLOR = GREEN
LOS_LINE_COLOR = YELLOW


################################################################################
PATH: ./tank_project/visualization/debug_draw.py
################################################################################
"""
Debug Draw - Visualisation Debug

Affiche éléments de debug (paths, LOS, grille, etc.).

Logs: [DEBUG_DRAW] prefix
"""

import pygame
import numpy as np
from typing import List, Tuple, Optional
from .colors import *


class DebugDraw:
    """
    Gère affichage éléments debug.
    """
    
    def __init__(self, surface: pygame.Surface, projector_mapping):
        """
        Initialize debug drawer.
        
        Args:
            surface: Surface Pygame
            projector_mapping: ProjectorMapping instance
        """
        self.surface = surface
        self.mapping = projector_mapping
        self.font = pygame.font.SysFont('Courier', 16)
        
    def draw_path(self, waypoints: List[Tuple[float, float]], 
                 color: Tuple = PATH_COLOR):
        """
        Dessine chemin planifié.
        
        Args:
            waypoints: Liste (x, y) en mètres
            color: Couleur ligne
        """
        if len(waypoints) < 2:
            return
        
        # Convertir en pixels
        points_px = [self.mapping.world_to_projector(x, y) 
                    for x, y in waypoints]
        
        # Dessiner lignes
        pygame.draw.lines(self.surface, color, False, points_px, 3)
        
        # Dessiner waypoints
        for px in points_px:
            pygame.draw.circle(self.surface, WAYPOINT_COLOR, px, 5)
            
    def draw_line_of_sight(self,
                          start: Tuple[float, float],
                          end: Tuple[float, float],
                          blocked: bool = False):
        """
        Dessine ligne de vue.
        
        Args:
            start: Point départ (x, y) mètres
            end: Point arrivée (x, y) mètres
            blocked: True si bloquée
        """
        p1 = self.mapping.world_to_projector(*start)
        p2 = self.mapping.world_to_projector(*end)
        
        color = RED if blocked else LOS_LINE_COLOR
        pygame.draw.line(self.surface, color, p1, p2, 2)
        
    def draw_grid(self, grid_resolution: float = 0.5):
        """
        Dessine grille métrique.
        
        Args:
            grid_resolution: Espacement grille (mètres)
        """
        # Lignes verticales
        x = 0.0
        while x <= self.mapping.arena_width_m:
            p1 = self.mapping.world_to_projector(x, 0)
            p2 = self.mapping.world_to_projector(x, self.mapping.arena_height_m)
            pygame.draw.line(self.surface, GRID_LINE_COLOR, p1, p2, 1)
            x += grid_resolution
        
        # Lignes horizontales
        y = 0.0
        while y <= self.mapping.arena_height_m:
            p1 = self.mapping.world_to_projector(0, y)
            p2 = self.mapping.world_to_projector(self.mapping.arena_width_m, y)
            pygame.draw.line(self.surface, GRID_LINE_COLOR, p1, p2, 1)
            y += grid_resolution
            
    def draw_occupancy_grid(self, grid):
        """
        Dessine grille occupation.
        
        Args:
            grid: OccupancyGrid instance
        """
        # Simplification: dessiner cellules occupées
        for row in range(grid.n_rows):
            for col in range(grid.n_cols):
                if grid.grid[row, col] > 0.5:
                    # Convertir cell -> monde -> pixels
                    x_m, y_m = grid.grid_to_world(row, col)
                    px, py = self.mapping.world_to_projector(x_m, y_m)
                    
                    cell_size = self.mapping.scale_length(grid.resolution)
                    rect = pygame.Rect(px, py, cell_size, cell_size)
                    
                    alpha = int(grid.grid[row, col] * 150)
                    s = pygame.Surface((cell_size, cell_size))
                    s.set_alpha(alpha)
                    s.fill(OBSTACLE_COLOR)
                    self.surface.blit(s, rect)
                    
    def draw_robot_info(self, robot_id: int,
                       pose: Tuple[float, float, float],
                       velocity: Optional[Tuple[float, float, float]] = None):
        """
        Affiche infos robot au-dessus.
        
        Args:
            robot_id: ID robot
            pose: (x, y, theta)
            velocity: (vx, vy, omega) optionnel
        """
        x, y, theta = pose
        px, py = self.mapping.world_to_projector(x, y)
        
        # Texte infos
        info_lines = [f"R{robot_id}"]
        info_lines.append(f"({x:.2f}, {y:.2f})")
        
        if velocity:
            vx, vy, omega = velocity
            v_norm = np.sqrt(vx**2 + vy**2)
            info_lines.append(f"v={v_norm:.2f}m/s")
        
        # Dessiner texte
        y_offset = -40
        for line in info_lines:
            text = self.font.render(line, True, BLACK)
            text_rect = text.get_rect(center=(px, py + y_offset))
            
            # Fond
            bg = text_rect.inflate(10, 4)
            s = pygame.Surface((bg.width, bg.height))
            s.set_alpha(180)
            s.fill(WHITE)
            self.surface.blit(s, bg)
            
            self.surface.blit(text, text_rect)
            y_offset += 20


################################################################################
PATH: ./tank_project/visualization/__init__.py
################################################################################


################################################################################
PATH: ./tank_project/visualization/projector_overlay.py
################################################################################
"""
Projector Overlay - Gestion Affichage Projecteur

Gère affichage superposé sur projecteur (éléments calibration, debug).

Logs: [OVERLAY] prefix
"""

import pygame
import numpy as np
from typing import Tuple, Optional
from .colors import *


class ProjectorOverlay:
    """
    Gère éléments overlay projetés.
    """
    
    def __init__(self, surface: pygame.Surface):
        """
        Initialize overlay.
        
        Args:
            surface: Surface Pygame où dessiner
        """
        self.surface = surface
        self.font = pygame.font.SysFont('Arial', 32)
        self.font_small = pygame.font.SysFont('Arial', 20)
        
    def draw_calibration_markers(self,
                                positions: list,
                                marker_ids: list,
                                size: int = 100):
        """
        Dessine marqueurs ArUco virtuels pour calibration.
        
        Args:
            positions: Liste (x, y) positions pixels
            marker_ids: Liste IDs marqueurs (0-3)
            size: Taille marqueurs pixels
        """
        for pos, marker_id in zip(positions, marker_ids):
            # Dessiner carré blanc avec bordure noire
            rect = pygame.Rect(pos[0] - size//2, pos[1] - size//2, size, size)
            pygame.draw.rect(self.surface, WHITE, rect)
            pygame.draw.rect(self.surface, BLACK, rect, 3)
            
            # Dessiner ID au centre
            text = self.font.render(str(marker_id), True, BLACK)
            text_rect = text.get_rect(center=pos)
            self.surface.blit(text, text_rect)
    
    def draw_crosshair(self, pos: Tuple[int, int], 
                      size: int = 20,
                      color: Tuple = RED):
        """
        Dessine réticule.
        
        Args:
            pos: Position (x, y)
            size: Taille
            color: Couleur
        """
        x, y = pos
        pygame.draw.line(self.surface, color, 
                        (x - size, y), (x + size, y), 2)
        pygame.draw.line(self.surface, color,
                        (x, y - size), (x, y + size), 2)
        pygame.draw.circle(self.surface, color, pos, size, 2)
    
    def draw_message(self, message: str,
                    position: Tuple[int, int],
                    color: Tuple = BLACK,
                    font_size: str = 'normal'):
        """
        Affiche message texte.
        
        Args:
            message: Texte à afficher
            position: (x, y) position
            color: Couleur texte
            font_size: 'normal' ou 'small'
        """
        font = self.font if font_size == 'normal' else self.font_small
        text = font.render(message, True, color)
        self.surface.blit(text, position)
    
    def draw_instruction(self, instruction: str):
        """
        Affiche instruction centrée en haut.
        
        Args:
            instruction: Texte instruction
        """
        text = self.font.render(instruction, True, BLACK)
        text_rect = text.get_rect(center=(self.surface.get_width() // 2, 100))
        
        # Fond semi-transparent
        bg_rect = text_rect.inflate(40, 20)
        s = pygame.Surface((bg_rect.width, bg_rect.height))
        s.set_alpha(200)
        s.fill(WHITE)
        self.surface.blit(s, bg_rect)
        
        # Texte
        self.surface.blit(text, text_rect)


################################################################################
PATH: ./tank_project/visualization/pygame_renderer.py
################################################################################
"""
Moteur de Rendu Pygame - Visualisation de Jeu Moderne

Rendu premium avec :
- Placement stratégique du HUD (coins, n'obscurcit jamais les ArUcos au centre)
- Écrans de début/fin de match avec animations
- Visualisation du chemin de débogage (bascule avec la touche 'D')
- Score dynamique avec retour visuel
- Design moderne (dégradés, ombres, polices premium)

Logs : préfixe [VIS]
"""

import pygame
import numpy as np
import os
import math
from typing import Dict, Tuple, Optional, List
from datetime import datetime


class PygameRenderer:
    """
    Moteur de rendu de jeu moderne avec design HUD tactique.
    
    Fonctionnalités :
    - HUD basé sur les coins (n'obstrue pas les ArUcos centraux)
    - États du match (attente, compte à rebours, jeu, terminé)
    - Visualisation chemin de débogage (bascule D)
    - Animations de score et effets visuels
    """
    
    # États du match
    STATE_WAITING = "waiting"
    STATE_COUNTDOWN = "countdown"
    STATE_PLAYING = "playing"
    STATE_FINISHED = "finished"
    
    def __init__(self, width: int = 1024, height: int = 768, margin: int = 50, 
                 fullscreen: bool = True, display_index: int = 0):
        """
        Initialise le rendu avec une UI de jeu moderne.
        
        Args:
            width: Largeur projecteur
            height: Hauteur projecteur
            margin: Marge zone sûre
            fullscreen: Si True, mode plein écran
            display_index: 0 = principal, 1 = projecteur
        """
        # Définit la position d'affichage AVANT pygame.init()
        if display_index == 1:
            os.environ['SDL_VIDEO_WINDOW_POS'] = f'{width},0'
        elif display_index == 0:
            os.environ['SDL_VIDEO_WINDOW_POS'] = '0,0'
        
        pygame.init()
        
        self.base_width = width
        self.base_height = height
        self.width = width
        self.height = height
        self.margin = margin
        self.fullscreen = fullscreen
        
        self.draw_width = width - 2 * margin
        self.draw_height = height - 2 * margin
        
        # Crée l'affichage - démarre toujours en mode fenêtré redimensionnable pour la stabilité
        self._create_display()
        
        pygame.display.set_caption("Tank Arena - Combat Tactique")
        
        # Polices - Hiérarchie premium
        pygame.font.init()
        self.font_title = pygame.font.SysFont('Arial Black', 72, bold=True)
        self.font_large = pygame.font.SysFont('Arial Black', 48, bold=True)
        self.font_medium = pygame.font.SysFont('Arial', 36, bold=True)
        self.font_small = pygame.font.SysFont('Arial', 24)
        self.font_tiny = pygame.font.SysFont('Courier', 16)
        
        # Palette de couleurs premium
        self.BG_DARK = (20, 20, 25)
        self.BG_LIGHT = (240, 240, 245)
        
        self.AI_PRIMARY = (50, 150, 255)      # Blue
        self.AI_GLOW = (100, 200, 255)
        self.AI_DARK = (20, 80, 150)
        
        self.HUMAN_PRIMARY = (255, 80, 80)    # Red
        self.HUMAN_GLOW = (255, 150, 150)
        self.HUMAN_DARK = (180, 30, 30)
        
        self.ACCENT_GOLD = (255, 200, 50)
        self.ACCENT_GREEN = (50, 255, 150)
        self.ACCENT_ORANGE = (255, 150, 50)
        
        self.TEXT_DARK = (30, 30, 35)
        self.TEXT_LIGHT = (250, 250, 255)
        self.TEXT_GRAY = (150, 150, 160)
        
        self.OVERLAY_DARK = (0, 0, 0, 180)    # Semi-transparent
        self.OVERLAY_LIGHT = (255, 255, 255, 200)
        
        # Arena dimensions
        self.arena_width_m = 3.0
        self.arena_height_m = 2.0
        self.scale = None
        
        # Match state
        self.match_state = self.STATE_WAITING
        self.countdown_start = None
        self.match_start_time = None
        self.winner = None
        
        # Debug visualization
        self.show_debug_path = False
        self.ai_path = []  # List of (x, y) waypoints
        
        # Visual effects
        self.score_flash_ai = 0
        self.score_flash_human = 0
        self.last_ai_score = 0
        
    def _create_display(self):
        """Create or recreate the display with current settings."""
        try:
            if self.fullscreen:
                # Try fullscreen without HWSURFACE (more compatible)
                self.screen = pygame.display.set_mode(
                    (self.width, self.height),
                    pygame.FULLSCREEN
                )
            else:
                # Windowed + resizable
                self.screen = pygame.display.set_mode(
                    (self.width, self.height),
                    pygame.RESIZABLE
                )
            print(f"[VIS] Affichage créé : {self.width}x{self.height} plein écran={self.fullscreen}")
        except pygame.error as e:
            print(f"[VIS] Erreur affichage : {e}, retour au mode fenêtré")
            self.fullscreen = False
            self.screen = pygame.display.set_mode(
                (self.base_width, self.base_height),
                pygame.RESIZABLE
            )
    
    def toggle_fullscreen(self):
        """Toggle between fullscreen and windowed mode."""
        self.fullscreen = not self.fullscreen
        if not self.fullscreen:
            # Restore base dimensions when exiting fullscreen
            self.width = self.base_width
            self.height = self.base_height
        else:
            # Get current display info for fullscreen
            info = pygame.display.Info()
            self.width = info.current_w
            self.height = info.current_h
        
        self._update_dimensions()
        self._create_display()
    
    def _update_dimensions(self):
        """Update drawing dimensions after resize."""
        self.draw_width = self.width - 2 * self.margin
        self.draw_height = self.height - 2 * self.margin
        
        # Recalculate scale
        if self.arena_width_m > 0 and self.arena_height_m > 0:
            scale_x = self.draw_width / self.arena_width_m
            scale_y = self.draw_height / self.arena_height_m
            self.scale = min(scale_x, scale_y)
    
    def handle_resize(self, new_width: int, new_height: int):
        """Handle window resize event."""
        self.width = new_width
        self.height = new_height
        self._update_dimensions()
        self.screen = pygame.display.set_mode((new_width, new_height), pygame.RESIZABLE)
        print(f"[VIS] Redimensionné à {new_width}x{new_height}")
        self.last_human_score = 0
        
    def set_arena_dimensions(self, width_m: float, height_m: float):
        """Set arena dimensions for coordinate conversion."""
        self.arena_width_m = width_m
        self.arena_height_m = height_m
        
        scale_x = self.draw_width / width_m
        scale_y = self.draw_height / height_m
        self.scale = min(scale_x, scale_y)
        
    def world_to_screen(self, x_m: float, y_m: float) -> Tuple[int, int]:
        """Convert world coordinates to screen pixels."""
        if self.scale is None:
            self.scale = 100
        
        px = self.margin + int(x_m * self.scale)
        py = self.margin + int((self.arena_height_m - y_m) * self.scale)
        
        return (px, py)
    
    def handle_keypress(self, event: pygame.event.Event):
        """
        Handle keyboard input.
        
        Args:
            event: Pygame key event
        """
        if event.type == pygame.KEYDOWN:
            if event.key == pygame.K_d:
                # Toggle debug path visualization
                self.show_debug_path = not self.show_debug_path
                print("[VIS] Chemin debug : {}".format('ON' if self.show_debug_path else 'OFF'))
            elif event.key == pygame.K_F11:
                # Toggle fullscreen
                self.toggle_fullscreen()
            elif event.key == pygame.K_ESCAPE and self.fullscreen:
                # Exit fullscreen on ESC
                self.toggle_fullscreen()
    
    def start_match(self, countdown_seconds: float = 3.0):
        """Start match countdown."""
        self.match_state = self.STATE_COUNTDOWN
        self.countdown_start = pygame.time.get_ticks() / 1000.0
        self.countdown_duration = countdown_seconds
        
    def begin_playing(self):
        """Begin actual gameplay."""
        self.match_state = self.STATE_PLAYING
        self.match_start_time = pygame.time.get_ticks() / 1000.0
        
    def end_match(self, winner: str):
        """
        End match and show results.
        
        Args:
            winner: "AI" or "HUMAN"
        """
        self.match_state = self.STATE_FINISHED
        self.winner = winner
        
    def set_ai_path(self, waypoints: List[Tuple[float, float]]):
        """
        Set AI path for debug visualization.
        
        Args:
            waypoints: List of (x, y) positions in meters
        """
        self.ai_path = waypoints
    
    def render_frame(self, world_state: Dict, game_state: Dict):
        """
        Render complete frame based on match state.
        
        Args:
            world_state: Robot poses, obstacles, etc.
            game_state: Scores, time, status
        """
        # Update score flash effects
        ai_score = game_state.get('robot_4_hits_inflicted', 0)
        human_score = game_state.get('robot_5_hits_inflicted', 0)
        
        if ai_score > self.last_ai_score:
            self.score_flash_ai = 30  # Flash for 30 frames
            self.last_ai_score = ai_score
        
        if human_score > self.last_human_score:
            self.score_flash_human = 30
            self.last_human_score = human_score
        
        self.score_flash_ai = max(0, self.score_flash_ai - 1)
        self.score_flash_human = max(0, self.score_flash_human - 1)
        
        # Render based on state
        if self.match_state == self.STATE_WAITING:
            self._render_waiting_screen()
        elif self.match_state == self.STATE_COUNTDOWN:
            self._render_countdown(world_state, game_state)
        elif self.match_state == self.STATE_PLAYING:
            self._render_gameplay(world_state, game_state)
        elif self.match_state == self.STATE_FINISHED:
            self._render_end_screen(game_state)
        
        # Update display
        pygame.display.flip()
    
    def _render_waiting_screen(self):
        """Render waiting for match start screen."""
        self.screen.fill(self.BG_DARK)
        
        # Title
        title = self.font_title.render("TANK ARENA", True, self.ACCENT_GOLD)
        title_rect = title.get_rect(center=(self.width // 2, self.height // 2 - 100))
        self.screen.blit(title, title_rect)
        
        # Sous-titre
        subtitle = self.font_medium.render("Combat de Robots Tactique", True, self.TEXT_LIGHT)
        subtitle_rect = subtitle.get_rect(center=(self.width // 2, self.height // 2))
        self.screen.blit(subtitle, subtitle_rect)
        
        # Instruction
        pulse = int(128 + 127 * math.sin(pygame.time.get_ticks() / 500))
        instruction = self.font_small.render("Appuyez sur START pour commencer", True, (pulse, pulse, pulse))
        instr_rect = instruction.get_rect(center=(self.width // 2, self.height // 2 + 100))
        self.screen.blit(instruction, instr_rect)
    
    def _render_countdown(self, world_state: Dict, game_state: Dict):
        """Render countdown before match."""
        # Draw arena first (faded)
        self._render_gameplay(world_state, game_state, alpha=100)
        
        # Overlay countdown
        overlay = pygame.Surface((self.width, self.height), pygame.SRCALPHA)
        overlay.fill((0, 0, 0, 150))
        self.screen.blit(overlay, (0, 0))
        
        # Calculate countdown
        elapsed = pygame.time.get_ticks() / 1000.0 - self.countdown_start
        remaining = max(0, self.countdown_duration - elapsed)
        
        if remaining > 0:
            count_num = int(remaining) + 1
            scale = 1.0 + 0.3 * (1.0 - (remaining % 1.0))
            
            count_text = self.font_title.render(str(count_num), True, self.ACCENT_GOLD)
            count_text = pygame.transform.scale(
                count_text,
                (int(count_text.get_width() * scale), int(count_text.get_height() * scale))
            )
            count_rect = count_text.get_rect(center=(self.width // 2, self.height // 2))
            self.screen.blit(count_text, count_rect)
        else:
            # Switch to playing
            self.begin_playing()
    
    def _render_gameplay(self, world_state: Dict, game_state: Dict, alpha: int = 255):
        """Render main gameplay view."""
        # Background
        self.screen.fill(self.BG_LIGHT)
        
        # Arena border
        self._draw_arena_border()
        
        # Debug: AI path (if enabled)
        if self.show_debug_path and self.ai_path:
            self._draw_ai_path()
        
        # Obstacles
        self._draw_obstacles(world_state.get('occupancy_grid'))
        
        # Robots
        robot_4_pose = world_state.get('robot_4_pose', (0, 0, 0))
        robot_5_pose = world_state.get('robot_5_pose', (0, 0, 0))
        
        self._draw_robot(robot_4_pose, self.AI_PRIMARY, "IA", self.AI_GLOW)
        self._draw_robot(robot_5_pose, self.HUMAN_PRIMARY, "HUMAIN", self.HUMAN_GLOW)
        
        # Lock-on indicator
        if game_state.get('ai_has_los', False):
            self._draw_lock_on(robot_5_pose[:2])
        
        # HUD - STRATEGIC PLACEMENT (corners only!)
        self._draw_modern_hud(game_state)
        
        # Debug info (bottom right corner)
        if self.show_debug_path:
            self._draw_debug_info(game_state)
    
    def _draw_arena_border(self):
        """Draw arena boundary with modern style."""
        rect = pygame.Rect(self.margin, self.margin, self.draw_width, self.draw_height)
        
        # Outer glow
        for i in range(3):
            glow_rect = rect.inflate(i * 4, i * 4)
            alpha = 40 - i * 10
            s = pygame.Surface((glow_rect.width, glow_rect.height), pygame.SRCALPHA)
            pygame.draw.rect(s, (*self.TEXT_GRAY, alpha), s.get_rect(), 2)
            self.screen.blit(s, glow_rect.topleft)
        
        # Main border
        pygame.draw.rect(self.screen, self.TEXT_DARK, rect, 4)
    
    def _draw_obstacles(self, grid):
        """Draw obstacles from occupancy grid."""
        if grid is None:
            return
            
        # Iterate through occupied cells
        # Note: inefficient for very large grids, optimization would be to use static surface
        rows, cols = grid.grid.shape
        
        # Color for obstacles
        obs_color = (60, 60, 70)
        
        for r in range(rows):
            for c in range(cols):
                if grid.grid[r, c] > 0.5:
                    # Convert grid cell to world m -> screen px
                    # Grid (r, c) -> World (x, y) center
                    x_m, y_m = grid.grid_to_world(r, c)
                    
                    # Convert to screen
                    px, py = self.world_to_screen(x_m, y_m)
                    
                    # Size of cell in pixels
                    size = int(grid.resolution * self.scale) + 1  # +1 to avoid gaps
                    
                    # Draw rect
                    rect = pygame.Rect(px - size//2, py - size//2, size, size)
                    pygame.draw.rect(self.screen, obs_color, rect)
    
    def _draw_robot(self, pose: Tuple[float, float, float], color: Tuple, 
                   label: str, glow_color: Tuple):
        """Draw robot with modern visual effects."""
        x, y, theta = pose
        px, py = self.world_to_screen(x, y)
        
        radius_px = int(0.09 * self.scale) if self.scale else 30
        
        # Glow effect
        for i in range(3):
            glow_radius = radius_px + (3 - i) * 8
            alpha = 30 + i * 10
            s = pygame.Surface((glow_radius * 2, glow_radius * 2), pygame.SRCALPHA)
            pygame.draw.circle(s, (*glow_color, alpha), (glow_radius, glow_radius), glow_radius)
            self.screen.blit(s, (px - glow_radius, py - glow_radius))
        
        # Main body
        pygame.draw.circle(self.screen, color, (px, py), radius_px)
        pygame.draw.circle(self.screen, self.TEXT_DARK, (px, py), radius_px, 3)
        
        # Orientation indicator (cannon)
        line_len = radius_px * 1.8
        end_x = px + int(line_len * np.cos(theta))
        end_y = py - int(line_len * np.sin(theta))
        
        # Cannon shadow
        pygame.draw.line(self.screen, (0, 0, 0, 100), 
                        (px + 2, py + 2), (end_x + 2, end_y + 2), 5)
        # Cannon
        pygame.draw.line(self.screen, self.TEXT_DARK, (px, py), (end_x, end_y), 5)
        pygame.draw.circle(self.screen, self.ACCENT_GOLD, (end_x, end_y), 6)
    
    def _draw_ai_path(self):
        """Draw AI pathfinding visualization (debug mode)."""
        if len(self.ai_path) < 2:
            return
        
        # Convert waypoints to screen coords
        points = [self.world_to_screen(x, y) for x, y in self.ai_path]
        
        # Draw path line
        if len(points) >= 2:
            pygame.draw.lines(self.screen, self.AI_PRIMARY, False, points, 3)
        
        # Draw waypoint markers
        for i, (px, py) in enumerate(points):
            pygame.draw.circle(self.screen, self.AI_PRIMARY, (px, py), 4)
            if i == len(points) - 1:
                # Goal marker
                pygame.draw.circle(self.screen, self.ACCENT_GREEN, (px, py), 8, 2)
    
    def _draw_lock_on(self, target_pos: Tuple[float, float]):
        """Draw lock-on indicator with pulse effect."""
        px, py = self.world_to_screen(*target_pos)
        
        t = pygame.time.get_ticks() / 1000.0
        radius = 25 + int(8 * math.sin(t * 4))
        
        # Crosshair
        pygame.draw.circle(self.screen, self.HUMAN_PRIMARY, (px, py), radius, 3)
        pygame.draw.line(self.screen, self.HUMAN_PRIMARY, 
                        (px - radius - 10, py), (px - radius - 5, py), 3)
        pygame.draw.line(self.screen, self.HUMAN_PRIMARY, 
                        (px + radius + 5, py), (px + radius + 10, py), 3)
        pygame.draw.line(self.screen, self.HUMAN_PRIMARY, 
                        (px, py - radius - 10), (px, py - radius - 5), 3)
        pygame.draw.line(self.screen, self.HUMAN_PRIMARY, 
                        (px, py + radius + 5), (px, py + radius + 10), 3)
        
        # Texte "VERROUILLÉ"
        locked_text = self.font_tiny.render("VERROUILLÉ", True, self.HUMAN_PRIMARY)
        self.screen.blit(locked_text, (px - 25, py + radius + 15))
    
    def _draw_modern_hud(self, game_state: Dict):
        """
        Draw HUD in CORNERS only (never obscures center ArUcos).
        
        Layout:
        - Top-left: AI score
        - Top-right: Human score
        - Top-center: Timer (small, minimal)
        - Bottom-left: Match info
        - Bottom-right: Debug toggle hint
        """
        # --- TOP-LEFT: AI SCORE ---
        ai_score = game_state.get('robot_4_hits_inflicted', 0)
        ai_health = game_state.get('robot_4_hits_received', 0)
        
        flash_alpha = self.score_flash_ai * 8 if self.score_flash_ai > 0 else 0
        ai_bg_color = (
            min(255, self.AI_PRIMARY[0] + flash_alpha),
            min(255, self.AI_PRIMARY[1] + flash_alpha),
            min(255, self.AI_PRIMARY[2] + flash_alpha)
        )
        
        self._draw_score_corner(30, 30, "ROBOT IA", ai_score, ai_health, 
                               ai_bg_color, self.AI_DARK, "left")
        
        # --- HAUT-DROITE : SCORE HUMAIN ---
        human_score = game_state.get('robot_5_hits_inflicted', 0)
        human_health = game_state.get('robot_5_hits_received', 0)
        
        flash_alpha = self.score_flash_human * 8 if self.score_flash_human > 0 else 0
        human_bg_color = (
            min(255, self.HUMAN_PRIMARY[0] + flash_alpha),
            min(255, self.HUMAN_PRIMARY[1] + flash_alpha),
            min(255, self.HUMAN_PRIMARY[2] + flash_alpha)
        )
        
        self._draw_score_corner(self.width - 30, 30, "HUMAIN", human_score, human_health,
                               human_bg_color, self.HUMAN_DARK, "right")
        
        # --- HAUT-CENTRE : MINUTEUR (minimal) ---
        time_remaining = game_state.get('time_remaining_s', 0)
        mins = int(time_remaining // 60)
        secs = int(time_remaining % 60)
        
        timer_text = f"{mins:02d}:{secs:02d}"
        timer_surface = self.font_medium.render(timer_text, True, self.TEXT_DARK)
        timer_rect = timer_surface.get_rect(midtop=(self.width // 2, 30))
        
        # Timer background
        bg_rect = timer_rect.inflate(40, 20)
        pygame.draw.rect(self.screen, self.TEXT_LIGHT, bg_rect, border_radius=10)
        pygame.draw.rect(self.screen, self.TEXT_GRAY, bg_rect, 2, border_radius=10)
        
        self.screen.blit(timer_surface, timer_rect)
        
        # --- BAS-GAUCHE : Info match ---
        status = game_state.get('ai_state', 'IDLE')
        info_text = f"IA : {status}"
        info_surface = self.font_small.render(info_text, True, self.TEXT_GRAY)
        self.screen.blit(info_surface, (30, self.height - 60))
        
        # --- BAS-DROITE : Indice debug ---
        if self.show_debug_path:
            debug_text = "[D] Masquer Chemin"
            debug_color = self.ACCENT_GREEN
        else:
            debug_text = "[D] Afficher Chemin IA"
            debug_color = self.TEXT_GRAY
        
        debug_surface = self.font_small.render(debug_text, True, debug_color)
        debug_rect = debug_surface.get_rect(bottomright=(self.width - 30, self.height - 30))
        self.screen.blit(debug_surface, debug_rect)
    
    def _draw_score_corner(self, x: int, y: int, label: str, score: int, health: int,
                          bg_color: Tuple, border_color: Tuple, align: str):
        """Draw score panel in corner."""
        # Panel dimensions
        panel_width = 240
        panel_height = 120
        
        # Calculate position based on alignment
        if align == "right":
            panel_x = x - panel_width
        else:
            panel_x = x
        
        panel_rect = pygame.Rect(panel_x, y, panel_width, panel_height)
        
        # Background with transparency
        s = pygame.Surface((panel_width, panel_height), pygame.SRCALPHA)
        pygame.draw.rect(s, (*bg_color, 200), s.get_rect(), border_radius=15)
        pygame.draw.rect(s, border_color, s.get_rect(), 3, border_radius=15)
        self.screen.blit(s, panel_rect.topleft)
        
        # Label
        label_surface = self.font_small.render(label, True, self.TEXT_LIGHT)
        self.screen.blit(label_surface, (panel_x + 15, y + 10))
        
        # Score (large)
        score_surface = self.font_large.render(str(score), True, self.TEXT_LIGHT)
        self.screen.blit(score_surface, (panel_x + 15, y + 40))
        
        # Coups reçus
        health_text = f"Coups : {health}"
        health_surface = self.font_tiny.render(health_text, True, self.TEXT_LIGHT)
        self.screen.blit(health_surface, (panel_x + 15, y + 95))
    
    def _draw_debug_info(self, game_state: Dict):
        """Draw debug information (bottom-right, small)."""
        debug_lines = [
            f"Path waypoints: {len(self.ai_path)}",
            f"AI LOS: {game_state.get('ai_has_los', False)}",
            f"Fire request: {game_state.get('ai_fire_request', False)}"
        ]
        
        y_offset = self.height - 120
        for line in debug_lines:
            text = self.font_tiny.render(line, True, self.TEXT_GRAY)
            self.screen.blit(text, (self.width - 300, y_offset))
            y_offset += 20
    
    def _render_end_screen(self, game_state: Dict):
        """Render match end screen with results."""
        self.screen.fill(self.BG_DARK)
        
        # Annonce vainqueur
        if self.winner == "AI":
            winner_text = "VICTOIRE IA"
            winner_color = self.AI_GLOW
        else:
            winner_text = "VICTOIRE HUMAIN"
            winner_color = self.HUMAN_GLOW
        
        winner_surface = self.font_title.render(winner_text, True, winner_color)
        winner_rect = winner_surface.get_rect(center=(self.width // 2, self.height // 2 - 100))
        self.screen.blit(winner_surface, winner_rect)
        
        # Final scores
        ai_score = game_state.get('robot_4_hits_inflicted', 0)
        human_score = game_state.get('robot_5_hits_inflicted', 0)
        
        scores_text = f"{ai_score}  -  {human_score}"
        scores_surface = self.font_large.render(scores_text, True, self.TEXT_LIGHT)
        scores_rect = scores_surface.get_rect(center=(self.width // 2, self.height // 2))
        self.screen.blit(scores_surface, scores_rect)
        
        # Étiquettes
        ai_label = self.font_medium.render("IA", True, self.AI_PRIMARY)
        human_label = self.font_medium.render("HUMAIN", True, self.HUMAN_PRIMARY)
        
        self.screen.blit(ai_label, (self.width // 2 - 150, self.height // 2 + 60))
        self.screen.blit(human_label, (self.width // 2 + 50, self.height // 2 + 60))
        
        # Indice redémarrage
        restart_text = "Appuyez sur R pour redémarrer"
        restart_surface = self.font_small.render(restart_text, True, self.TEXT_GRAY)
        restart_rect = restart_surface.get_rect(center=(self.width // 2, self.height // 2 + 150))
        self.screen.blit(restart_surface, restart_rect)
    
    def cleanup(self):
        """Cleanup Pygame resources."""
        pygame.quit()


################################################################################
PATH: ./tank_project/visualization/ui_hud.py
################################################################################
"""
UI HUD - Heads-Up Display

Gère affichage HUD (scores, timer, status).

Logs: [HUD] prefix
"""

import pygame
import time
from typing import Dict, Optional
from .colors import *


class UI_HUD:
    """
    Gère HUD du jeu.
    """
    
    def __init__(self, surface: pygame.Surface):
        """
        Initialize HUD.
        
        Args:
            surface: Surface Pygame
        """
        self.surface = surface
        self.width = surface.get_width()
        self.height = surface.get_height()
        
        # Fonts
        self.font_large = pygame.font.SysFont('Arial', 64, bold=True)
        self.font_medium = pygame.font.SysFont('Arial', 40)
        self.font_small = pygame.font.SysFont('Arial', 28)
        
    def draw_timer(self, time_remaining: float):
        """
        Dessine chronomètre.
        
        Args:
            time_remaining: Temps restant (secondes)
        """
        minutes = int(time_remaining // 60)
        seconds = int(time_remaining % 60)
        
        time_text = f"{minutes:02d}:{seconds:02d}"
        text = self.font_large.render(time_text, True, TIMER_COLOR)
        text_rect = text.get_rect(center=(self.width // 2, 60))
        
        # Fond
        bg_rect = text_rect.inflate(40, 20)
        pygame.draw.rect(self.surface, WHITE, bg_rect)
        pygame.draw.rect(self.surface, BLACK, bg_rect, 3)
        
        self.surface.blit(text, text_rect)
        
    def draw_scores(self, ai_hits: int, human_hits: int):
        """
        Dessine scores.
        
        Args:
            ai_hits: Hits IA
            human_hits: Hits humain
        """
        # Score IA (gauche)
        ai_text = f"IA: {ai_hits}"
        ai_surface = self.font_medium.render(ai_text, True, SCORE_AI_COLOR)
        
        bg_ai = pygame.Rect(40, 40, 150, 60)
        pygame.draw.rect(self.surface, WHITE, bg_ai)
        pygame.draw.rect(self.surface, SCORE_AI_COLOR, bg_ai, 3)
        self.surface.blit(ai_surface, (50, 50))
        
        # Score Humain (droite)
        human_text = f"HUMAIN: {human_hits}"
        human_surface = self.font_medium.render(human_text, True, SCORE_HUMAN_COLOR)
        
        bg_human = pygame.Rect(self.width - 250, 40, 210, 60)
        pygame.draw.rect(self.surface, WHITE, bg_human)
        pygame.draw.rect(self.surface, SCORE_HUMAN_COLOR, bg_human, 3)
        self.surface.blit(human_surface, (self.width - 240, 50))
        
    def draw_cooldown(self, robot_id: int, cooldown_remaining: float):
        """
        Dessine barre cooldown tir.
        
        Args:
            robot_id: 4 (IA) ou 5 (Humain)
            cooldown_remaining: Temps restant (secondes)
        """
        if cooldown_remaining <= 0:
            return
        
        # Position selon robot
        if robot_id == 4:  # IA
            x, y = 40, 120
            color = SCORE_AI_COLOR
        else:  # Humain
            x, y = self.width - 250, 120
            color = SCORE_HUMAN_COLOR
        
        # Barre fond
        bar_width = 200
        bar_height = 20
        pygame.draw.rect(self.surface, GRAY_LIGHT, (x, y, bar_width, bar_height))
        
        # Barre remplissage
        fill_width = int(bar_width * (cooldown_remaining / 5.0))  # Max 5s
        pygame.draw.rect(self.surface, color, (x, y, fill_width, bar_height))
        
        # Bordure
        pygame.draw.rect(self.surface, BLACK, (x, y, bar_width, bar_height), 2)
        
    def draw_game_over(self, winner: str):
        """
        Affiche écran fin de partie.
        
        Args:
            winner: "AI", "HUMAN", ou "DRAW"
        """
        # Fond semi-transparent
        overlay = pygame.Surface((self.width, self.height))
        overlay.set_alpha(180)
        overlay.fill(BLACK)
        self.surface.blit(overlay, (0, 0))
        
        # Texte vainqueur
        if winner == "DRAW":
            text = "ÉGALITÉ!"
            color = YELLOW
        elif winner == "AI":
            text = "VICTOIRE IA!"
            color = SCORE_AI_COLOR
        else:
            text = "VICTOIRE HUMAIN!"
            color = SCORE_HUMAN_COLOR
        
        winner_surface = self.font_large.render(text, True, color)
        winner_rect = winner_surface.get_rect(center=(self.width // 2, self.height // 2))
        self.surface.blit(winner_surface, winner_rect)
        
    def draw_status_message(self, message: str, 
                          position: Optional[tuple] = None):
        """
        Affiche message status.
        
        Args:
            message: Message à afficher
            position: Position (x,y) ou None pour centré bas
        """
        text = self.font_small.render(message, True, BLACK)
        
        if position is None:
            position = (self.width // 2 - text.get_width() // 2, 
                       self.height - 100)
        
        # Fond
        bg_rect = text.get_rect(topleft=position).inflate(20, 10)
        pygame.draw.rect(self.surface, WHITE, bg_rect)
        pygame.draw.rect(self.surface, BLACK, bg_rect, 2)
        
        self.surface.blit(text, position)


################################################################################
PATH: ./turtlebot_game/config/safety_config.py
################################################################################
# config/safety_config.py
"""Configuration centralisée pour le Safety Bridge"""

class SafetyBridgeConfig:
    """Configuration du WebSocket Safety Bridge"""
    
    # ===== WEBSOCKET =====
    ROBOT_NAMESPACE = "robot1"
    WS_HOST = "0.0.0.0"
    WS_PORT = 8765
    
    # ===== LIMITES DE VITESSE =====
    MAX_LINEAR_VEL = 0.5      # m/s
    MIN_LINEAR_VEL = -0.3     # m/s
    MAX_ANGULAR_VEL = 1.5     # rad/s
    
    # ===== SÉCURITÉ (pour version avec détection d'obstacles) =====
    SAFETY_DISTANCE = 0.3           # Distance minimale obstacles (m)
    ROBOT_SAFETY_DISTANCE = 0.5     # Distance minimale entre robots (m)
    ROBOT_RADIUS = 0.2              # Rayon du robot (m)
    
    # ===== PRÉDICTION DE TRAJECTOIRE =====
    PREDICTION_STEPS = 10     # Nombre de steps de prédiction
    PREDICTION_DT = 0.1       # Delta temps entre steps (s)
    
    # ===== LOGGING & DEBUG =====
    LOG_LEVEL = "INFO"        # DEBUG, INFO, WARN, ERROR
    DEBUG = False             # Mode debug verbeux
    
    # ===== QoS ROS2 =====
    QOS_DEPTH = 10
    QOS_RELIABILITY = "RELIABLE"  # RELIABLE ou BEST_EFFORT
    
    # ===== WEBSOCKET AVANCÉ =====
    WS_PING_INTERVAL = 20     # Intervalle ping WebSocket (s)
    WS_PING_TIMEOUT = 10      # Timeout ping (s)
    WS_MAX_MESSAGE_SIZE = 1048576  # 1MB
    
    # ===== BROADCAST =====
    STATUS_BROADCAST_INTERVAL = 5.0  # Intervalle broadcast status (s)
    
    # ===== TIMEOUTS =====
    CMD_TIMEOUT = 1.0         # Timeout commande (s)
    CONNECTION_TIMEOUT = 30.0 # Timeout connexion (s)
    
    @classmethod
    def to_dict(cls):
        """Convertit la config en dictionnaire"""
        return {
            key.lower(): value 
            for key, value in vars(cls).items() 
            if not key.startswith('_') and key.isupper()
        }
    
    @classmethod
    def get_ros_params(cls):
        """Retourne les paramètres au format ROS2"""
        return {
            'robot_namespace': cls.ROBOT_NAMESPACE,
            'ws_host': cls.WS_HOST,
            'ws_port': cls.WS_PORT,
            'max_linear_vel': cls.MAX_LINEAR_VEL,
            'min_linear_vel': cls.MIN_LINEAR_VEL,
            'max_angular_vel': cls.MAX_ANGULAR_VEL,
            'safety_distance': cls.SAFETY_DISTANCE,
            'robot_safety_distance': cls.ROBOT_SAFETY_DISTANCE,
            'robot_radius': cls.ROBOT_RADIUS,
            'prediction_steps': cls.PREDICTION_STEPS,
            'prediction_dt': cls.PREDICTION_DT,
            'log_level': cls.LOG_LEVEL,
            'debug': cls.DEBUG,
            'qos_depth': cls.QOS_DEPTH,
            'ws_ping_interval': cls.WS_PING_INTERVAL,
            'ws_ping_timeout': cls.WS_PING_TIMEOUT,
            'status_broadcast_interval': cls.STATUS_BROADCAST_INTERVAL,
            'cmd_timeout': cls.CMD_TIMEOUT,
        }


# Configurations pré-définies
class DevConfig(SafetyBridgeConfig):
    """Configuration pour développement"""
    DEBUG = True
    LOG_LEVEL = "DEBUG"
    STATUS_BROADCAST_INTERVAL = 2.0


class ProdConfig(SafetyBridgeConfig):
    """Configuration pour production"""
    DEBUG = False
    LOG_LEVEL = "INFO"
    MAX_LINEAR_VEL = 0.3  # Plus conservateur


class FastConfig(SafetyBridgeConfig):
    """Configuration pour robot rapide"""
    MAX_LINEAR_VEL = 1.0
    MAX_ANGULAR_VEL = 2.0

################################################################################
PATH: ./turtlebot_game/DOCUMENTATION.md
################################################################################
# TurtleBot Game - Documentation

Pont ROS2 entre les clients WebSocket et le robot TurtleBot physique.

## Architecture

```mermaid
flowchart LR
    subgraph CLIENTS["Clients WebSocket"]
        TANK[Tank Project<br/>IA Robot]
        CTRL[Control TurtleBot<br/>Manuel]
    end

    subgraph BRIDGE["Safety Bridge"]
        WS[Serveur WebSocket<br/>Port 8765]
        LIM[VelocityLimiter]
        ROS[ROS2 Node]
    end

    subgraph ROBOT["TurtleBot"]
        CMD["/cmd_vel Topic"]
    end

    TANK -->|JSON| WS
    CTRL -->|JSON| WS
    WS --> LIM
    LIM --> ROS
    ROS -->|Twist| CMD
```

## Flux de Traitement

```mermaid
sequenceDiagram
    participant CLIENT as Client WebSocket
    participant WS as WebSocket Server
    participant LIM as VelocityLimiter
    participant ROS as ROS2 Publisher
    participant BOT as TurtleBot

    CLIENT->>WS: {"type": "cmd_vel", "linear_x": 0.2, "angular_z": 0.5}
    WS->>WS: Parse JSON
    WS->>LIM: validate_command(0.2, 0.5)
    LIM->>LIM: Clamp aux limites
    LIM-->>WS: (True, 0.2, 0.5, "OK")
    WS->>ROS: Twist(linear.x=0.2, angular.z=0.5)
    ROS->>BOT: Publish /cmd_vel
    WS-->>CLIENT: {"type": "cmd_accepted", ...}
```

## Protocole WebSocket

### Messages Entrants

| Type             | Description      | Champs Requis           |
| ---------------- | ---------------- | ----------------------- |
| `cmd_vel`        | Commande vitesse | `linear_x`, `angular_z` |
| `emergency_stop` | Arrêt immédiat   | -                       |
| `get_status`     | Demande d'état   | -                       |
| `ping`           | Test connexion   | -                       |

### Messages Sortants

| Type                 | Description              |
| -------------------- | ------------------------ |
| `connected`          | Accueil + config limites |
| `cmd_accepted`       | Vitesses appliquées      |
| `emergency_stop_ack` | Confirmation arrêt       |
| `status`             | État du bridge           |
| `pong`               | Réponse ping             |
| `error`              | Erreur traitement        |

## Limites de Vitesse

Le VelocityLimiter applique des contraintes de sécurité :

| Paramètre         | Valeur Par Défaut |
| ----------------- | ----------------- |
| `max_linear_vel`  | 0.5 m/s           |
| `min_linear_vel`  | -0.3 m/s          |
| `max_angular_vel` | ±1.5 rad/s        |

## Paramètres ROS2

```yaml
robot_namespace: 'robot_controler'
ws_host: '0.0.0.0'
ws_port: 8765
max_linear_vel: 0.5
min_linear_vel: -0.3
max_angular_vel: 1.5
```

## Structure des Fichiers

```
turtlebot_game/
├── package.xml
├── setup.py
├── setup.cfg
├── config/
│   └── bridge_params.yaml
├── launch/
│   └── safety_bridge.launch.py
└── turtlebot_game/
    ├── __init__.py
    └── safety_bridge.py      # Nœud ROS2 principal
```

## Lancement

```bash
# Build le package
cd ~/ros2_ws
colcon build --packages-select turtlebot_game

# Source et lancer
source install/setup.bash
ros2 run turtlebot_game safety_bridge
```

Ou via launch file :
```bash
ros2 launch turtlebot_game safety_bridge.launch.py
```

## Intégration

Le Safety Bridge est le point central de communication :

```mermaid
graph TB
    subgraph "Tank Project"
        AI[AIStrategy]
        RBC[ROSBridgeClient]
    end

    subgraph "Control TurtleBot"
        UI[IntegratedUI]
        WSC[WebSocketClient]
    end

    subgraph "TurtleBot Game"
        SB[Safety Bridge<br/>:8765]
    end

    subgraph "Robot"
        TB[TurtleBot<br/>/cmd_vel]
    end

    AI --> RBC
    RBC -->|Port 8765| SB
    UI --> WSC
    WSC -->|Port 8765| SB
    SB --> TB
```

Les deux clients (Tank Project pour l'IA et Control TurtleBot pour le contrôle manuel) communiquent avec le même Safety Bridge qui publie sur le topic `/cmd_vel`.


################################################################################
PATH: ./turtlebot_game/launch/safety_bridge.launch.py
################################################################################
# launch/safety_bridge.launch.py
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration
from launch_ros.actions import Node
import sys
import os

# Importer la config
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'config'))
from safety_config import SafetyBridgeConfig, DevConfig, ProdConfig

def generate_launch_description():
    """
    Lance le Safety Bridge avec configuration centralisée
    
    Usage:
        ros2 launch turtlebot_game safety_bridge.launch.py
        ros2 launch turtlebot_game safety_bridge.launch.py robot_namespace:=robot2 ws_port:=8766
    """
    
    # Choisir la config (change selon besoin)
    config = SafetyBridgeConfig  # Ou DevConfig, ProdConfig
    
    # ===== ARGUMENTS DYNAMIQUES =====
    # Ces arguments peuvent override la config
    robot_namespace = LaunchConfiguration('robot_namespace')
    ws_host = LaunchConfiguration('ws_host')
    ws_port = LaunchConfiguration('ws_port')
    max_linear_vel = LaunchConfiguration('max_linear_vel')
    min_linear_vel = LaunchConfiguration('min_linear_vel')
    max_angular_vel = LaunchConfiguration('max_angular_vel')
    log_level = LaunchConfiguration('log_level')
    debug = LaunchConfiguration('debug')
    
    return LaunchDescription([
        # ===== DECLARE ARGUMENTS avec valeurs depuis config =====
        DeclareLaunchArgument(
            'robot_namespace', 
            default_value=config.ROBOT_NAMESPACE,
            description='Namespace du robot'
        ),
        DeclareLaunchArgument(
            'ws_host', 
            default_value=config.WS_HOST,
            description='Host WebSocket (0.0.0.0 pour toutes interfaces)'
        ),
        DeclareLaunchArgument(
            'ws_port', 
            default_value=str(config.WS_PORT),
            description='Port WebSocket'
        ),
        DeclareLaunchArgument(
            'max_linear_vel', 
            default_value=str(config.MAX_LINEAR_VEL),
            description='Vitesse linéaire max (m/s)'
        ),
        DeclareLaunchArgument(
            'min_linear_vel', 
            default_value=str(config.MIN_LINEAR_VEL),
            description='Vitesse linéaire min (m/s)'
        ),
        DeclareLaunchArgument(
            'max_angular_vel', 
            default_value=str(config.MAX_ANGULAR_VEL),
            description='Vitesse angulaire max (rad/s)'
        ),
        DeclareLaunchArgument(
            'log_level', 
            default_value=config.LOG_LEVEL,
            description='Niveau de log (DEBUG, INFO, WARN, ERROR)'
        ),
        DeclareLaunchArgument(
            'debug', 
            default_value=str(config.DEBUG).lower(),
            description='Mode debug'
        ),
        
        # ===== SAFETY BRIDGE NODE =====
        Node(
            package='turtlebot_game',
            executable='safety_bridge',
            namespace=robot_namespace,
            name='safety_bridge',
            output='screen',
            emulate_tty=True,
            
            # Remappings
            remappings=[
                ('cmd_vel', '/cmd_vel'),
            ],
            
            # Paramètres: mix config + launch args
            parameters=[{
                # Paramètres de base
                'robot_namespace': robot_namespace,
                'ws_host': ws_host,
                'ws_port': ws_port,
                'max_linear_vel': max_linear_vel,
                'min_linear_vel': min_linear_vel,
                'max_angular_vel': max_angular_vel,
                'log_level': log_level,
                
                # Paramètres depuis config (non-overridables par launch)
                'safety_distance': config.SAFETY_DISTANCE,
                'robot_safety_distance': config.ROBOT_SAFETY_DISTANCE,
                'robot_radius': config.ROBOT_RADIUS,
                'prediction_steps': config.PREDICTION_STEPS,
                'prediction_dt': config.PREDICTION_DT,
                'qos_depth': config.QOS_DEPTH,
                'ws_ping_interval': config.WS_PING_INTERVAL,
                'ws_ping_timeout': config.WS_PING_TIMEOUT,
                'status_broadcast_interval': config.STATUS_BROADCAST_INTERVAL,
                'cmd_timeout': config.CMD_TIMEOUT,
            }],
            
            # Arguments ROS2
            arguments=['--ros-args', '--log-level', log_level]
        ),
    ])

################################################################################
PATH: ./turtlebot_game/package.xml
################################################################################
<?xml version="1.0"?>
<package format="3">
  <name>turtlebot_game</name>
  <version>0.1.0</version>
  <description>Projet VA50 UTBM - TurtleBot controllers and Safety Bridge WebSocket</description>

  <maintainer email="projetva50@utbm.edu">Projet VA50 Promo 2025 Automne</maintainer>
  <license>MIT</license>

  <buildtool_depend>ament_python</buildtool_depend>

  <exec_depend>rclpy</exec_depend>
  <exec_depend>geometry_msgs</exec_depend>
  <exec_depend>nav_msgs</exec_depend>
  <exec_depend>std_msgs</exec_depend>
  <exec_depend>tf2_ros</exec_depend>

  <exec_depend>python3-websockets</exec_depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

################################################################################
PATH: ./turtlebot_game/README.md
################################################################################
# TurtleBot Game

Package ROS2 contenant le Safety Bridge WebSocket pour contrôler le TurtleBot.

## Installation

```bash
cd ~/ros2_ws
colcon build --packages-select turtlebot_game
source install/setup.bash
```

## Lancement

```bash
ros2 run turtlebot_game safety_bridge
```

Ou via le script unifié :
```bash
./launch_game.sh --bridge
```

## Configuration

Paramètres ROS2 :
| Paramètre         | Défaut    | Description          |
| ----------------- | --------- | -------------------- |
| `ws_host`         | `0.0.0.0` | Interface d'écoute   |
| `ws_port`         | `8765`    | Port WebSocket       |
| `max_linear_vel`  | `0.5`     | Vitesse max (m/s)    |
| `max_angular_vel` | `1.5`     | Rotation max (rad/s) |

## Protocole WebSocket

### Messages Entrants

```json
{"type": "cmd_vel", "linear_x": 0.2, "angular_z": 0.5}
{"type": "emergency_stop"}
{"type": "get_status"}
{"type": "ping"}
```

### Messages Sortants

```json
{"type": "connected", "robot": "robot_controler", "config": {...}}
{"type": "cmd_accepted", "linear_x": 0.2, "angular_z": 0.5}
{"type": "pong", "timestamp": "..."}
```

## Structure

```
turtlebot_game/
├── package.xml
├── setup.py
├── launch/
│   └── safety_bridge.launch.py
└── turtlebot_game/
    └── safety_bridge.py     # Nœud ROS2 principal
```

Voir [DOCUMENTATION.md](DOCUMENTATION.md) pour l'architecture complète.


################################################################################
PATH: ./turtlebot_game/resource/turtlebot_game
################################################################################


################################################################################
PATH: ./turtlebot_game/setup.cfg
################################################################################
[develop]
script_dir=$base/lib/turtlebot_game
[install]
install_scripts=$base/lib/turtlebot_game


################################################################################
PATH: ./turtlebot_game/setup.py
################################################################################
from setuptools import setup, find_packages

package_name = 'turtlebot_game'

setup(
    name=package_name,
    version='0.1.0',
    packages=find_packages(), 
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),

        ('share/' + package_name, ['package.xml']),

        # Launch files
        ('share/' + package_name + '/launch', [
            'launch/safety_bridge.launch.py',
        ]),
    ],
    install_requires=[
        'setuptools',
        'websockets>=12.0',  
        'numpy',
    ],
    zip_safe=True,
    maintainer='Projet VA50 Promo 2025 Automne',
    maintainer_email='projetva50@utbm.edu',
    description='Modules de jeu TurtleBot + Safety Bridge WebSocket pour VA50 UTBM',
    license='MIT',
    tests_require=['pytest'],
    
    entry_points={
        'console_scripts': [
            'safety_bridge = turtlebot_game.safety_bridge:main',
        ],
    },
)


################################################################################
PATH: ./turtlebot_game/test/test_copyright.py
################################################################################
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


# Remove the `skip` decorator once the source file(s) have a copyright header
@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')
@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'


################################################################################
PATH: ./turtlebot_game/test/test_flake8.py
################################################################################
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)


################################################################################
PATH: ./turtlebot_game/test/test_pep257.py
################################################################################
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'


################################################################################
PATH: ./turtlebot_game/turtlebot_game/__init__.py
################################################################################
\"\"\"Package turtlebot_game - Modules de jeu et pont de securite WebSocket.\"\"\"


################################################################################
PATH: ./turtlebot_game/turtlebot_game/safety_bridge.py
################################################################################
"""
TurtleBot WebSocket Bridge ROS2 
Bridge pur entre WebSocket et ROS2 cmd_vel
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
import numpy as np
import json
import asyncio
import websockets
from threading import Thread, Lock
from geometry_msgs.msg import Twist
import math
import socket
from datetime import datetime
import traceback


class SafetyConfig:
    """Configuration des limites de vitesse"""
    def __init__(self):
        self.max_linear_vel = 0.5
        self.min_linear_vel = -0.3
        self.max_angular_vel = 1.5


class VelocityLimiter:
    """Limiteur simple de vitesse (clamp uniquement)"""
    
    def __init__(self, config, logger):
        self.config = config
        self.lock = Lock()
        self.logger = logger
        
    def validate_command(self, linear_x, angular_z):
        """Validation simple : clamp aux limites physiques"""
        with self.lock:
            original_linear = linear_x
            original_angular = angular_z
            
            # Clamp aux limites configurées
            linear_x = np.clip(linear_x, self.config.min_linear_vel, self.config.max_linear_vel)
            angular_z = np.clip(angular_z, -self.config.max_angular_vel, self.config.max_angular_vel)
            
            # Déterminer le statut
            if abs(linear_x) < 0.001 and abs(angular_z) < 0.001:
                reason = "Arrêt"
            elif abs(original_linear - linear_x) > 0.001 or abs(original_angular - angular_z) > 0.001:
                reason = "Vitesse Limitée"
            else:
                reason = "OK"
            
            return True, linear_x, angular_z, reason


class ROSBridge(Node):
    """Pont simple entre WebSocket et ROS2"""
    
    def __init__(self):
        super().__init__('websocket_bridge')
        
        self._print_startup_banner()
        
        # Paramètres ROS2
        self._declare_and_get_parameters()
        
        # Configuration
        self.config = SafetyConfig()
        self.config.max_linear_vel = self.max_linear_vel
        self.config.min_linear_vel = self.min_linear_vel
        self.config.max_angular_vel = self.max_angular_vel
        
        self.velocity_limiter = VelocityLimiter(self.config, self.get_logger())
        
        self._print_configuration()
        
        # Publisher cmd_vel uniquement
        self._setup_ros_interfaces()
        
        # Stats
        self.commands_received = 0
        self.commands_accepted = 0
        self.commands_blocked = 0
        self.last_status = "Initialisation"
        self.connected_clients = set()
        self.start_time = self.get_clock().now()
        
        # WebSocket
        self.ws_server = None
        self.running = True
        
        self._print_network_info()
        
        self.get_logger().info(" [INIT] Bridge prêt à démarrer")
    
    def _print_startup_banner(self):
        """Affiche la bannière de démarrage"""
        banner = """
╔══════════════════════════════════════════════════════════════╗
║            _ TURTLEBOT WEBSOCKET BRIDGE ROS2 _               ║
╚══════════════════════════════════════════════════════════════╝
"""
        print(banner)
        self.get_logger().info(" [INIT] Démarrage du WebSocket Bridge")
    
    def _declare_and_get_parameters(self):
        """Déclare et récupère tous les paramètres ROS2"""
        # Déclaration
        self.declare_parameter('robot_namespace', 'robot_controler')
        self.declare_parameter('ws_host', '0.0.0.0')
        self.declare_parameter('ws_port', 8765)
        self.declare_parameter('max_linear_vel', 0.5)
        self.declare_parameter('min_linear_vel', -0.3)
        self.declare_parameter('max_angular_vel', 1.5)
        self.declare_parameter('log_level', 'INFO')
        
        # Récupération
        self.robot_namespace = self.get_parameter('robot_namespace').value
        self.ws_host = self.get_parameter('ws_host').value
        self.ws_port = self.get_parameter('ws_port').value
        self.max_linear_vel = self.get_parameter('max_linear_vel').value
        self.min_linear_vel = self.get_parameter('min_linear_vel').value
        self.max_angular_vel = self.get_parameter('max_angular_vel').value
        self.log_level = self.get_parameter('log_level').value
        
        self.get_logger().info("  [INIT] Paramètres ROS2 chargés:")
        self.get_logger().info(f"   ├─ robot_namespace: {self.robot_namespace}")
        self.get_logger().info(f"   ├─ ws_host: {self.ws_host}")
        self.get_logger().info(f"   ├─ ws_port: {self.ws_port}")
        self.get_logger().info(f"   ├─ max_linear_vel: {self.max_linear_vel}")
        self.get_logger().info(f"   ├─ min_linear_vel: {self.min_linear_vel}")
        self.get_logger().info(f"   ├─ max_angular_vel: {self.max_angular_vel}")
        self.get_logger().info(f"   └─ log_level: {self.log_level}")
    
    def _setup_ros_interfaces(self):
        """Configure le publisher ROS2"""
        self.get_logger().info(" [INIT] Configuration des interfaces ROS2...")
        
        # QoS Profile pour meilleure fiabilité
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=10
        )
        
        # Publisher cmd_vel uniquement
        self.cmd_vel_pub = self.create_publisher(
            Twist,
            'cmd_vel',
            qos_profile
        )
        self.get_logger().info(f"   └─  Publisher: /{self.robot_namespace}/cmd_vel")
    
    def _print_configuration(self):
        """Affiche la configuration détaillée"""
        self.get_logger().info("╔" + "═"*58 + "╗")
        self.get_logger().info("║" + " "*18 + "CONFIGURATION" + " "*27 + "║")
        self.get_logger().info("╠" + "═"*58 + "╣")
        self.get_logger().info(f"║  Robot: {self.robot_namespace:<44} ║")
        self.get_logger().info(f"║  WebSocket: {self.ws_host}:{self.ws_port:<34} ║")
        self.get_logger().info(f"║  Vitesse linéaire: [{self.min_linear_vel:>6.2f}, {self.max_linear_vel:>5.2f}] m/s" + " "*11 + "║")
        self.get_logger().info(f"║  Vitesse angulaire: ±{self.max_angular_vel:.2f} rad/s" + " "*21 + "║")
        self.get_logger().info("╚" + "═"*58 + "╝")
    
    def _print_network_info(self):
        """Affiche les informations réseau"""
        try:
            hostname = socket.gethostname()
            local_ip = socket.gethostbyname(hostname)
            
            self.get_logger().info("╔" + "═"*58 + "╗")
            self.get_logger().info("║" + " "*17 + "INFORMATIONS RÉSEAU" + " "*21 + "║")
            self.get_logger().info("╠" + "═"*58 + "╣")
            self.get_logger().info(f"║   Hostname: {hostname:<42} ║")
            self.get_logger().info(f"║  IP locale: {local_ip:<41} ║")
            self.get_logger().info(f"║  Port WebSocket: {self.ws_port:<36} ║")
            self.get_logger().info(f"║  URL: ws://{local_ip}:{self.ws_port:<31} ║")
            if self.ws_host == '0.0.0.0':
                self.get_logger().info(f"║   Écoute sur toutes les interfaces" + " "*20 + "║")
            self.get_logger().info("╚" + "═"*58 + "╝")
        except Exception as e:
            self.get_logger().warn(f"  Impossible de récupérer les infos réseau: {e}")
    
    async def handle_websocket(self, websocket, path=None):
        """Gère une connexion WebSocket avec logging détaillé"""
        client_ip = websocket.remote_address[0]
        client_port = websocket.remote_address[1]
        client_id = f"{client_ip}:{client_port}"
        connection_time = datetime.now()
        
        path_str = str(path) if path is not None else "/"

        self.connected_clients.add(websocket)
        
        # Log détaillé de connexion
        self.get_logger().info("╔" + "═"*58 + "╗")
        self.get_logger().info("║" + " "*16 + " NOUVELLE CONNEXION" + " "*21 + "║")
        self.get_logger().info("╠" + "═"*58 + "╣")
        self.get_logger().info(f"║  IP: {client_ip:<48} ║")
        self.get_logger().info(f"║  Port: {client_port:<46} ║")
        self.get_logger().info(f"║  ID: {client_id:<49} ║")
        self.get_logger().info(f"║  Heure: {connection_time.strftime('%H:%M:%S.%f')[:-3]:<43} ║")
        self.get_logger().info(f"║  Total clients: {len(self.connected_clients):<37} ║")
        self.get_logger().info(f"║  Path: {path_str:<47} ║")
        self.get_logger().info("╚" + "═"*58 + "╝")
        
        try:
            # Message d'accueil
            welcome = {
                'type': 'connected',
                'robot': self.robot_namespace,
                'server_time': connection_time.isoformat(),
                'config': {
                    'max_linear_vel': self.max_linear_vel,
                    'min_linear_vel': self.min_linear_vel,
                    'max_angular_vel': self.max_angular_vel
                }
            }
            
            welcome_json = json.dumps(welcome, indent=2)
            
            self.get_logger().info(f" [WS{client_id}] Envoi message d'accueil")
            self.get_logger().info(f" Payload ({len(welcome_json)} octets):")
            for line in welcome_json.split('\n'):
                self.get_logger().info(f"   {line}")
            
            await websocket.send(welcome_json)
            self.get_logger().info(f" [WS{client_id}] Message d'accueil envoyé")
            
            # Boucle de réception
            msg_count = 0
            self.get_logger().info(f" [WS{client_id}] En attente de messages...")
            
            async for message in websocket:
                msg_count += 1
                receive_time = datetime.now()
                
                # Log de réception détaillé
                self.get_logger().info("┌" + "─"*58 + "┐")
                self.get_logger().info(f"│  MESSAGE #{msg_count:<46} │")
                self.get_logger().info("├" + "─"*58 + "┤")
                self.get_logger().info(f"│  Client: {client_id:<45} │")
                self.get_logger().info(f"│  Heure: {receive_time.strftime('%H:%M:%S.%f')[:-3]:<46} │")
                self.get_logger().info(f"│  Taille: {len(message)} octets{' '*(44-len(str(len(message))))} │")
                self.get_logger().info("└" + "─"*58 + "┘")
                
                # Log du contenu brut
                self.get_logger().info(f" Contenu brut:")
                if len(message) <= 500:
                    self.get_logger().info(f"   {message}")
                else:
                    self.get_logger().info(f"   {message[:500]}... (tronqué)")
                
                try:
                    data = json.loads(message)
                    msg_type = data.get('type', 'unknown')
                    
                    self.get_logger().info(f" Message parsé:")
                    self.get_logger().info(f"   ├─ Type: {msg_type}")
                    
                    # Log du JSON complet
                    json_str = json.dumps(data, indent=2)
                    self.get_logger().info(f"   └─ Données:")
                    for line in json_str.split('\n'):
                        self.get_logger().info(f"      {line}")
                    
                    # Traitement selon le type
                    if msg_type == 'cmd_vel':
                        await self._process_cmd_vel(websocket, data, client_id, msg_count)
                    
                    elif msg_type == 'emergency_stop':
                        await self._process_emergency_stop(websocket, client_id, msg_count)
                    
                    elif msg_type == 'get_status':
                        await self._process_get_status(websocket, client_id, msg_count)
                    
                    elif msg_type == 'ping':
                        await self._process_ping(websocket, client_id, msg_count)
                    
                    else:
                        self.get_logger().warn(f" [WS{client_id}] Type inconnu: {msg_type}")
                        await websocket.send(json.dumps({
                            'type': 'error',
                            'reason': f'Unknown message type: {msg_type}',
                            'received_type': msg_type
                        }))
                
                except json.JSONDecodeError as e:
                    self.get_logger().error(f"  [WS{client_id}] ERREUR JSON:")
                    self.get_logger().error(f"   ├─ Position: {e.pos}")
                    self.get_logger().error(f"   ├─ Ligne: {e.lineno}, Colonne: {e.colno}")
                    self.get_logger().error(f"   ├─ Message: {e.msg}")
                    self.get_logger().error(f"   └─ Contenu: {message[:200]}")
                    
                    await websocket.send(json.dumps({
                        'type': 'error',
                        'reason': 'Invalid JSON',
                        'details': str(e)
                    }))
                
                except Exception as e:
                    self.get_logger().error(f" [WS{client_id}] ERREUR TRAITEMENT:")
                    self.get_logger().error(f"   ├─ Type: {type(e).__name__}")
                    self.get_logger().error(f"   ├─ Message: {e}")
                    self.get_logger().error(f"   └─ Traceback:")
                    for line in traceback.format_exc().split('\n'):
                        if line.strip():
                            self.get_logger().error(f"      {line}")
        
        except websockets.exceptions.ConnectionClosed as e:
            duration = (datetime.now() - connection_time).total_seconds()
            
            self.get_logger().info("╔" + "═"*58 + "╗")
            self.get_logger().info("║" + " "*18 + " DÉCONNEXION" + " "*25 + "║")
            self.get_logger().info("╠" + "═"*58 + "╣")
            self.get_logger().info(f"║  Client: {client_id:<44} ║")
            self.get_logger().info(f"║  Code: {e.code:<47} ║")
            self.get_logger().info(f"║  Raison: {str(e.reason)[:43]:<44} ║")
            self.get_logger().info(f"║  Messages traités: {msg_count:<34} ║")
            self.get_logger().info(f"║   Durée: {duration:.2f}s{' '*(43-len(f'{duration:.2f}'))} ║")
            self.get_logger().info("╚" + "═"*58 + "╝")
        
        except Exception as e:
            self.get_logger().error(f" [WS] ERREUR CONNEXION ({client_id}):")
            self.get_logger().error(f"   ├─ {type(e).__name__}: {e}")
            self.get_logger().error(f"   └─ Traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    self.get_logger().error(f"      {line}")
        
        finally:
            if websocket in self.connected_clients:
                self.connected_clients.remove(websocket)
            
            self.get_logger().info(f" [WS] Fin connexion {client_id}")
            self.get_logger().info(f"   └─ Clients restants: {len(self.connected_clients)}")
    
    async def _process_cmd_vel(self, websocket, data, client_id, msg_num):
        """Traite une commande cmd_vel"""
        self.commands_received += 1
        process_start = datetime.now()
        
        linear_x = data.get('linear_x', 0.0)
        angular_z = data.get('angular_z', 0.0)
        
        self.get_logger().info(f" [CMD_VEL #{msg_num}] Commande reçue:")
        self.get_logger().info(f"   ├─ Source: {client_id}")
        self.get_logger().info(f"   ├─ linear_x:  {linear_x:>8.6f} m/s")
        self.get_logger().info(f"   └─ angular_z: {angular_z:>8.6f} rad/s")
        
        # Validation simple (clamp uniquement)
        is_valid, safe_linear, safe_angular, reason = \
            self.velocity_limiter.validate_command(linear_x, angular_z)
        
        self.commands_accepted += 1
        
        # Publication sur ROS
        twist = Twist()
        twist.linear.x = safe_linear
        twist.angular.z = safe_angular
        
        self.get_logger().info(f" [CMD_VEL #{msg_num}] Commande PUBLIÉE:")
        self.get_logger().info(f"   ├─ Raison: {reason}")
        self.get_logger().info(f"   ├─ Publié linear:  {safe_linear:>8.6f} m/s")
        self.get_logger().info(f"   ├─ Publié angular: {safe_angular:>8.6f} rad/s")
        self.get_logger().info(f"   └─ Topic: /{self.robot_namespace}/cmd_vel")
        
        self.cmd_vel_pub.publish(twist)
        self.last_status = reason
        
        # Stats
        accept_rate = (self.commands_accepted / self.commands_received * 100) if self.commands_received > 0 else 0
        self.get_logger().info(f" [STATS] Reçues: {self.commands_received} | "
                             f"Acceptées: {self.commands_accepted} ({accept_rate:.1f}%)")
        
        # Confirmation au client
        response = {
            'type': 'cmd_accepted',
            'linear_x': safe_linear,
            'angular_z': safe_angular,
            'reason': reason,
            'msg_num': msg_num,
            'timestamp': datetime.now().isoformat()
        }
        
        await websocket.send(json.dumps(response))
        
        process_time = (datetime.now() - process_start).total_seconds() * 1000
        self.get_logger().info(f"  [CMD_VEL #{msg_num}] Traité en {process_time:.2f}ms")
    
    async def _process_emergency_stop(self, websocket, client_id, msg_num):
        """Traite un arrêt d'urgence"""
        self.get_logger().warn("╔" + "═"*58 + "╗")
        self.get_logger().warn("║" + " "*16 + " ARRÊT D'URGENCE" + " "*23 + "║")
        self.get_logger().warn("╠" + "═"*58 + "╣")
        self.get_logger().warn(f"║  Demandé par: {client_id:<40} ║")
        self.get_logger().warn(f"║  Message #{msg_num:<44} ║")
        self.get_logger().warn(f"║  Heure: {datetime.now().strftime('%H:%M:%S.%f')[:-3]:<46} ║")
        self.get_logger().warn("╚" + "═"*58 + "╝")
        
        # Arrêt immédiat
        twist = Twist()
        self.cmd_vel_pub.publish(twist)
        
        self.get_logger().warn(f" [EMERGENCY] Robot ARRÊTÉ sur /{self.robot_namespace}/cmd_vel")
        
        # Confirmation
        response = {
            'type': 'emergency_stop_ack',
            'timestamp': datetime.now().isoformat(),
            'msg_num': msg_num
        }
        
        await websocket.send(json.dumps(response))
        self.get_logger().info(f" [EMERGENCY] Confirmation envoyée à {client_id}")
    
    async def _process_get_status(self, websocket, client_id, msg_num):
        """Traite une demande de status"""
        self.get_logger().info(f" [STATUS] Demande #{msg_num} de {client_id}")
        
        uptime = (self.get_clock().now() - self.start_time).nanoseconds / 1e9
        
        status = {
            'type': 'status',
            'timestamp': datetime.now().isoformat(),
            'uptime_seconds': uptime,
            'commands_received': self.commands_received,
            'commands_accepted': self.commands_accepted,
            'last_status': self.last_status,
            'connected_clients': len(self.connected_clients)
        }
        
        status_json = json.dumps(status, indent=2)
        self.get_logger().info(f" [STATUS] Envoi:")
        for line in status_json.split('\n')[:10]:
            self.get_logger().info(f"   {line}")
        
        await websocket.send(status_json)
        self.get_logger().info(f" [STATUS] Status envoyé à {client_id}")
    
    async def _process_ping(self, websocket, client_id, msg_num):
        """Traite un ping"""
        self.get_logger().info(f" [PING] Reçu de {client_id}")
        
        response = {
            'type': 'pong',
            'timestamp': datetime.now().isoformat(),
            'msg_num': msg_num
        }
        
        await websocket.send(json.dumps(response))
        self.get_logger().info(f" [PONG] Réponse envoyée à {client_id}")
    
    async def broadcast_status(self):
        """Broadcast périodique du status"""
        broadcast_count = 0
        
        self.get_logger().info(" [BROADCAST] Service de broadcast démarré")
        
        while self.running:
            await asyncio.sleep(5.0)
            
            if self.connected_clients:
                broadcast_count += 1
                uptime = (self.get_clock().now() - self.start_time).nanoseconds / 1e9
                
                status_msg = {
                    'type': 'status_broadcast',
                    'timestamp': datetime.now().isoformat(),
                    'broadcast_num': broadcast_count,
                    'uptime_seconds': uptime,
                    'last_status': self.last_status,
                    'commands_stats': {
                        'received': self.commands_received,
                        'accepted': self.commands_accepted
                    },
                    'connected_clients': len(self.connected_clients)
                }
                
                if broadcast_count % 12 == 0:
                    self.get_logger().info(f" [BROADCAST #{broadcast_count}] Status envoyé à {len(self.connected_clients)} client(s)")
                    self.get_logger().info(f"   ├─ Uptime: {uptime:.1f}s")
                    self.get_logger().info(f"   ├─ Commandes: {self.commands_received} reçues, {self.commands_accepted} acceptées")
                    self.get_logger().info(f"   └─ Status: {self.last_status}")
                
                try:
                    websockets.broadcast(self.connected_clients, json.dumps(status_msg))
                except Exception as e:
                    self.get_logger().error(f"  [BROADCAST] Erreur: {e}")
    
    def run_websocket_server(self):
        """Lance le serveur WebSocket"""
        self.get_logger().info("╔" + "═"*58 + "╗")
        self.get_logger().info("║" + " "*12 + " DÉMARRAGE SERVEUR WEBSOCKET" + " "*16 + "║")
        self.get_logger().info("╚" + "═"*58 + "╝")
        
        async def main():
            try:
                self.get_logger().info(f" [WS-SERVER] Configuration:")
                self.get_logger().info(f"   ├─ Host: {self.ws_host}")
                self.get_logger().info(f"   ├─ Port: {self.ws_port}")
                self.get_logger().info(f"   └─ Namespace: {self.robot_namespace}")
                
                self.get_logger().info(f" [WS-SERVER] Lancement du serveur...")
                
                async with websockets.serve(
                    self.handle_websocket,
                    self.ws_host,
                    self.ws_port,
                    ping_interval=20,
                    ping_timeout=10,
                    compression=None
                ):
                    self.get_logger().info("╔" + "═"*58 + "╗")
                    self.get_logger().info("║" + " "*12 + " SERVEUR WEBSOCKET ACTIF" + " "*19 + "║")
                    self.get_logger().info("╠" + "═"*58 + "╣")
                    
                    try:
                        hostname = socket.gethostname()
                        local_ip = socket.gethostbyname(hostname)
                        
                        self.get_logger().info(f"║  URLs de connexion:" + " "*35 + "║")
                        self.get_logger().info(f"║    • Local:   ws://localhost:{self.ws_port}{' '*(27-len(str(self.ws_port)))} ║")
                        self.get_logger().info(f"║    • LAN:     ws://{local_ip}:{self.ws_port}{' '*(27-len(local_ip)-len(str(self.ws_port)))} ║")
                    except:
                        self.get_logger().info(f"║  URL: ws://{self.ws_host}:{self.ws_port}{' '*(36-len(self.ws_host)-len(str(self.ws_port)))} ║")
                    
                    self.get_logger().info("╠" + "═"*58 + "╣")
                    self.get_logger().info(f"║  En attente de connexions..." + " "*26 + "║")
                    self.get_logger().info(f"║  Robot: {self.robot_namespace:<44} ║")
                    self.get_logger().info(f"║  Prêt à recevoir des commandes cmd_vel" + " "*15 + "║")
                    self.get_logger().info("╚" + "═"*58 + "╝")
                    
                    # Broadcast task
                    broadcast_task = asyncio.create_task(self.broadcast_status())
                    
                    self.get_logger().info(" [WS-SERVER] Serveur opérationnel!")
                    self.get_logger().info("")
                    self.get_logger().info(" COMMANDES DISPONIBLES:")
                    self.get_logger().info("   • cmd_vel        - Envoyer une commande de vitesse")
                    self.get_logger().info("   • emergency_stop - Arrêt d'urgence")
                    self.get_logger().info("   • get_status     - Obtenir le statut")
                    self.get_logger().info("   • ping           - Test de connexion")
                    self.get_logger().info("")
                    
                    await asyncio.Future()
            
            except OSError as e:
                self.get_logger().error("╔" + "═"*58 + "╗")
                self.get_logger().error("║" + " "*14 + " ERREUR DÉMARRAGE SERVEUR" + " "*17 + "║")
                self.get_logger().error("╠" + "═"*58 + "╣")
                
                if e.errno == 98 or e.errno == 48:
                    self.get_logger().error(f"║   Port {self.ws_port} déjà utilisé!" + " "*(36-len(str(self.ws_port))) + "║")
                    self.get_logger().error("║" + " "*58 + "║")
                    self.get_logger().error("║  Solutions:" + " "*44 + "║")
                    self.get_logger().error(f"║    lsof -i :{self.ws_port}{' '*(44-len(str(self.ws_port)))} ║")
                else:
                    self.get_logger().error(f"║ Erreur: {str(e)[:50]:<50} ║")
                
                self.get_logger().error("╚" + "═"*58 + "╝")
            
            except Exception as e:
                self.get_logger().error("╔" + "═"*58 + "╗")
                self.get_logger().error("║" + " "*18 + " ERREUR SERVEUR" + " "*23 + "║")
                self.get_logger().error("╠" + "═"*58 + "╣")
                self.get_logger().error(f"║ Type: {type(e).__name__:<49} ║")
                self.get_logger().error(f"║ Message: {str(e)[:48]:<48} ║")
                self.get_logger().error("╚" + "═"*58 + "╝")
        
        asyncio.run(main())
    
    def shutdown(self):
        """Arrêt propre du bridge"""
        self.get_logger().info("╔" + "═"*58 + "╗")
        self.get_logger().info("║" + " "*20 + " ARRÊT DU BRIDGE" + " "*21 + "║")
        self.get_logger().info("╚" + "═"*58 + "╝")
        
        self.running = False
        
        # Arrêt du robot
        twist = Twist()
        self.cmd_vel_pub.publish(twist)
        self.get_logger().info("   ├─  Robot arrêté")
        
        # Stats finales
        uptime = (self.get_clock().now() - self.start_time).nanoseconds / 1e9
        
        self.get_logger().info("╔" + "═"*58 + "╗")
        self.get_logger().info("║" + " "*20 + " STATISTIQUES FINALES" + " "*15 + "║")
        self.get_logger().info("╠" + "═"*58 + "╣")
        self.get_logger().info(f"║   Uptime: {uptime:.2f}s{' '*(47-len(f'{uptime:.2f}'))} ║")
        self.get_logger().info(f"║  Commandes reçues: {self.commands_received:<33} ║")
        self.get_logger().info(f"║  Commandes acceptées: {self.commands_accepted:<30} ║")
        
        if self.commands_received > 0:
            accept_rate = (self.commands_accepted / self.commands_received * 100)
            self.get_logger().info(f"║  Taux d'acceptation: {accept_rate:.1f}%{' '*(30-len(f'{accept_rate:.1f}'))} ║")
        
        self.get_logger().info("╚" + "═"*58 + "╝")
        
        self.destroy_node()
        self.get_logger().info(" [SHUTDOWN] Bridge arrêté proprement")


def main(args=None):
    """Point d'entrée principal"""
    print("\n" + "╔" + "═"*58 + "╗")
    print("║" + " "*8 + " TURTLEBOT WEBSOCKET BRIDGE ROS2 " + " "*13 + "║")
    print("║" + " "*12 + "Version 2.1 - Bridge Simple & Propre" + " "*9 + "║")
    print("╚" + "═"*58 + "╝\n")
    
    rclpy.init(args=args)
    
    bridge = None
    
    try:
        bridge = ROSBridge()
        
        print(" Démarrage du serveur WebSocket...\n")
        ws_thread = Thread(target=bridge.run_websocket_server, daemon=True)
        ws_thread.start()
        
        print(" Bridge initialisé")
        print(" Attendez le message ' SERVEUR WEBSOCKET ACTIF'...\n")
        
        import time
        time.sleep(2)
        
        print(" Démarrage du spin ROS2...\n")
        rclpy.spin(bridge)
    
    except KeyboardInterrupt:
        print("\n╔" + "═"*58 + "╗")
        print("║" + " "*12 + " ARRÊT DEMANDÉ PAR L'UTILISATEUR" + " "*13 + "║")
        print("╚" + "═"*58 + "╝")
    
    except Exception as e:
        print("\n╔" + "═"*58 + "╗")
        print("║" + " "*20 + " ERREUR FATALE" + " "*23 + "║")
        print("╠" + "═"*58 + "╣")
        print(f"║ {type(e).__name__}: {str(e)[:45]:<45} ║")
        print("╚" + "═"*58 + "╝\n")
        traceback.print_exc()
    
    finally:
        if bridge is not None:
            try:
                bridge.shutdown()
            except:
                pass
        
        try:
            rclpy.shutdown()
        except:
            pass
        
        print("\n Programme terminé\n")


if __name__ == '__main__':
    main()

